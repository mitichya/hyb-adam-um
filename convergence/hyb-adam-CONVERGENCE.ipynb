{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "688068cb-3134-4e4f-9399-a96112fff9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calculating Δ for original matrix ===\n",
      "Original matrix file: Result_NW_15x15.txt\n",
      "Number of triplets (n choose 3) = 455\n",
      "Original matrix Δ_total = 105.474106\n",
      "Original Δ_normalized = 0.037533\n",
      "Original Δ_per_triangle (Δ/ntri) = 0.231811\n",
      "\n",
      "=== Running Hyb-Adam-UM on all masks ===\n",
      "\n",
      "  Processing 50% missing, replicate 1...\n",
      "Initial robust Δ: 243.066975\n",
      "Epoch     1 | full Δ = 381.057073 | lr=0.04000\n",
      "Epoch    50 | full Δ = 106.895121 | lr=0.04000\n",
      "Epoch   100 | full Δ = 92.239178 | lr=0.04000\n",
      "Epoch   150 | full Δ = 94.305672 | lr=0.04000\n",
      "Epoch   200 | full Δ = 82.451682 | lr=0.04000\n",
      "Epoch   250 | full Δ = 98.693658 | lr=0.04000\n",
      "Epoch   300 | full Δ = 85.928601 | lr=0.04000\n",
      "Epoch   350 | full Δ = 101.890860 | lr=0.04000\n",
      "Epoch   400 | full Δ = 88.335313 | lr=0.04000\n",
      "Epoch   450 | full Δ = 95.304443 | lr=0.04000\n",
      "Epoch   500 | full Δ = 93.485534 | lr=0.04000\n",
      "Epoch   550 | full Δ = 92.988153 | lr=0.04000\n",
      "Epoch 00550: lr plateau 0.040000->0.020000\n",
      "Epoch   600 | full Δ = 76.819292 | lr=0.02000\n",
      "Epoch   650 | full Δ = 70.200410 | lr=0.02000\n",
      "Epoch 00700: lr milestone 0.020000->0.010000\n",
      "Epoch   700 | full Δ = 74.598075 | lr=0.01000\n",
      "Epoch   750 | full Δ = 64.288624 | lr=0.01000\n",
      "Epoch   800 | full Δ = 64.982691 | lr=0.01000\n",
      "Epoch   850 | full Δ = 64.465249 | lr=0.01000\n",
      "Epoch   900 | full Δ = 64.335373 | lr=0.01000\n",
      "Epoch   950 | full Δ = 64.364539 | lr=0.01000\n",
      "Epoch  1000 | full Δ = 63.397518 | lr=0.01000\n",
      "Epoch  1050 | full Δ = 65.370420 | lr=0.01000\n",
      "Epoch  1100 | full Δ = 64.751692 | lr=0.01000\n",
      "Epoch  1150 | full Δ = 64.625972 | lr=0.01000\n",
      "Epoch  1200 | full Δ = 64.559146 | lr=0.01000\n",
      "Epoch  1250 | full Δ = 63.038766 | lr=0.01000\n",
      "Epoch  1300 | full Δ = 67.310358 | lr=0.01000\n",
      "Epoch  1350 | full Δ = 65.363387 | lr=0.01000\n",
      "Epoch  1400 | full Δ = 64.127679 | lr=0.01000\n",
      "Epoch  1450 | full Δ = 65.129194 | lr=0.01000\n",
      "Epoch  1500 | full Δ = 66.255599 | lr=0.01000\n",
      "Epoch  1550 | full Δ = 64.292794 | lr=0.01000\n",
      "Epoch  1600 | full Δ = 65.872560 | lr=0.01000\n",
      "Epoch 01600: lr plateau 0.010000->0.005000\n",
      "Epoch  1650 | full Δ = 60.173621 | lr=0.00500\n",
      "Epoch  1700 | full Δ = 61.912326 | lr=0.00500\n",
      "Epoch  1750 | full Δ = 60.895291 | lr=0.00500\n",
      "Epoch  1800 | full Δ = 60.488784 | lr=0.00500\n",
      "Epoch  1850 | full Δ = 60.844872 | lr=0.00500\n",
      "Epoch  1900 | full Δ = 60.747608 | lr=0.00500\n",
      "Epoch  1950 | full Δ = 61.744817 | lr=0.00500\n",
      "Epoch 02000: lr milestone 0.005000->0.002500\n",
      "Epoch  2000 | full Δ = 61.202679 | lr=0.00250\n",
      "Epoch 02000: lr plateau 0.002500->0.001250\n",
      "Epoch  2050 | full Δ = 57.899791 | lr=0.00125\n",
      "Epoch  2100 | full Δ = 57.912317 | lr=0.00125\n",
      "Epoch  2150 | full Δ = 58.064765 | lr=0.00125\n",
      "Epoch  2200 | full Δ = 57.887573 | lr=0.00125\n",
      "Epoch  2250 | full Δ = 57.905258 | lr=0.00125\n",
      "Epoch  2300 | full Δ = 57.928577 | lr=0.00125\n",
      "Epoch  2350 | full Δ = 57.841017 | lr=0.00125\n",
      "Epoch  2400 | full Δ = 58.063592 | lr=0.00125\n",
      "Epoch  2450 | full Δ = 57.910107 | lr=0.00125\n",
      "Epoch  2500 | full Δ = 57.933560 | lr=0.00125\n",
      "Epoch  2550 | full Δ = 57.808807 | lr=0.00125\n",
      "Epoch  2600 | full Δ = 58.200274 | lr=0.00125\n",
      "Epoch  2650 | full Δ = 57.978132 | lr=0.00125\n",
      "Epoch  2700 | full Δ = 58.023144 | lr=0.00125\n",
      "Epoch  2750 | full Δ = 57.783135 | lr=0.00125\n",
      "Epoch  2800 | full Δ = 57.836762 | lr=0.00125\n",
      "Epoch  2850 | full Δ = 57.973481 | lr=0.00125\n",
      "Epoch  2900 | full Δ = 58.208372 | lr=0.00125\n",
      "Epoch  2950 | full Δ = 57.913882 | lr=0.00125\n",
      "Epoch  3000 | full Δ = 57.986640 | lr=0.00125\n",
      "    Runtime for 50% missing, replicate 1: 19.96 sec (0.33 min)\n",
      "    End-to-end runtime: 19.96 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 2...\n",
      "Initial robust Δ: 188.218800\n",
      "Epoch     1 | full Δ = 335.480424 | lr=0.04000\n",
      "Epoch    50 | full Δ = 351.175168 | lr=0.04000\n",
      "Epoch   100 | full Δ = 463.888968 | lr=0.04000\n",
      "Epoch   150 | full Δ = 121.957262 | lr=0.04000\n",
      "Epoch   200 | full Δ = 225.708705 | lr=0.04000\n",
      "Epoch   250 | full Δ = 83.451989 | lr=0.04000\n",
      "Epoch   300 | full Δ = 86.834745 | lr=0.04000\n",
      "Epoch   350 | full Δ = 96.828417 | lr=0.04000\n",
      "Epoch   400 | full Δ = 80.741992 | lr=0.04000\n",
      "Epoch   450 | full Δ = 85.694190 | lr=0.04000\n",
      "Epoch   500 | full Δ = 95.380746 | lr=0.04000\n",
      "Epoch   550 | full Δ = 82.977306 | lr=0.04000\n",
      "Epoch   600 | full Δ = 80.447833 | lr=0.04000\n",
      "Epoch   650 | full Δ = 78.274873 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch   700 | full Δ = 93.796876 | lr=0.02000\n",
      "Epoch   750 | full Δ = 62.959849 | lr=0.02000\n",
      "Epoch   800 | full Δ = 66.230264 | lr=0.02000\n",
      "Epoch   850 | full Δ = 69.379880 | lr=0.02000\n",
      "Epoch   900 | full Δ = 64.414368 | lr=0.02000\n",
      "Epoch   950 | full Δ = 62.174568 | lr=0.02000\n",
      "Epoch  1000 | full Δ = 65.789140 | lr=0.02000\n",
      "Epoch  1050 | full Δ = 68.056238 | lr=0.02000\n",
      "Epoch  1100 | full Δ = 65.383301 | lr=0.02000\n",
      "Epoch  1150 | full Δ = 64.256341 | lr=0.02000\n",
      "Epoch  1200 | full Δ = 66.121293 | lr=0.02000\n",
      "Epoch  1250 | full Δ = 69.277587 | lr=0.02000\n",
      "Epoch  1300 | full Δ = 67.238395 | lr=0.02000\n",
      "Epoch 01300: lr plateau 0.020000->0.010000\n",
      "Epoch  1350 | full Δ = 55.250705 | lr=0.01000\n",
      "Epoch  1400 | full Δ = 59.111953 | lr=0.01000\n",
      "Epoch  1450 | full Δ = 56.292315 | lr=0.01000\n",
      "Epoch  1500 | full Δ = 57.012048 | lr=0.01000\n",
      "Epoch  1550 | full Δ = 55.975609 | lr=0.01000\n",
      "Epoch  1600 | full Δ = 57.841602 | lr=0.01000\n",
      "Epoch  1650 | full Δ = 57.416144 | lr=0.01000\n",
      "Epoch  1700 | full Δ = 58.439526 | lr=0.01000\n",
      "Epoch 01700: lr plateau 0.010000->0.005000\n",
      "Epoch  1750 | full Δ = 53.720618 | lr=0.00500\n",
      "Epoch  1800 | full Δ = 52.166426 | lr=0.00500\n",
      "Epoch  1850 | full Δ = 53.058538 | lr=0.00500\n",
      "Epoch  1900 | full Δ = 53.185634 | lr=0.00500\n",
      "Epoch  1950 | full Δ = 52.804163 | lr=0.00500\n",
      "Epoch 02000: lr milestone 0.005000->0.002500\n",
      "Epoch  2000 | full Δ = 53.025157 | lr=0.00250\n",
      "Epoch  2050 | full Δ = 51.045559 | lr=0.00250\n",
      "Epoch  2100 | full Δ = 50.877863 | lr=0.00250\n",
      "Epoch  2150 | full Δ = 50.762017 | lr=0.00250\n",
      "Epoch  2200 | full Δ = 51.277554 | lr=0.00250\n",
      "Epoch  2250 | full Δ = 51.187798 | lr=0.00250\n",
      "Epoch  2300 | full Δ = 51.360197 | lr=0.00250\n",
      "Epoch  2350 | full Δ = 50.927851 | lr=0.00250\n",
      "Epoch  2400 | full Δ = 50.956892 | lr=0.00250\n",
      "Epoch  2450 | full Δ = 51.159012 | lr=0.00250\n",
      "Epoch  2500 | full Δ = 50.887580 | lr=0.00250\n",
      "Epoch 02500: lr plateau 0.002500->0.001250\n",
      "Epoch  2550 | full Δ = 50.111704 | lr=0.00125\n",
      "Epoch  2600 | full Δ = 50.061789 | lr=0.00125\n",
      "Epoch  2650 | full Δ = 50.095906 | lr=0.00125\n",
      "Epoch  2700 | full Δ = 49.893329 | lr=0.00125\n",
      "Epoch  2750 | full Δ = 50.067037 | lr=0.00125\n",
      "Epoch  2800 | full Δ = 50.180212 | lr=0.00125\n",
      "Epoch  2850 | full Δ = 50.255111 | lr=0.00125\n",
      "Epoch  2900 | full Δ = 50.050147 | lr=0.00125\n",
      "Epoch  2950 | full Δ = 50.045803 | lr=0.00125\n",
      "Epoch  3000 | full Δ = 50.098544 | lr=0.00125\n",
      "    Runtime for 50% missing, replicate 2: 19.97 sec (0.33 min)\n",
      "    End-to-end runtime: 19.97 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 3...\n",
      "Initial robust Δ: 152.632863\n",
      "Epoch     1 | full Δ = 351.536512 | lr=0.04000\n",
      "Epoch    50 | full Δ = 84.171909 | lr=0.04000\n",
      "Epoch   100 | full Δ = 73.619143 | lr=0.04000\n",
      "Epoch   150 | full Δ = 76.228710 | lr=0.04000\n",
      "Epoch   200 | full Δ = 75.779724 | lr=0.04000\n",
      "Epoch   250 | full Δ = 74.315283 | lr=0.04000\n",
      "Epoch   300 | full Δ = 76.836688 | lr=0.04000\n",
      "Epoch   350 | full Δ = 74.613228 | lr=0.04000\n",
      "Epoch   400 | full Δ = 71.659702 | lr=0.04000\n",
      "Epoch   450 | full Δ = 68.205086 | lr=0.04000\n",
      "Epoch   500 | full Δ = 74.397511 | lr=0.04000\n",
      "Epoch   550 | full Δ = 72.128102 | lr=0.04000\n",
      "Epoch   600 | full Δ = 72.336597 | lr=0.04000\n",
      "Epoch   650 | full Δ = 74.494604 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch   700 | full Δ = 69.968875 | lr=0.02000\n",
      "Epoch   750 | full Δ = 57.667337 | lr=0.02000\n",
      "Epoch   800 | full Δ = 57.964349 | lr=0.02000\n",
      "Epoch   850 | full Δ = 60.443019 | lr=0.02000\n",
      "Epoch   900 | full Δ = 57.919033 | lr=0.02000\n",
      "Epoch   950 | full Δ = 59.973757 | lr=0.02000\n",
      "Epoch  1000 | full Δ = 60.988139 | lr=0.02000\n",
      "Epoch  1050 | full Δ = 59.253998 | lr=0.02000\n",
      "Epoch  1100 | full Δ = 57.063735 | lr=0.02000\n",
      "Epoch  1150 | full Δ = 58.570627 | lr=0.02000\n",
      "Epoch  1200 | full Δ = 60.462287 | lr=0.02000\n",
      "Epoch  1250 | full Δ = 56.516235 | lr=0.02000\n",
      "Epoch  1300 | full Δ = 61.175991 | lr=0.02000\n",
      "Epoch  1350 | full Δ = 56.556305 | lr=0.02000\n",
      "Epoch  1400 | full Δ = 58.140116 | lr=0.02000\n",
      "Epoch  1450 | full Δ = 57.150298 | lr=0.02000\n",
      "Epoch  1500 | full Δ = 57.822738 | lr=0.02000\n",
      "Epoch  1550 | full Δ = 56.377146 | lr=0.02000\n",
      "Epoch  1600 | full Δ = 58.918674 | lr=0.02000\n",
      "Epoch  1650 | full Δ = 58.504245 | lr=0.02000\n",
      "Epoch  1700 | full Δ = 60.532339 | lr=0.02000\n",
      "Epoch  1750 | full Δ = 57.513990 | lr=0.02000\n",
      "Epoch  1800 | full Δ = 60.958205 | lr=0.02000\n",
      "Epoch  1850 | full Δ = 58.946772 | lr=0.02000\n",
      "Epoch  1900 | full Δ = 56.727494 | lr=0.02000\n",
      "Epoch 01900: lr plateau 0.020000->0.010000\n",
      "Epoch  1950 | full Δ = 50.920647 | lr=0.01000\n",
      "Epoch 02000: lr milestone 0.010000->0.005000\n",
      "Epoch  2000 | full Δ = 51.641696 | lr=0.00500\n",
      "Epoch  2050 | full Δ = 47.972156 | lr=0.00500\n",
      "Epoch  2100 | full Δ = 48.373243 | lr=0.00500\n",
      "Epoch  2150 | full Δ = 47.686556 | lr=0.00500\n",
      "Epoch  2200 | full Δ = 47.949249 | lr=0.00500\n",
      "Epoch  2250 | full Δ = 48.471185 | lr=0.00500\n",
      "Epoch  2300 | full Δ = 48.041260 | lr=0.00500\n",
      "Epoch  2350 | full Δ = 47.965552 | lr=0.00500\n",
      "Epoch  2400 | full Δ = 47.870539 | lr=0.00500\n",
      "Epoch  2450 | full Δ = 48.264438 | lr=0.00500\n",
      "Epoch  2500 | full Δ = 48.254244 | lr=0.00500\n",
      "Epoch 02500: lr plateau 0.005000->0.002500\n",
      "Epoch  2550 | full Δ = 46.771697 | lr=0.00250\n",
      "Epoch  2600 | full Δ = 46.556610 | lr=0.00250\n",
      "Epoch  2650 | full Δ = 46.772139 | lr=0.00250\n",
      "Epoch  2700 | full Δ = 46.876323 | lr=0.00250\n",
      "Epoch  2750 | full Δ = 46.747272 | lr=0.00250\n",
      "Epoch  2800 | full Δ = 46.660823 | lr=0.00250\n",
      "Epoch  2850 | full Δ = 46.967203 | lr=0.00250\n",
      "Epoch  2900 | full Δ = 46.430385 | lr=0.00250\n",
      "Epoch  2950 | full Δ = 46.443852 | lr=0.00250\n",
      "Epoch  3000 | full Δ = 46.746620 | lr=0.00250\n",
      "    Runtime for 50% missing, replicate 3: 20.31 sec (0.34 min)\n",
      "    End-to-end runtime: 20.31 sec (0.34 min)\n",
      "\n",
      "  Processing 50% missing, replicate 4...\n",
      "Initial robust Δ: 223.673541\n",
      "Epoch     1 | full Δ = 248.564304 | lr=0.04000\n",
      "Epoch    50 | full Δ = 257.622527 | lr=0.04000\n",
      "Epoch   100 | full Δ = 148.435974 | lr=0.04000\n",
      "Epoch   150 | full Δ = 85.706488 | lr=0.04000\n",
      "Epoch   200 | full Δ = 68.530354 | lr=0.04000\n",
      "Epoch   250 | full Δ = 72.342427 | lr=0.04000\n",
      "Epoch   300 | full Δ = 66.937203 | lr=0.04000\n",
      "Epoch   350 | full Δ = 67.729061 | lr=0.04000\n",
      "Epoch   400 | full Δ = 73.749460 | lr=0.04000\n",
      "Epoch   450 | full Δ = 77.501025 | lr=0.04000\n",
      "Epoch   500 | full Δ = 72.246675 | lr=0.04000\n",
      "Epoch   550 | full Δ = 76.605659 | lr=0.04000\n",
      "Epoch   600 | full Δ = 75.673494 | lr=0.04000\n",
      "Epoch   650 | full Δ = 69.723385 | lr=0.04000\n",
      "Epoch 00650: lr plateau 0.040000->0.020000\n",
      "Epoch 00700: lr milestone 0.020000->0.010000\n",
      "Epoch   700 | full Δ = 56.288301 | lr=0.01000\n",
      "Epoch   750 | full Δ = 50.299844 | lr=0.01000\n",
      "Epoch   800 | full Δ = 49.200242 | lr=0.01000\n",
      "Epoch   850 | full Δ = 50.983081 | lr=0.01000\n",
      "Epoch   900 | full Δ = 50.796848 | lr=0.01000\n",
      "Epoch   950 | full Δ = 49.417393 | lr=0.01000\n",
      "Epoch  1000 | full Δ = 49.622760 | lr=0.01000\n",
      "Epoch  1050 | full Δ = 47.632289 | lr=0.01000\n",
      "Epoch  1100 | full Δ = 48.258378 | lr=0.01000\n",
      "Epoch  1150 | full Δ = 48.268178 | lr=0.01000\n",
      "Epoch  1200 | full Δ = 48.899516 | lr=0.01000\n",
      "Epoch  1250 | full Δ = 48.841980 | lr=0.01000\n",
      "Epoch  1300 | full Δ = 48.370125 | lr=0.01000\n",
      "Epoch  1350 | full Δ = 50.174577 | lr=0.01000\n",
      "Epoch  1400 | full Δ = 49.729116 | lr=0.01000\n",
      "Epoch 01400: lr plateau 0.010000->0.005000\n",
      "Epoch  1450 | full Δ = 46.422534 | lr=0.00500\n",
      "Epoch  1500 | full Δ = 45.299455 | lr=0.00500\n",
      "Epoch  1550 | full Δ = 45.866126 | lr=0.00500\n",
      "Epoch  1600 | full Δ = 46.005755 | lr=0.00500\n",
      "Epoch  1650 | full Δ = 46.362433 | lr=0.00500\n",
      "Epoch  1700 | full Δ = 45.311286 | lr=0.00500\n",
      "Epoch  1750 | full Δ = 46.167874 | lr=0.00500\n",
      "Epoch  1800 | full Δ = 46.643796 | lr=0.00500\n",
      "Epoch  1850 | full Δ = 45.757311 | lr=0.00500\n",
      "Epoch 01850: lr plateau 0.005000->0.002500\n",
      "Epoch  1900 | full Δ = 43.985483 | lr=0.00250\n",
      "Epoch  1950 | full Δ = 43.772644 | lr=0.00250\n",
      "Epoch 02000: lr milestone 0.002500->0.001250\n",
      "Epoch  2000 | full Δ = 44.251494 | lr=0.00125\n",
      "Epoch  2050 | full Δ = 42.848545 | lr=0.00125\n",
      "Epoch  2100 | full Δ = 42.737719 | lr=0.00125\n",
      "Epoch  2150 | full Δ = 42.966133 | lr=0.00125\n",
      "Epoch  2200 | full Δ = 42.920673 | lr=0.00125\n",
      "Epoch  2250 | full Δ = 42.895654 | lr=0.00125\n",
      "Epoch  2300 | full Δ = 42.811800 | lr=0.00125\n",
      "Epoch  2350 | full Δ = 42.941386 | lr=0.00125\n",
      "Epoch  2400 | full Δ = 43.038716 | lr=0.00125\n",
      "Epoch  2450 | full Δ = 42.788390 | lr=0.00125\n",
      "Epoch 02450: lr plateau 0.001250->0.000625\n",
      "Epoch  2500 | full Δ = 42.505510 | lr=0.00063\n",
      "Epoch  2550 | full Δ = 42.449936 | lr=0.00063\n",
      "Epoch  2600 | full Δ = 42.484233 | lr=0.00063\n",
      "Epoch  2650 | full Δ = 42.467877 | lr=0.00063\n",
      "Epoch  2700 | full Δ = 42.494634 | lr=0.00063\n",
      "Epoch  2750 | full Δ = 42.474264 | lr=0.00063\n",
      "Epoch  2800 | full Δ = 42.444439 | lr=0.00063\n",
      "Epoch  2850 | full Δ = 42.416795 | lr=0.00063\n",
      "Epoch  2900 | full Δ = 42.436500 | lr=0.00063\n",
      "Epoch  2950 | full Δ = 42.411994 | lr=0.00063\n",
      "Epoch  3000 | full Δ = 42.410310 | lr=0.00063\n",
      "    Runtime for 50% missing, replicate 4: 20.03 sec (0.33 min)\n",
      "    End-to-end runtime: 20.03 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 5...\n",
      "Initial robust Δ: 268.340100\n",
      "Epoch     1 | full Δ = 237.950093 | lr=0.04000\n",
      "Epoch    50 | full Δ = 103.137308 | lr=0.04000\n",
      "Epoch   100 | full Δ = 90.757203 | lr=0.04000\n",
      "Epoch   150 | full Δ = 77.892373 | lr=0.04000\n",
      "Epoch   200 | full Δ = 84.251226 | lr=0.04000\n",
      "Epoch   250 | full Δ = 83.829102 | lr=0.04000\n",
      "Epoch   300 | full Δ = 80.919863 | lr=0.04000\n",
      "Epoch   350 | full Δ = 86.344647 | lr=0.04000\n",
      "Epoch   400 | full Δ = 88.521604 | lr=0.04000\n",
      "Epoch   450 | full Δ = 82.951448 | lr=0.04000\n",
      "Epoch   500 | full Δ = 86.992377 | lr=0.04000\n",
      "Epoch 00500: lr plateau 0.040000->0.020000\n",
      "Epoch   550 | full Δ = 73.849748 | lr=0.02000\n",
      "Epoch   600 | full Δ = 71.245117 | lr=0.02000\n",
      "Epoch   650 | full Δ = 71.410471 | lr=0.02000\n",
      "Epoch 00700: lr milestone 0.020000->0.010000\n",
      "Epoch   700 | full Δ = 70.637008 | lr=0.01000\n",
      "Epoch   750 | full Δ = 64.308305 | lr=0.01000\n",
      "Epoch   800 | full Δ = 64.308142 | lr=0.01000\n",
      "Epoch   850 | full Δ = 62.509554 | lr=0.01000\n",
      "Epoch   900 | full Δ = 63.971368 | lr=0.01000\n",
      "Epoch   950 | full Δ = 63.531202 | lr=0.01000\n",
      "Epoch  1000 | full Δ = 63.771372 | lr=0.01000\n",
      "Epoch  1050 | full Δ = 63.261358 | lr=0.01000\n",
      "Epoch  1100 | full Δ = 63.826465 | lr=0.01000\n",
      "Epoch  1150 | full Δ = 65.294416 | lr=0.01000\n",
      "Epoch  1200 | full Δ = 63.529678 | lr=0.01000\n",
      "Epoch 01200: lr plateau 0.010000->0.005000\n",
      "Epoch  1250 | full Δ = 60.087707 | lr=0.00500\n",
      "Epoch  1300 | full Δ = 61.155198 | lr=0.00500\n",
      "Epoch  1350 | full Δ = 61.107120 | lr=0.00500\n",
      "Epoch  1400 | full Δ = 60.784933 | lr=0.00500\n",
      "Epoch  1450 | full Δ = 59.927172 | lr=0.00500\n",
      "Epoch  1500 | full Δ = 60.437871 | lr=0.00500\n",
      "Epoch  1550 | full Δ = 60.530034 | lr=0.00500\n",
      "Epoch  1600 | full Δ = 61.063862 | lr=0.00500\n",
      "Epoch  1650 | full Δ = 61.279254 | lr=0.00500\n",
      "Epoch  1700 | full Δ = 59.924201 | lr=0.00500\n",
      "Epoch  1750 | full Δ = 60.481893 | lr=0.00500\n",
      "Epoch  1800 | full Δ = 60.200859 | lr=0.00500\n",
      "Epoch  1850 | full Δ = 60.259237 | lr=0.00500\n",
      "Epoch  1900 | full Δ = 60.531321 | lr=0.00500\n",
      "Epoch  1950 | full Δ = 63.067002 | lr=0.00500\n",
      "Epoch 02000: lr milestone 0.005000->0.002500\n",
      "Epoch  2000 | full Δ = 60.435680 | lr=0.00250\n",
      "Epoch  2050 | full Δ = 58.822337 | lr=0.00250\n",
      "Epoch  2100 | full Δ = 58.827342 | lr=0.00250\n",
      "Epoch  2150 | full Δ = 59.080217 | lr=0.00250\n",
      "Epoch  2200 | full Δ = 58.498484 | lr=0.00250\n",
      "Epoch  2250 | full Δ = 59.199480 | lr=0.00250\n",
      "Epoch  2300 | full Δ = 58.931516 | lr=0.00250\n",
      "Epoch  2350 | full Δ = 59.257714 | lr=0.00250\n",
      "Epoch  2400 | full Δ = 59.047692 | lr=0.00250\n",
      "Epoch  2450 | full Δ = 59.030420 | lr=0.00250\n",
      "Epoch  2500 | full Δ = 59.085494 | lr=0.00250\n",
      "Epoch  2550 | full Δ = 59.198202 | lr=0.00250\n",
      "Epoch 02550: lr plateau 0.002500->0.001250\n",
      "Epoch  2600 | full Δ = 58.308518 | lr=0.00125\n",
      "Epoch  2650 | full Δ = 58.138654 | lr=0.00125\n",
      "Epoch  2700 | full Δ = 58.091029 | lr=0.00125\n",
      "Epoch  2750 | full Δ = 58.261663 | lr=0.00125\n",
      "Epoch  2800 | full Δ = 58.362259 | lr=0.00125\n",
      "Epoch  2850 | full Δ = 58.176359 | lr=0.00125\n",
      "Epoch  2900 | full Δ = 58.043473 | lr=0.00125\n",
      "Epoch  2950 | full Δ = 58.246829 | lr=0.00125\n",
      "Epoch  3000 | full Δ = 58.259437 | lr=0.00125\n",
      "    Runtime for 50% missing, replicate 5: 20.08 sec (0.33 min)\n",
      "    End-to-end runtime: 20.08 sec (0.33 min)\n",
      "\n",
      "  Processing 65% missing, replicate 1...\n",
      "Initial robust Δ: 164.923388\n",
      "Epoch     1 | full Δ = 293.114437 | lr=0.04000\n",
      "Epoch    50 | full Δ = 336.832716 | lr=0.04000\n",
      "Epoch   100 | full Δ = 82.578960 | lr=0.04000\n",
      "Epoch   150 | full Δ = 70.020412 | lr=0.04000\n",
      "Epoch   200 | full Δ = 72.038435 | lr=0.04000\n",
      "Epoch   250 | full Δ = 64.551585 | lr=0.04000\n",
      "Epoch   300 | full Δ = 68.168415 | lr=0.04000\n",
      "Epoch   350 | full Δ = 72.874485 | lr=0.04000\n",
      "Epoch   400 | full Δ = 68.703478 | lr=0.04000\n",
      "Epoch   450 | full Δ = 73.316511 | lr=0.04000\n",
      "Epoch   500 | full Δ = 73.231788 | lr=0.04000\n",
      "Epoch   550 | full Δ = 74.075652 | lr=0.04000\n",
      "Epoch   600 | full Δ = 66.630263 | lr=0.04000\n",
      "Epoch 00600: lr plateau 0.040000->0.020000\n",
      "Epoch   650 | full Δ = 46.014857 | lr=0.02000\n",
      "Epoch 00700: lr milestone 0.020000->0.010000\n",
      "Epoch   700 | full Δ = 48.149644 | lr=0.01000\n",
      "Epoch   750 | full Δ = 40.045724 | lr=0.01000\n",
      "Epoch   800 | full Δ = 41.043876 | lr=0.01000\n",
      "Epoch   850 | full Δ = 39.782906 | lr=0.01000\n",
      "Epoch   900 | full Δ = 39.508774 | lr=0.01000\n",
      "Epoch   950 | full Δ = 41.063169 | lr=0.01000\n",
      "Epoch  1000 | full Δ = 41.670195 | lr=0.01000\n",
      "Epoch  1050 | full Δ = 40.273477 | lr=0.01000\n",
      "Epoch  1100 | full Δ = 41.240387 | lr=0.01000\n",
      "Epoch  1150 | full Δ = 40.593913 | lr=0.01000\n",
      "Epoch  1200 | full Δ = 41.149928 | lr=0.01000\n",
      "Epoch  1250 | full Δ = 40.975688 | lr=0.01000\n",
      "Epoch 01250: lr plateau 0.010000->0.005000\n",
      "Epoch  1300 | full Δ = 35.856131 | lr=0.00500\n",
      "Epoch  1350 | full Δ = 36.859576 | lr=0.00500\n",
      "Epoch  1400 | full Δ = 36.276161 | lr=0.00500\n",
      "Epoch  1450 | full Δ = 35.323657 | lr=0.00500\n",
      "Epoch  1500 | full Δ = 35.261205 | lr=0.00500\n",
      "Epoch  1550 | full Δ = 35.264177 | lr=0.00500\n",
      "Epoch  1600 | full Δ = 34.958165 | lr=0.00500\n",
      "Epoch  1650 | full Δ = 35.701284 | lr=0.00500\n",
      "Epoch  1700 | full Δ = 36.079554 | lr=0.00500\n",
      "Epoch  1750 | full Δ = 35.272721 | lr=0.00500\n",
      "Epoch  1800 | full Δ = 35.576267 | lr=0.00500\n",
      "Epoch  1850 | full Δ = 35.908687 | lr=0.00500\n",
      "Epoch  1900 | full Δ = 35.018742 | lr=0.00500\n",
      "Epoch  1950 | full Δ = 36.122163 | lr=0.00500\n",
      "Epoch 01950: lr plateau 0.005000->0.002500\n",
      "Epoch 02000: lr milestone 0.002500->0.001250\n",
      "Epoch  2000 | full Δ = 33.046633 | lr=0.00125\n",
      "Epoch  2050 | full Δ = 31.961306 | lr=0.00125\n",
      "Epoch  2100 | full Δ = 31.923359 | lr=0.00125\n",
      "Epoch  2150 | full Δ = 32.177230 | lr=0.00125\n",
      "Epoch  2200 | full Δ = 32.227164 | lr=0.00125\n",
      "Epoch  2250 | full Δ = 32.016881 | lr=0.00125\n",
      "Epoch  2300 | full Δ = 32.286712 | lr=0.00125\n",
      "Epoch  2350 | full Δ = 32.107688 | lr=0.00125\n",
      "Epoch  2400 | full Δ = 32.034943 | lr=0.00125\n",
      "Epoch  2450 | full Δ = 31.939642 | lr=0.00125\n",
      "Epoch 02450: lr plateau 0.001250->0.000625\n",
      "Epoch  2500 | full Δ = 31.578151 | lr=0.00063\n",
      "Epoch  2550 | full Δ = 31.461098 | lr=0.00063\n",
      "Epoch  2600 | full Δ = 31.511569 | lr=0.00063\n",
      "Epoch  2650 | full Δ = 31.439066 | lr=0.00063\n",
      "Epoch  2700 | full Δ = 31.492932 | lr=0.00063\n",
      "Epoch  2750 | full Δ = 31.523315 | lr=0.00063\n",
      "Epoch  2800 | full Δ = 31.422146 | lr=0.00063\n",
      "Epoch  2850 | full Δ = 31.534462 | lr=0.00063\n",
      "Epoch  2900 | full Δ = 31.399402 | lr=0.00063\n",
      "Epoch  2950 | full Δ = 31.475213 | lr=0.00063\n",
      "Epoch  3000 | full Δ = 31.417033 | lr=0.00063\n",
      "    End-to-end runtime: 26.30 sec (0.44 min)\n",
      "\n",
      "  Processing 65% missing, replicate 2...\n",
      "Initial robust Δ: 112.219396\n",
      "Epoch     1 | full Δ = 360.654517 | lr=0.04000\n",
      "Epoch    50 | full Δ = 71.173432 | lr=0.04000\n",
      "Epoch   100 | full Δ = 54.910895 | lr=0.04000\n",
      "Epoch   150 | full Δ = 58.771525 | lr=0.04000\n",
      "Epoch   200 | full Δ = 56.303505 | lr=0.04000\n",
      "Epoch   250 | full Δ = 54.541516 | lr=0.04000\n",
      "Epoch   300 | full Δ = 58.837168 | lr=0.04000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 639\u001b[0m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mNote: Δ_normalized uses log scaling: δ_norm = log(1+δ)/log(101), then clipped to [0,1].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 455\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    452\u001b[0m t_all \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m D_hyb, info \u001b[38;5;241m=\u001b[39m \u001b[43mhyb_adam_um_impute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_inc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrip_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrip_all\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mntri\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mntri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m runtime_total \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m t_all\n\u001b[1;32m    458\u001b[0m runtime_50 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 315\u001b[0m, in \u001b[0;36mhyb_adam_um_impute\u001b[0;34m(D_in, trip_all, ntri, verbose)\u001b[0m\n\u001b[1;32m    312\u001b[0m f_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m xvec: objective_full(xvec)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# Central-diff gradient\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m g \u001b[38;5;241m=\u001b[39m \u001b[43mcentral_diff_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mH_CENTRAL_DIFF\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# Weight decay\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WEIGHT_DECAY \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 267\u001b[0m, in \u001b[0;36mcentral_diff_grad\u001b[0;34m(x, f, h)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39msize):\n\u001b[1;32m    266\u001b[0m     x[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h; f1 \u001b[38;5;241m=\u001b[39m f(x)\n\u001b[0;32m--> 267\u001b[0m     x[k] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mh; f2 \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m     x[k] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m h\n\u001b[1;32m    269\u001b[0m     g[k] \u001b[38;5;241m=\u001b[39m (f1 \u001b[38;5;241m-\u001b[39m f2) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mh)\n",
      "Cell \u001b[0;32mIn[4], line 312\u001b[0m, in \u001b[0;36mhyb_adam_um_impute.<locals>.<lambda>\u001b[0;34m(xvec)\u001b[0m\n\u001b[1;32m    309\u001b[0m t \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# FULL batch\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m f_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m xvec: \u001b[43mobjective_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxvec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# Central-diff gradient\u001b[39;00m\n\u001b[1;32m    315\u001b[0m g \u001b[38;5;241m=\u001b[39m central_diff_grad(x, f_batch, h\u001b[38;5;241m=\u001b[39mH_CENTRAL_DIFF)\n",
      "Cell \u001b[0;32mIn[4], line 289\u001b[0m, in \u001b[0;36mhyb_adam_um_impute.<locals>.objective_full\u001b[0;34m(xvec)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mobjective_full\u001b[39m(xvec: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m    288\u001b[0m     M \u001b[38;5;241m=\u001b[39m assemble_full(xvec)\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrobust_delta_sum_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_triplets\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 182\u001b[0m, in \u001b[0;36mrobust_delta_sum_numpy\u001b[0;34m(M, triplets)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrobust_delta_sum_numpy\u001b[39m(M: np\u001b[38;5;241m.\u001b[39mndarray, triplets: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mrobust_delta_per_triplet_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriplets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum())\n",
      "Cell \u001b[0;32mIn[4], line 173\u001b[0m, in \u001b[0;36mrobust_delta_per_triplet_numpy\u001b[0;34m(M, triplets)\u001b[0m\n\u001b[1;32m    171\u001b[0m cosA \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip((b\u001b[38;5;241m*\u001b[39mb \u001b[38;5;241m+\u001b[39m c\u001b[38;5;241m*\u001b[39mc \u001b[38;5;241m-\u001b[39m a\u001b[38;5;241m*\u001b[39ma) \u001b[38;5;241m/\u001b[39m denomA, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    172\u001b[0m cosB \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip((a\u001b[38;5;241m*\u001b[39ma \u001b[38;5;241m+\u001b[39m c\u001b[38;5;241m*\u001b[39mc \u001b[38;5;241m-\u001b[39m b\u001b[38;5;241m*\u001b[39mb) \u001b[38;5;241m/\u001b[39m denomB, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m--> 173\u001b[0m cosG \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdenomG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marccos(cosA); B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marccos(cosB); G \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marccos(cosG)\n\u001b[1;32m    175\u001b[0m Ang \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([A, B, G], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/_core/fromnumeric.py:2341\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, min, max, **kwargs)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mmax\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue:\n\u001b[1;32m   2338\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `min` or `max` keyword argument when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2339\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`a_min` and `a_max` are provided is forbidden.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/_core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/_core/_methods.py:101\u001b[0m, in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_clip\u001b[39m(a, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;66;03m# If min/max is a Python integer, deal with out-of-bound values here.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;66;03m# (This enforces NEP 50 rules as no value based promotion is done.)\u001b[39;00m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mmin\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(a\u001b[38;5;241m.\u001b[39mdtype)\u001b[38;5;241m.\u001b[39mmin:\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "STANDALONE Hyb-Adam-UM ALGORITHM ONLY — ALL MISSINGNESS × REPS, NJ*-STYLE OUTPUT TABLES\n",
    "\n",
    "Minimal-change rewrite of your \"Hyb-Adam-UM only (30% rep1)\" script so it matches the\n",
    "output style of the TreePrior code you posted:\n",
    "\n",
    "What this script does\n",
    "---------------------\n",
    "1) Load ORIGINAL full matrix, symmetrize & sanitize.\n",
    "2) Build & freeze ALL masked matrices for each missingness level × replicate:\n",
    "     - default: 30/50/65/85% × 5 reps  (match your TreePrior script)\n",
    "     - same seeding pattern: rng = RandomState(BASE_SEED + (rep-1))\n",
    "3) For each mask:\n",
    "     - Run Hyb-Adam-UM (your manual Adam, NumPy-only, central-diff grads on missing LT)\n",
    "     - Produce a COMPLETED matrix\n",
    "4) Save:\n",
    "     - All masked matrices to MASKED_DIR\n",
    "     - All completed matrices to COMPLETED_DIR\n",
    "     - Detailed results CSV (all masks)\n",
    "     - Summary mean±std CSV (by missingness)\n",
    "     - Numeric summary CSV\n",
    "     - Training-style delta table CSV (Original + each missingness mean±std)\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- I did NOT change the optimizer math (central diff + Adam). I only wrapped it in an\n",
    "  \"all masks\" driver and added the same table outputs as in the TreePrior script.\n",
    "- This NumPy central-diff implementation is extremely expensive for n=100; it is intended\n",
    "  for small matrices (e.g., 15×15). If you run n=100 with EPOCHS=30000 you will likely\n",
    "  wait a very long time.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, json, math, warnings, zipfile, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Set, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "from itertools import combinations\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- CONFIG -----------------------------\n",
    "# ============================================================\n",
    "\n",
    "# Data (align with your TreePrior script)\n",
    "ORIG_CANDIDATES = [\n",
    "    \"Result_NW_15x15.txt\",\n",
    "    \"/mnt/data/Result_NW_100x100.txt\",\n",
    "    \"Result_NW_15x15.txt\",\n",
    "    \"/mnt/data/Result_NW_15x15.txt\",\n",
    "]\n",
    "\n",
    "# Missingness × reps (align with your TreePrior script)\n",
    "MISSING_FRACS = (0.50, 0.65)\n",
    "REPS          = 5\n",
    "BASE_SEED     = 55\n",
    "\n",
    "# Output folders (NJ*-style)\n",
    "MASKED_DIR    = \"hyb_adam_um_missing_matrices\"\n",
    "COMPLETED_DIR = \"hyb_adam_um_completed_matrices\"\n",
    "\n",
    "# Preserve observed entries EXACTLY in the final output?\n",
    "# IMPORTANT: Your original hyb_adam_um_impute() reconstructs the whole matrix from\n",
    "# observed LT + optimized missing LT, so observed entries are preserved by construction.\n",
    "PRESERVE_OBSERVED = True\n",
    "\n",
    "# -----------------------\n",
    "# Training hyperparameters (keep your original defaults)\n",
    "# -----------------------\n",
    "EPOCHS              = 3000\n",
    "PRINT_EVERY         = 50\n",
    "LR_INIT             = 0.04\n",
    "WEIGHT_DECAY        = 0.0\n",
    "CLIP_GRAD_NORM      = 5.0\n",
    "H_CENTRAL_DIFF      = 5e-5\n",
    "BETA1               = 0.9\n",
    "BETA2               = 0.999\n",
    "ADAM_EPS            = 1e-8\n",
    "TRI_FRAC            = 1.0   # use ALL triplets\n",
    "SEED_HYB            = 42\n",
    "\n",
    "# LR schedule: earlier & also fixed milestones\n",
    "SCHED_PATIENCE_BLOCKS = 7    # with PRINT_EVERY=100 -> ~700 epochs\n",
    "LR_FACTOR             = 0.5\n",
    "LR_MIN                = 1e-4\n",
    "LR_MILESTONES         = [700, 2000]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- Loading & helpers -------------------\n",
    "# ============================================================\n",
    "\n",
    "MISSING_VAL = -1.0\n",
    "\n",
    "def load_matrix_with_candidates(cands):\n",
    "    for p in cands:\n",
    "        if os.path.exists(p):\n",
    "            M = np.loadtxt(p)\n",
    "            if np.nanmax(M) > 500:\n",
    "                M = M / 1000.0\n",
    "            return M, p\n",
    "    raise FileNotFoundError(f\"File not found. Tried: {cands}\")\n",
    "\n",
    "def symmetrize_full(D: np.ndarray) -> np.ndarray:\n",
    "    D = 0.5*(D + D.T)\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "def symmetrize_with_missing(D: np.ndarray) -> np.ndarray:\n",
    "    D = D.copy().astype(float)\n",
    "    n = D.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            a, b = D[i, j], D[j, i]\n",
    "            if a >= 0 and b >= 0: v = 0.5*(a+b)\n",
    "            elif a >= 0:         v = a\n",
    "            elif b >= 0:         v = b\n",
    "            else:                v = MISSING_VAL\n",
    "            D[i, j] = D[j, i] = v\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "def _finite_fill(v, fallback=1.0):\n",
    "    v = np.asarray(v)\n",
    "    if np.isfinite(v).any():\n",
    "        return float(np.nanmedian(v[np.isfinite(v)]))\n",
    "    return float(fallback)\n",
    "\n",
    "def sanitize_distance_matrix(D: np.ndarray, name: str=\"D\", force_nonneg: bool=True) -> np.ndarray:\n",
    "    \"\"\"Ensure finite, symmetric, optionally nonnegative, 0-diagonal matrix.\"\"\"\n",
    "    M = np.array(D, dtype=float)\n",
    "    n = M.shape[0]\n",
    "    neg = (M < 0); np.fill_diagonal(neg, False)\n",
    "    M[neg] = np.nan\n",
    "    off = ~np.eye(n, dtype=bool)\n",
    "    med = _finite_fill(M[off], fallback=1.0)\n",
    "    M = np.nan_to_num(M, nan=med, posinf=med, neginf=med)\n",
    "    q = np.quantile(M[off], 0.995)\n",
    "    if np.isfinite(q) and q > 0: M[off] = np.minimum(M[off], q)\n",
    "    M = 0.5*(M + M.T)\n",
    "    if force_nonneg: M = np.maximum(M, 0.0)\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "    if not np.isfinite(M).all():\n",
    "        raise ValueError(f\"{name} has non-finite entries after sanitize.\")\n",
    "    return M\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- Robust δ / Δ ------------------------\n",
    "# ============================================================\n",
    "\n",
    "OMEGA   = 2.0\n",
    "EPS_NUM = 1.0e-12\n",
    "\n",
    "def robust_delta_per_triplet_numpy(M: np.ndarray, triplets: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return δ(i,j,k) for each triplet; M must be symmetric, nonnegative, 0-diagonal.\"\"\"\n",
    "    i, j, k = triplets[:, 0], triplets[:, 1], triplets[:, 2]\n",
    "    a = M[i, j]; b = M[i, k]; c = M[j, k]\n",
    "    S = np.stack([a, b, c], axis=1)\n",
    "    S_sorted = -np.sort(-S, axis=1)\n",
    "    a, b, c = S_sorted[:, 0], S_sorted[:, 1], S_sorted[:, 2]\n",
    "    viol = a >= (b + c)\n",
    "    denom_v = np.maximum(b + c, EPS_NUM)\n",
    "    delta1 = np.maximum(a / denom_v, OMEGA)\n",
    "    denomA = np.maximum(2.0 * b * c, EPS_NUM)\n",
    "    denomB = np.maximum(2.0 * a * c, EPS_NUM)\n",
    "    denomG = np.maximum(2.0 * a * b, EPS_NUM)\n",
    "    cosA = np.clip((b*b + c*c - a*a) / denomA, -1.0, 1.0)\n",
    "    cosB = np.clip((a*a + c*c - b*b) / denomB, -1.0, 1.0)\n",
    "    cosG = np.clip((a*a + b*b - c*c) / denomG, -1.0, 1.0)\n",
    "    A = np.arccos(cosA); B = np.arccos(cosB); G = np.arccos(cosG)\n",
    "    Ang = np.stack([A, B, G], axis=1)\n",
    "    Ang_sorted = -np.sort(-Ang, axis=1)\n",
    "    A, B, G = Ang_sorted[:, 0], Ang_sorted[:, 1], Ang_sorted[:, 2]\n",
    "    delta2 = (A - B) / np.maximum(G, EPS_NUM)\n",
    "    return np.where(viol, delta1, delta2)\n",
    "\n",
    "def robust_delta_sum_numpy(M: np.ndarray, triplets: np.ndarray) -> float:\n",
    "    return float(robust_delta_per_triplet_numpy(M, triplets).sum())\n",
    "\n",
    "def compute_normalized_delta(M: np.ndarray, triplets: np.ndarray) -> float:\n",
    "    \"\"\"Log-compressed mean δ in [0,1] (clipped), using max_reasonable_delta=100.\"\"\"\n",
    "    delta_vals = robust_delta_per_triplet_numpy(M, triplets)\n",
    "    max_reasonable_delta = 100.0\n",
    "    delta_norm_vals = np.log1p(delta_vals) / np.log1p(max_reasonable_delta)\n",
    "    delta_norm_vals = np.clip(delta_norm_vals, 0.0, 1.0)\n",
    "    return float(np.mean(delta_norm_vals))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- RMSE helper -------------------------\n",
    "# ============================================================\n",
    "\n",
    "def rmse_on_lt(A: np.ndarray, B: np.ndarray) -> float:\n",
    "    n = A.shape[0]\n",
    "    i_lt, j_lt = np.tril_indices(n, k=-1)\n",
    "    diff = (A - B)[i_lt, j_lt]\n",
    "    return float(np.sqrt(np.mean(diff*diff)))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- Mask generation ---------------------\n",
    "# ============================================================\n",
    "\n",
    "def simulate_missing(D_full: np.ndarray, frac_missing: float, rng: np.random.RandomState):\n",
    "    \"\"\"Mask lower-triangle pairs to -1 (symmetrically) at given fraction.\"\"\"\n",
    "    n = D_full.shape[0]\n",
    "    lower = np.tril(np.ones((n,n), dtype=bool), k=-1)\n",
    "    I, J = np.where(lower); m = len(I)\n",
    "    drop = int(round(frac_missing*m))\n",
    "    keep = np.ones(m, dtype=bool)\n",
    "    if drop > 0:\n",
    "        keep[rng.choice(m, size=drop, replace=False)] = False\n",
    "    D_inc = D_full.copy().astype(float)\n",
    "    for idx in range(m):\n",
    "        i, j = I[idx], J[idx]\n",
    "        if not keep[idx]:\n",
    "            D_inc[i, j] = D_inc[j, i] = MISSING_VAL\n",
    "    np.fill_diagonal(D_inc, 0.0)\n",
    "    D_inc = symmetrize_with_missing(D_inc)\n",
    "    obs_mask = (D_inc >= 0)\n",
    "    np.fill_diagonal(obs_mask, True)\n",
    "    return D_inc, obs_mask\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ---------------- Hyb-Adam-UM (manual Adam) ------------------\n",
    "# ============================================================\n",
    "\n",
    "def setup_problem_for_hyb_adam(M_in: np.ndarray):\n",
    "    \"\"\"Prepare parameterization over missing lower-triangle entries.\"\"\"\n",
    "    n = M_in.shape[0]\n",
    "    lower_mask = np.tril(np.ones((n, n), dtype=bool), k=-1)\n",
    "    given_mask_lower   = lower_mask & (M_in >= 0.0)\n",
    "    missing_mask_lower = lower_mask & (M_in <  0.0)\n",
    "    given_pairs   = np.array(np.where(given_mask_lower)).T\n",
    "    missing_pairs = np.array(np.where(missing_mask_lower)).T\n",
    "    Ng = len(given_pairs)\n",
    "    given_vals = M_in[given_mask_lower].astype(np.float64)\n",
    "    init_val = float(np.mean(given_vals)) if Ng > 0 else 1.0\n",
    "    x = np.full((len(missing_pairs),), init_val, dtype=np.float64)\n",
    "    triplets = np.array(list(combinations(range(n), 3)), dtype=np.int32)\n",
    "\n",
    "    def assemble_full(xvec: np.ndarray) -> np.ndarray:\n",
    "        # Observed LT preserved EXACTLY because we copy given_vals to those LT positions.\n",
    "        M = np.zeros((n, n), dtype=np.float64)\n",
    "        if Ng > 0:\n",
    "            gi, gj = given_pairs[:, 0], given_pairs[:, 1]\n",
    "            M[gi, gj] = given_vals\n",
    "        if len(missing_pairs) > 0:\n",
    "            mi, mj = missing_pairs[:, 0], missing_pairs[:, 1]\n",
    "            M[mi, mj] = xvec\n",
    "        M = M + M.T\n",
    "        np.fill_diagonal(M, 0.0)\n",
    "        np.maximum(M, 0.0, out=M)\n",
    "        return M\n",
    "\n",
    "    return x, given_pairs, missing_pairs, given_vals, triplets, assemble_full\n",
    "\n",
    "def central_diff_grad(x: np.ndarray, f, h: float = H_CENTRAL_DIFF) -> np.ndarray:\n",
    "    g = np.zeros_like(x)\n",
    "    for k in range(x.size):\n",
    "        x[k] += h; f1 = f(x)\n",
    "        x[k] -= 2*h; f2 = f(x)\n",
    "        x[k] += h\n",
    "        g[k] = (f1 - f2) / (2*h)\n",
    "    return g\n",
    "\n",
    "def hyb_adam_um_impute(D_in: np.ndarray, trip_all: np.ndarray, ntri: int, verbose: bool=True) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Optimize missing LT with robust-Δ objective; FULL-BATCH so batch Δ == full Δ.\n",
    "    Returns (completed_matrix, train_info_dict).\n",
    "    \"\"\"\n",
    "    np.random.seed(SEED_HYB)\n",
    "\n",
    "    x, _, _, _, all_triplets, assemble_full = setup_problem_for_hyb_adam(D_in)\n",
    "    T = all_triplets.shape[0]\n",
    "\n",
    "    if x.size == 0:\n",
    "        M0 = assemble_full(x)\n",
    "        info = {\"skipped\": True, \"reason\": \"no missing pairs\", \"epochs\": 0}\n",
    "        return M0, info\n",
    "\n",
    "    def objective_full(xvec: np.ndarray) -> float:\n",
    "        M = assemble_full(xvec)\n",
    "        return robust_delta_sum_numpy(M, all_triplets)\n",
    "\n",
    "    # Initial\n",
    "    delta0_full = objective_full(x)\n",
    "    if verbose:\n",
    "        print(f\"Initial robust Δ: {delta0_full:.6f}\")\n",
    "\n",
    "    # Adam state\n",
    "    m = np.zeros_like(x); v = np.zeros_like(x); t = 0\n",
    "    lr = LR_INIT\n",
    "\n",
    "    # Scheduler state\n",
    "    best_full = float(\"inf\")\n",
    "    last_block_best = float(\"inf\")\n",
    "    no_improve_blocks = 0\n",
    "\n",
    "    best_x = x.copy()\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        t += 1\n",
    "\n",
    "        # FULL batch\n",
    "        f_batch = lambda xvec: objective_full(xvec)\n",
    "\n",
    "        # Central-diff gradient\n",
    "        g = central_diff_grad(x, f_batch, h=H_CENTRAL_DIFF)\n",
    "\n",
    "        # Weight decay\n",
    "        if WEIGHT_DECAY > 0.0:\n",
    "            g = g + WEIGHT_DECAY * x\n",
    "\n",
    "        # Gradient clipping\n",
    "        if CLIP_GRAD_NORM is not None:\n",
    "            g_norm = float(np.linalg.norm(g))\n",
    "            if g_norm > CLIP_GRAD_NORM and g_norm > 0:\n",
    "                g = g * (CLIP_GRAD_NORM / g_norm)\n",
    "\n",
    "        # Adam update\n",
    "        m = BETA1 * m + (1 - BETA1) * g\n",
    "        v = BETA2 * v + (1 - BETA2) * (g * g)\n",
    "        m_hat = m / (1 - (BETA1 ** t))\n",
    "        v_hat = v / (1 - (BETA2 ** t))\n",
    "        x -= lr * (m_hat / (np.sqrt(v_hat) + ADAM_EPS))\n",
    "        x = np.maximum(x, 0.0)\n",
    "\n",
    "        # Fixed epoch milestones\n",
    "        if epoch in LR_MILESTONES and lr > LR_MIN + 1e-12:\n",
    "            new_lr = max(LR_MIN, lr * LR_FACTOR)\n",
    "            if new_lr < lr - 1e-12 and verbose:\n",
    "                print(f\"Epoch {epoch:05d}: lr milestone {lr:.6f}->{new_lr:.6f}\")\n",
    "            lr = new_lr\n",
    "\n",
    "        # Logging + plateau schedule\n",
    "        if epoch % PRINT_EVERY == 0 or epoch == 1 or epoch == EPOCHS:\n",
    "            full_loss  = objective_full(x)\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch:5d} | full Δ = {full_loss:.6f} | lr={lr:.5f}\")\n",
    "\n",
    "            # plateau-based reduction\n",
    "            if full_loss < last_block_best - 1e-12:\n",
    "                no_improve_blocks = 0\n",
    "                last_block_best = full_loss\n",
    "            else:\n",
    "                no_improve_blocks += 1\n",
    "                if no_improve_blocks >= SCHED_PATIENCE_BLOCKS and lr > LR_MIN + 1e-12:\n",
    "                    new_lr = max(LR_MIN, lr * LR_FACTOR)\n",
    "                    if new_lr < lr - 1e-12 and verbose:\n",
    "                        print(f\"Epoch {epoch:05d}: lr plateau {lr:.6f}->{new_lr:.6f}\")\n",
    "                    lr = new_lr\n",
    "                    no_improve_blocks = 0\n",
    "\n",
    "        # Track best\n",
    "        full_loss_now = objective_full(x)\n",
    "        if full_loss_now < best_loss - 1e-12:\n",
    "            best_loss = full_loss_now\n",
    "            best_x = x.copy()\n",
    "\n",
    "        if full_loss_now < best_full - 1e-12:\n",
    "            best_full = full_loss_now\n",
    "\n",
    "    M_best = assemble_full(best_x)\n",
    "    M_best = 0.5*(M_best + M_best.T)\n",
    "    np.fill_diagonal(M_best, 0.0)\n",
    "    M_best = np.maximum(M_best, 0.0)\n",
    "\n",
    "    info = {\n",
    "        \"skipped\": False,\n",
    "        \"epochs\": int(EPOCHS),\n",
    "        \"final_lr\": float(lr),\n",
    "        \"best_obj\": float(best_loss),\n",
    "        \"missing_params\": int(best_x.size),\n",
    "    }\n",
    "    return M_best, info\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------- Tables helpers --------------------\n",
    "# ============================================================\n",
    "\n",
    "def fmt_pm(mean_val, std_val, decimals=6) -> str:\n",
    "    return f\"{mean_val:.{decimals}f} ± {std_val:.{decimals}f}\"\n",
    "\n",
    "def mean_std(x: np.ndarray) -> Tuple[float, float]:\n",
    "    m = float(np.mean(x))\n",
    "    s = float(np.std(x, ddof=1)) if len(x) > 1 else 0.0\n",
    "    return m, s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------- MAIN ------------------------------\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # Load ORIGINAL\n",
    "    D_orig, used_orig_path = load_matrix_with_candidates(ORIG_CANDIDATES)\n",
    "    D0 = sanitize_distance_matrix(symmetrize_full(D_orig), \"D_orig\")\n",
    "\n",
    "    n = D0.shape[0]\n",
    "    labels = [f\"T{i+1}\" for i in range(n)]\n",
    "    trip_all = np.array(list(combinations(range(n), 3)), dtype=np.int32)\n",
    "    ntri = n*(n-1)*(n-2)//6\n",
    "\n",
    "    # ORIGINAL Δ\n",
    "    print(\"=== Calculating Δ for original matrix ===\")\n",
    "    Δ_original = robust_delta_sum_numpy(D0, trip_all)\n",
    "    Δ_normalized_original = compute_normalized_delta(D0, trip_all)\n",
    "    print(f\"Original matrix file: {used_orig_path}\")\n",
    "    print(f\"Number of triplets (n choose 3) = {ntri}\")\n",
    "    print(f\"Original matrix Δ_total = {Δ_original:.6f}\")\n",
    "    print(f\"Original Δ_normalized = {Δ_normalized_original:.6f}\")\n",
    "    print(f\"Original Δ_per_triangle (Δ/ntri) = {Δ_original/ntri:.6f}\")\n",
    "    print()\n",
    "\n",
    "    # Build & freeze ALL masked matrices (same seed pattern as TreePrior)\n",
    "    masked_registry = []\n",
    "    for frac in MISSING_FRACS:\n",
    "        for r in range(1, REPS + 1):\n",
    "            rng = np.random.RandomState(BASE_SEED + (r - 1))\n",
    "            D_inc, obs_mask = simulate_missing(D0, frac, rng)\n",
    "            masked_registry.append({\"frac\": frac, \"rep\": r, \"D_inc\": D_inc, \"obs_mask\": obs_mask})\n",
    "\n",
    "    # Save all masked matrices\n",
    "    os.makedirs(MASKED_DIR, exist_ok=True)\n",
    "    for rec in masked_registry:\n",
    "        pct = int(round(100 * rec[\"frac\"]))\n",
    "        fn = f\"missing_p{pct}_rep{rec['rep']}.csv\"\n",
    "        pd.DataFrame(rec[\"D_inc\"], index=labels, columns=labels).to_csv(os.path.join(MASKED_DIR, fn))\n",
    "\n",
    "    # Run Hyb-Adam-UM on ALL masks\n",
    "    print(\"=== Running Hyb-Adam-UM on all masks ===\")\n",
    "    os.makedirs(COMPLETED_DIR, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    runtimes_50 = []\n",
    "\n",
    "    for rec in masked_registry:\n",
    "        frac = rec[\"frac\"]; rep = rec[\"rep\"]\n",
    "        D_inc = rec[\"D_inc\"]\n",
    "        pct = int(round(100 * frac))\n",
    "        print(f\"\\n  Processing {pct}% missing, replicate {rep}...\")\n",
    "\n",
    "        t0_50 = time.perf_counter() if abs(frac - 0.50) < 1e-12 else None\n",
    "        t_all = time.perf_counter()\n",
    "\n",
    "        # Train\n",
    "        D_hyb, info = hyb_adam_um_impute(D_inc, trip_all=trip_all, ntri=ntri, verbose=True)\n",
    "\n",
    "        runtime_total = time.perf_counter() - t_all\n",
    "        runtime_50 = None\n",
    "        if t0_50 is not None:\n",
    "            runtime_50 = time.perf_counter() - t0_50\n",
    "            runtimes_50.append(runtime_50)\n",
    "            print(f\"    Runtime for 50% missing, replicate {rep}: {runtime_50:.2f} sec ({runtime_50/60:.2f} min)\")\n",
    "        print(f\"    End-to-end runtime: {runtime_total:.2f} sec ({runtime_total/60:.2f} min)\")\n",
    "\n",
    "        # Sanitize (consistent with your earlier script)\n",
    "        D_hyb_san = sanitize_distance_matrix(D_hyb, f\"Hyb-Adam-UM_p{pct}_rep{rep}\")\n",
    "\n",
    "        # Metrics vs original\n",
    "        rmse_val = rmse_on_lt(D_hyb_san, D0)\n",
    "        Δ_total  = robust_delta_sum_numpy(D_hyb_san, trip_all)\n",
    "        Δ_norm   = compute_normalized_delta(D_hyb_san, trip_all)\n",
    "        Δ_per_triangle = Δ_total / ntri\n",
    "        Δ_relative = (Δ_total / Δ_original) if (Δ_original != 0) else float(\"nan\")\n",
    "\n",
    "        # Save completed matrix\n",
    "        out_fn = f\"HybAdamUM_completed_p{pct}_rep{rep}.csv\"\n",
    "        pd.DataFrame(D_hyb_san, index=labels, columns=labels).to_csv(os.path.join(COMPLETED_DIR, out_fn))\n",
    "\n",
    "        results.append({\n",
    "            \"pct_missing\": pct,\n",
    "            \"replicate\": rep,\n",
    "            \"RMSE_vs_ORIG\": rmse_val,\n",
    "            \"Δ_total\": Δ_total,\n",
    "            \"Δ_normalized\": Δ_norm,\n",
    "            \"Δ_per_triangle\": Δ_per_triangle,\n",
    "            \"Δ_relative\": Δ_relative,\n",
    "            \"runtime_seconds\": runtime_50,   # keep TreePrior convention: only filled for 50%\n",
    "            \"completed_file\": out_fn,\n",
    "            \"train_info\": str(info),\n",
    "        })\n",
    "\n",
    "    # runtime summary for 50%\n",
    "    if runtimes_50:\n",
    "        avg_runtime_50 = float(np.mean(runtimes_50))\n",
    "        min_runtime_50 = float(np.min(runtimes_50))\n",
    "        max_runtime_50 = float(np.max(runtimes_50))\n",
    "        print(\"\\n=== Runtime summary for 50% missing matrices ===\")\n",
    "        print(f\"Count: {len(runtimes_50)}\")\n",
    "        print(f\"Average: {avg_runtime_50:.2f} sec ({avg_runtime_50/60:.2f} min)\")\n",
    "        print(f\"Range:   {min_runtime_50:.2f} - {max_runtime_50:.2f} sec ({min_runtime_50/60:.2f} - {max_runtime_50/60:.2f} min)\")\n",
    "\n",
    "    # detailed results table\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== Hyb-Adam-UM results for all masks ===\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(results_df)\n",
    "    except Exception:\n",
    "        print(results_df.to_string(index=False))\n",
    "    results_df.to_csv(\"hyb_adam_um_all_masks_detailed.csv\", index=False)\n",
    "\n",
    "    # summary (mean ± std over reps per missingness)\n",
    "    summary_rows = []\n",
    "    for frac in MISSING_FRACS:\n",
    "        pct = int(round(100 * frac))\n",
    "        mask_results = results_df[results_df[\"pct_missing\"] == pct]\n",
    "\n",
    "        rmse_vals = mask_results[\"RMSE_vs_ORIG\"].astype(float).to_numpy()\n",
    "        dt_vals   = mask_results[\"Δ_total\"].astype(float).to_numpy()\n",
    "        dn_vals   = mask_results[\"Δ_normalized\"].astype(float).to_numpy()\n",
    "        dpt_vals  = mask_results[\"Δ_per_triangle\"].astype(float).to_numpy()\n",
    "        dr_vals   = mask_results[\"Δ_relative\"].astype(float).to_numpy()\n",
    "\n",
    "        rmse_m, rmse_s = mean_std(rmse_vals)\n",
    "        dt_m, dt_s     = mean_std(dt_vals)\n",
    "        dn_m, dn_s     = mean_std(dn_vals)\n",
    "        dpt_m, dpt_s   = mean_std(dpt_vals)\n",
    "        dr_m, dr_s     = mean_std(dr_vals)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"% Missing\": f\"{pct}%\",\n",
    "            \"RMSE_mean\": rmse_m, \"RMSE_std\": rmse_s,\n",
    "            \"Δ_total_mean\": dt_m, \"Δ_total_std\": dt_s,\n",
    "            \"Δ_normalized_mean\": dn_m, \"Δ_normalized_std\": dn_s,\n",
    "            \"Δ_per_triangle_mean\": dpt_m, \"Δ_per_triangle_std\": dpt_s,\n",
    "            \"Δ_relative_mean\": dr_m, \"Δ_relative_std\": dr_s\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    print(\"\\n=== Hyb-Adam-UM summary (mean ± std over replicates) ===\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(summary_df)\n",
    "    except Exception:\n",
    "        print(summary_df.to_string(index=False))\n",
    "\n",
    "    # formatted summary (NJ*-style)\n",
    "    formatted_summary_df = summary_df.copy()\n",
    "    formatted_summary_df[\"RMSE\"] = [\n",
    "        fmt_pm(row[\"RMSE_mean\"], row[\"RMSE_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ_total\"] = [\n",
    "        fmt_pm(row[\"Δ_total_mean\"], row[\"Δ_total_std\"], 4) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ_normalized\"] = [\n",
    "        fmt_pm(row[\"Δ_normalized_mean\"], row[\"Δ_normalized_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ̄ (per triangle)\"] = [\n",
    "        fmt_pm(row[\"Δ_per_triangle_mean\"], row[\"Δ_per_triangle_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ_relative (to original)\"] = [\n",
    "        fmt_pm(row[\"Δ_relative_mean\"], row[\"Δ_relative_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df = formatted_summary_df[\n",
    "        [\"% Missing\", \"RMSE\", \"Δ_total\", \"Δ_normalized\", \"Δ̄ (per triangle)\", \"Δ_relative (to original)\"]\n",
    "    ]\n",
    "\n",
    "    print(\"\\n=== Hyb-Adam-UM formatted summary ===\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(formatted_summary_df)\n",
    "    except Exception:\n",
    "        print(formatted_summary_df.to_string(index=False))\n",
    "\n",
    "    formatted_summary_df.to_csv(\"hyb_adam_um_summary_formatted.csv\", index=False)\n",
    "    pd.concat({\n",
    "        \"mean\": summary_df[[\"RMSE_mean\", \"Δ_total_mean\", \"Δ_normalized_mean\", \"Δ_per_triangle_mean\", \"Δ_relative_mean\"]],\n",
    "        \"std\":  summary_df[[\"RMSE_std\",  \"Δ_total_std\",  \"Δ_normalized_std\",  \"Δ_per_triangle_std\",  \"Δ_relative_std\"]]\n",
    "    }, axis=1).to_csv(\"hyb_adam_um_summary_numeric.csv\")\n",
    "\n",
    "    # training-style delta table (final matrices)\n",
    "    print(f\"\\n=== Delta Sum Table (training-style; COMPLETED matrices) for Hyb-Adam-UM ===\")\n",
    "    print(f\"Original Δ_total = {Δ_original:.6f}\")\n",
    "    print(f\"Original Δ_normalized = {Δ_normalized_original:.6f}\")\n",
    "    print(f\"Number of triangles = {ntri}\")\n",
    "    print(f\"Original Δ_per_triangle = {Δ_original/ntri:.6f}\")\n",
    "\n",
    "    delta_table_rows = [\n",
    "        {\"% Missing\": \"Original\",\n",
    "         \"Hyb-Adam-UM Δ_total\": f\"{Δ_original:.4f}\",\n",
    "         \"Δ_normalized\": f\"{Δ_normalized_original:.6f}\",\n",
    "         \"Δ̄ (per triangle)\": f\"{Δ_original/ntri:.6f}\",\n",
    "         \"Δ_relative (to original)\": \"1.0000\"}\n",
    "    ]\n",
    "\n",
    "    for frac in MISSING_FRACS:\n",
    "        pct = int(round(100 * frac))\n",
    "        mask_results = results_df[results_df[\"pct_missing\"] == pct]\n",
    "\n",
    "        dt_vals  = mask_results[\"Δ_total\"].astype(float).to_numpy()\n",
    "        dn_vals  = mask_results[\"Δ_normalized\"].astype(float).to_numpy()\n",
    "        dpt_vals = mask_results[\"Δ_per_triangle\"].astype(float).to_numpy()\n",
    "        dr_vals  = mask_results[\"Δ_relative\"].astype(float).to_numpy()\n",
    "\n",
    "        dt_m, dt_s   = mean_std(dt_vals)\n",
    "        dn_m, dn_s   = mean_std(dn_vals)\n",
    "        dpt_m, dpt_s = mean_std(dpt_vals)\n",
    "        dr_m, dr_s   = mean_std(dr_vals)\n",
    "\n",
    "        delta_table_rows.append({\n",
    "            \"% Missing\": f\"{pct}%\",\n",
    "            \"Hyb-Adam-UM Δ_total\": f\"{dt_m:.4f} ± {dt_s:.4f}\",\n",
    "            \"Δ_normalized\": f\"{dn_m:.6f} ± {dn_s:.6f}\",\n",
    "            \"Δ̄ (per triangle)\": f\"{dpt_m:.6f} ± {dpt_s:.6f}\",\n",
    "            \"Δ_relative (to original)\": f\"{dr_m:.4f} ± {dr_s:.4f}\"\n",
    "        })\n",
    "\n",
    "    delta_table_df = pd.DataFrame(delta_table_rows)\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(delta_table_df)\n",
    "    except Exception:\n",
    "        print(delta_table_df.to_string(index=False))\n",
    "\n",
    "    delta_table_df.to_csv(\"hyb_adam_um_delta_sum_training_style.csv\", index=False)\n",
    "\n",
    "    print(\"\\n=== ALL PROCESSING COMPLETE! ===\")\n",
    "    print(\"Output files:\")\n",
    "    print(f\"  - Masked matrices saved to: {MASKED_DIR}/\")\n",
    "    print(f\"  - Completed matrices saved to: {COMPLETED_DIR}/\")\n",
    "    print(\"  - Detailed results: hyb_adam_um_all_masks_detailed.csv\")\n",
    "    print(\"  - Formatted summary: hyb_adam_um_summary_formatted.csv\")\n",
    "    print(\"  - Numeric summary: hyb_adam_um_summary_numeric.csv\")\n",
    "    print(\"  - Training-style delta table: hyb_adam_um_delta_sum_training_style.csv\")\n",
    "    print(\"\\nNote: Δ_normalized uses log scaling: δ_norm = log(1+δ)/log(101), then clipped to [0,1].\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb86fb4-01c9-4d0c-a711-870869dc4f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 completed matrices in: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/hyb_adam_um_completed_matrices\n",
      "  p30 rep1: HybAdamUM_completed_p30_rep1.csv\n",
      "  p30 rep2: HybAdamUM_completed_p30_rep2.csv\n",
      "  p30 rep3: HybAdamUM_completed_p30_rep3.csv\n",
      "  p30 rep4: HybAdamUM_completed_p30_rep4.csv\n",
      "  p30 rep5: HybAdamUM_completed_p30_rep5.csv\n",
      "  p50 rep1: HybAdamUM_completed_p50_rep1.csv\n",
      "  p50 rep2: HybAdamUM_completed_p50_rep2.csv\n",
      "  p50 rep3: HybAdamUM_completed_p50_rep3.csv\n",
      "  p50 rep4: HybAdamUM_completed_p50_rep4.csv\n",
      "  p50 rep5: HybAdamUM_completed_p50_rep5.csv\n",
      "  ...\n",
      "\n",
      "Output directory: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/trees_hyb_adam_um_all\n",
      "\n",
      "Loading original matrix...\n",
      "  Original matrix loaded: Result_NW_15x15.txt\n",
      "  Original matrix shape:  (15, 15)\n",
      "\n",
      "Building NJ tree for original matrix...\n",
      "  Saved: tree_Original.png, tree_Original.newick\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep1.csv (p30, rep1)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p30_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep2.csv (p30, rep2)\n",
      "  Done: RF_norm = 0.333333 | saved -> tree_p30_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep3.csv (p30, rep3)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p30_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep4.csv (p30, rep4)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p30_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep5.csv (p30, rep5)\n",
      "  Done: RF_norm = 0.000000 | saved -> tree_p30_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep1.csv (p50, rep1)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p50_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep2.csv (p50, rep2)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p50_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep3.csv (p50, rep3)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p50_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep4.csv (p50, rep4)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p50_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep5.csv (p50, rep5)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p50_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep1.csv (p65, rep1)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p65_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep2.csv (p65, rep2)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p65_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep3.csv (p65, rep3)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p65_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep4.csv (p65, rep4)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p65_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep5.csv (p65, rep5)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p65_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep1.csv (p85, rep1)\n",
      "  Done: RF_norm = 0.833333 | saved -> tree_p85_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep2.csv (p85, rep2)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p85_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep3.csv (p85, rep3)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p85_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep4.csv (p85, rep4)\n",
      "  Done: RF_norm = 0.750000 | saved -> tree_p85_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep5.csv (p85, rep5)\n",
      "  Done: RF_norm = 1.000000 | saved -> tree_p85_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep1.csv (p90, rep1)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p90_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep2.csv (p90, rep2)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p90_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep3.csv (p90, rep3)\n",
      "  Done: RF_norm = 0.833333 | saved -> tree_p90_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep4.csv (p90, rep4)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p90_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep5.csv (p90, rep5)\n",
      "  Done: RF_norm = 1.000000 | saved -> tree_p90_rep5.png\n",
      "\n",
      "======================================================================\n",
      "Detailed Tree Benchmark Results (ALL)\n",
      "======================================================================\n",
      " pct_missing  replicate                             file  RF  RF_norm  n_splits  pat_MAE  pat_RMSE  pat_Pearson  pat_Spearman\n",
      "          30          1 HybAdamUM_completed_p30_rep1.csv  14 0.583333        12 0.003757  0.010976     0.952821      0.930717\n",
      "          30          2 HybAdamUM_completed_p30_rep2.csv   8 0.333333        12 0.003722  0.013130     0.933712      0.897533\n",
      "          30          3 HybAdamUM_completed_p30_rep3.csv  12 0.500000        12 0.003255  0.005278     0.990696      0.965758\n",
      "          30          4 HybAdamUM_completed_p30_rep4.csv  10 0.416667        12 0.003217  0.006648     0.982462      0.980790\n",
      "          30          5 HybAdamUM_completed_p30_rep5.csv   0 0.000000        12 0.000934  0.001220     0.999498      0.995791\n",
      "          50          1 HybAdamUM_completed_p50_rep1.csv  10 0.416667        12 0.004151  0.013484     0.927933      0.895604\n",
      "          50          2 HybAdamUM_completed_p50_rep2.csv  10 0.416667        12 0.005839  0.014267     0.923170      0.881122\n",
      "          50          3 HybAdamUM_completed_p50_rep3.csv  12 0.500000        12 0.004223  0.007756     0.984120      0.965011\n",
      "          50          4 HybAdamUM_completed_p50_rep4.csv  14 0.583333        12 0.005164  0.013934     0.924263      0.899160\n",
      "          50          5 HybAdamUM_completed_p50_rep5.csv  10 0.416667        12 0.002695  0.004079     0.994232      0.969718\n",
      "          65          1 HybAdamUM_completed_p65_rep1.csv  14 0.583333        12 0.006030  0.014315     0.924316      0.907858\n",
      "          65          2 HybAdamUM_completed_p65_rep2.csv  12 0.500000        12 0.010036  0.022512     0.804828      0.842515\n",
      "          65          3 HybAdamUM_completed_p65_rep3.csv  14 0.583333        12 0.004457  0.007528     0.984022      0.960937\n",
      "          65          4 HybAdamUM_completed_p65_rep4.csv  12 0.500000        12 0.006023  0.013614     0.931080      0.898787\n",
      "          65          5 HybAdamUM_completed_p65_rep5.csv  12 0.500000        12 0.008872  0.012481     0.959542      0.881039\n",
      "          85          1 HybAdamUM_completed_p85_rep1.csv  20 0.833333        12 0.023484  0.040490     0.319375      0.291675\n",
      "          85          2 HybAdamUM_completed_p85_rep2.csv  22 0.916667        12 0.026145  0.042519     0.246836      0.214400\n",
      "          85          3 HybAdamUM_completed_p85_rep3.csv  22 0.916667        12 0.024687  0.041485     0.337793      0.244360\n",
      "          85          4 HybAdamUM_completed_p85_rep4.csv  18 0.750000        12 0.020120  0.034220     0.518634      0.497844\n",
      "          85          5 HybAdamUM_completed_p85_rep5.csv  24 1.000000        12 0.018676  0.033334     0.564808      0.586440\n",
      "          90          1 HybAdamUM_completed_p90_rep1.csv  22 0.916667        12 0.043357  0.047536     0.329062      0.140711\n",
      "          90          2 HybAdamUM_completed_p90_rep2.csv  22 0.916667        12 0.030061  0.046854     0.128818      0.411341\n",
      "          90          3 HybAdamUM_completed_p90_rep3.csv  20 0.833333        12 0.041863  0.044637     0.342753      0.288451\n",
      "          90          4 HybAdamUM_completed_p90_rep4.csv  22 0.916667        12 0.057522  0.066526     0.017742      0.020143\n",
      "          90          5 HybAdamUM_completed_p90_rep5.csv  24 1.000000        12 0.042865  0.054285     0.214867      0.333392\n",
      "\n",
      "======================================================================\n",
      "Detailed Matrix Benchmark Results (ALL)\n",
      "======================================================================\n",
      " pct_missing  replicate                             file  mat_MAE  mat_RMSE  mat_Pearson  mat_Spearman\n",
      "          30          1 HybAdamUM_completed_p30_rep1.csv 0.002543  0.011035     0.951756      0.952404\n",
      "          30          2 HybAdamUM_completed_p30_rep2.csv 0.003397  0.013289     0.931174      0.896230\n",
      "          30          3 HybAdamUM_completed_p30_rep3.csv 0.001625  0.004645     0.992249      0.979296\n",
      "          30          4 HybAdamUM_completed_p30_rep4.csv 0.002054  0.006316     0.984019      0.983834\n",
      "          30          5 HybAdamUM_completed_p30_rep5.csv 0.000822  0.002205     0.998132      0.986406\n",
      "          50          1 HybAdamUM_completed_p50_rep1.csv 0.003823  0.013535     0.926405      0.878571\n",
      "          50          2 HybAdamUM_completed_p50_rep2.csv 0.005118  0.014419     0.919915      0.888097\n",
      "          50          3 HybAdamUM_completed_p50_rep3.csv 0.003360  0.008292     0.978682      0.970336\n",
      "          50          4 HybAdamUM_completed_p50_rep4.csv 0.004596  0.014044     0.921897      0.886588\n",
      "          50          5 HybAdamUM_completed_p50_rep5.csv 0.002148  0.004616     0.991820      0.956578\n",
      "          65          1 HybAdamUM_completed_p65_rep1.csv 0.005598  0.014495     0.919831      0.885980\n",
      "          65          2 HybAdamUM_completed_p65_rep2.csv 0.009389  0.022682     0.798165      0.823929\n",
      "          65          3 HybAdamUM_completed_p65_rep3.csv 0.003694  0.008072     0.979562      0.957861\n",
      "          65          4 HybAdamUM_completed_p65_rep4.csv 0.005514  0.013864     0.926005      0.882216\n",
      "          65          5 HybAdamUM_completed_p65_rep5.csv 0.007713  0.036386     0.718468      0.934200\n",
      "          85          1 HybAdamUM_completed_p85_rep1.csv 0.022957  0.040384     0.316774      0.310895\n",
      "          85          2 HybAdamUM_completed_p85_rep2.csv 0.025665  0.042554     0.235280      0.175983\n",
      "          85          3 HybAdamUM_completed_p85_rep3.csv 0.024105  0.041562     0.330834      0.282587\n",
      "          85          4 HybAdamUM_completed_p85_rep4.csv 0.019788  0.034707     0.490339      0.466859\n",
      "          85          5 HybAdamUM_completed_p85_rep5.csv 0.017873  0.033046     0.569134      0.623642\n",
      "          90          1 HybAdamUM_completed_p90_rep1.csv 0.043303  0.048874     0.244462      0.332857\n",
      "          90          2 HybAdamUM_completed_p90_rep2.csv 0.029338  0.046747     0.127467      0.393132\n",
      "          90          3 HybAdamUM_completed_p90_rep3.csv 0.040226  0.045360     0.300709      0.285424\n",
      "          90          4 HybAdamUM_completed_p90_rep4.csv 0.056821  0.066633     0.105568      0.026062\n",
      "          90          5 HybAdamUM_completed_p90_rep5.csv 0.043839  0.055265     0.215781      0.332273\n",
      "\n",
      "======================================================================\n",
      "Tree metrics: mean ± SD by missingness\n",
      "======================================================================\n",
      " pct_missing                   RF             RF_norm             pat_MAE            pat_RMSE         pat_Pearson        pat_Spearman\n",
      "          30  8.800000 ± 5.403702 0.366667 ± 0.225154 0.002977 ± 0.001169 0.007451 ± 0.004714 0.971838 ± 0.027608 0.954118 ± 0.039790\n",
      "          50 11.200000 ± 1.788854 0.466667 ± 0.074536 0.004414 ± 0.001189 0.010704 ± 0.004567 0.950744 ± 0.035310 0.922123 ± 0.041882\n",
      "          65 12.800000 ± 1.095445 0.533333 ± 0.045644 0.007083 ± 0.002294 0.014090 ± 0.005405 0.920758 ± 0.069039 0.898227 ± 0.043084\n",
      "          85 21.200000 ± 2.280351 0.883333 ± 0.095015 0.022622 ± 0.003132 0.038409 ± 0.004301 0.397489 ± 0.136961 0.366944 ± 0.165284\n",
      "          90 22.000000 ± 1.414214 0.916667 ± 0.058926 0.043134 ± 0.009742 0.051968 ± 0.008900 0.206648 ± 0.137223 0.238808 ± 0.157016\n",
      "\n",
      "======================================================================\n",
      "Matrix metrics: mean ± SD by missingness\n",
      "======================================================================\n",
      " pct_missing             mat_MAE            mat_RMSE         mat_Pearson        mat_Spearman\n",
      "          30 0.002088 ± 0.000967 0.007498 ± 0.004572 0.971466 ± 0.028777 0.959634 ± 0.037952\n",
      "          50 0.003809 ± 0.001151 0.010981 ± 0.004344 0.947744 ± 0.034633 0.916034 ± 0.043713\n",
      "          65 0.006382 ± 0.002203 0.019100 ± 0.010976 0.868406 ± 0.106926 0.896837 ± 0.051882\n",
      "          85 0.022078 ± 0.003189 0.038451 ± 0.004286 0.388472 ± 0.136882 0.371993 ± 0.174981\n",
      "          90 0.042705 ± 0.009820 0.052576 ± 0.008726 0.198797 ± 0.081455 0.273950 ± 0.143750\n",
      "\n",
      "Saved heatmap grid: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/trees_hyb_adam_um_all/heatmap_grid_original_plus_all.png\n",
      "\n",
      "======================================================================\n",
      "ALL PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "Output directory: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/trees_hyb_adam_um_all\n",
      "\n",
      "Saved:\n",
      "  - Trees: 1 Original + 25 completed PNGs + Newicks\n",
      "  - Detailed CSVs: benchmark_tree_all.csv, benchmark_matrix_all.csv\n",
      "  - Mean±SD CSVs:  benchmark_tree_by_missingness_meanstd.csv, benchmark_matrix_by_missingness_meanstd.csv\n",
      "  - Heatmap grid: heatmap_grid_original_plus_all.png\n"
     ]
    }
   ],
   "source": [
    "# Cell — PICTURES OF TREES + HEATMAPS (ALL masks) for Hyb-Adam-UM (NO TreePrior)\n",
    "#\n",
    "# Compatible with the \"Hyb-Adam-UM only — all missingness × reps\" script above.\n",
    "#\n",
    "# What this does:\n",
    "#   • Auto-finds ALL completed matrices produced by that script:\n",
    "#       HybAdamUM_completed_p{30,50,65,85}_rep{1..5}.csv   (default 20 files)\n",
    "#   • Loads ORIGINAL matrix\n",
    "#   • Builds NJ tree for Original (once)\n",
    "#   • Builds NJ trees for ALL completed matrices\n",
    "#   • Saves:\n",
    "#       - tree PNGs + Newicks (Original + all completed)\n",
    "#       - benchmark CSVs (tree + matrix), detailed + mean±std by missingness\n",
    "#       - heatmap grid PNG (Original + all completed; auto grid size)\n",
    "#\n",
    "# Output folder (single directory, minimal files by default):\n",
    "#   trees_hyb_adam_um_all/\n",
    "#     tree_Original.png\n",
    "#     tree_Original.newick\n",
    "#     tree_p30_rep1.png, tree_p30_rep1.newick, ... (all found)\n",
    "#     benchmark_tree_all.csv\n",
    "#     benchmark_matrix_all.csv\n",
    "#     benchmark_tree_by_missingness_meanstd.csv\n",
    "#     benchmark_matrix_by_missingness_meanstd.csv\n",
    "#     heatmap_grid_original_plus_all.png\n",
    "#\n",
    "# Notes:\n",
    "#   • Heatmap = plt.imshow(matrix), saved as PNG.\n",
    "#   • Grid size is automatic (works for 16, 20, etc).\n",
    "#   • This NJ implementation is a simple nonnegative NJ for visualization/benchmarking.\n",
    "#     It is NOT NJ* for incomplete matrices (we are reading COMPLETED matrices).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================\n",
    "# -------------------------- CONFIG ---------------------------\n",
    "# ============================================================\n",
    "\n",
    "COMPLETED_DIR = \"hyb_adam_um_completed_matrices\"   # from the code above\n",
    "OUT_DIR       = \"trees_hyb_adam_um_all\"\n",
    "\n",
    "# Original matrix candidates (edit if needed)\n",
    "ORIG_CANDIDATES = [\n",
    "    \"Result_NW_15x15.txt\",\n",
    "    \"./Result_NW_15x15.txt\",\n",
    "    \"/mnt/data/Result_NW_15x15.txt\",\n",
    "    \"Result_NW_100x100.txt\",\n",
    "    \"./Result_NW_100x100.txt\",\n",
    "    \"/mnt/data/Result_NW_100x100.txt\",\n",
    "    \"ta41_orig.txt\",\n",
    "    \"./ta41_orig.txt\",\n",
    "    \"/mnt/data/ta41_orig.txt\",\n",
    "]\n",
    "\n",
    "# Heatmap options (keep minimal by default)\n",
    "SAVE_HEATMAP_GRID          = True\n",
    "SAVE_INDIVIDUAL_HEATMAPS   = False   # if True: saves (1 + N) PNGs\n",
    "SAVE_PATRISTIC_HEATMAPS    = False   # if True: saves patristic grid too\n",
    "SHOW_PLOTS_INLINE          = False\n",
    "\n",
    "HEATMAP_CMAP = \"viridis\"\n",
    "HEATMAP_DPI  = 220\n",
    "TREE_DPI     = 180\n",
    "\n",
    "# If your completed folder contains extra files, you can limit to first K\n",
    "MAX_COMPLETED_TO_PROCESS = None   # e.g. 15, 20, or None for all found\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- IO HELPERS --------------------------\n",
    "# ============================================================\n",
    "\n",
    "def load_matrix_with_candidates(cands: List[str]) -> Tuple[np.ndarray, str]:\n",
    "    for p in cands:\n",
    "        if os.path.exists(p):\n",
    "            M = np.loadtxt(p)\n",
    "            # heuristic: if distances are in ~1000s, rescale to ~units\n",
    "            if np.nanmax(M) > 500:\n",
    "                M = M / 1000.0\n",
    "            return M, p\n",
    "    raise FileNotFoundError(f\"File not found. Tried: {cands}\")\n",
    "\n",
    "def load_completed_csv(path_csv: str) -> Tuple[np.ndarray, List[str]]:\n",
    "    if not os.path.exists(path_csv):\n",
    "        raise FileNotFoundError(path_csv)\n",
    "    df = pd.read_csv(path_csv, index_col=0)\n",
    "    labels = list(df.columns)\n",
    "    return df.values.astype(float), labels\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- SANITIZATION ------------------------\n",
    "# ============================================================\n",
    "\n",
    "def _finite_fill(v, fallback: float = 1.0) -> float:\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    vv = v[np.isfinite(v)]\n",
    "    if vv.size > 0:\n",
    "        return float(np.nanmedian(vv))\n",
    "    return float(fallback)\n",
    "\n",
    "def sanitize_distance_matrix(D: np.ndarray, name: str = \"D\", force_nonneg: bool = True) -> np.ndarray:\n",
    "    M = np.array(D, dtype=float)\n",
    "    if M.ndim != 2 or M.shape[0] != M.shape[1]:\n",
    "        raise ValueError(f\"{name} must be square. Got {M.shape}.\")\n",
    "    n = M.shape[0]\n",
    "\n",
    "    neg = (M < 0)\n",
    "    np.fill_diagonal(neg, False)\n",
    "    M[neg] = np.nan\n",
    "\n",
    "    off = ~np.eye(n, dtype=bool)\n",
    "    med = _finite_fill(M[off], fallback=1.0)\n",
    "    M = np.nan_to_num(M, nan=med, posinf=med, neginf=med)\n",
    "\n",
    "    try:\n",
    "        q = np.quantile(M[off], 0.995)\n",
    "    except Exception:\n",
    "        q = np.nan\n",
    "    if np.isfinite(q) and q > 0:\n",
    "        M[off] = np.minimum(M[off], q)\n",
    "\n",
    "    M = 0.5 * (M + M.T)\n",
    "    if force_nonneg:\n",
    "        M = np.maximum(M, 0.0)\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "\n",
    "    if not np.isfinite(M).all():\n",
    "        raise ValueError(f\"{name} has non-finite entries after sanitize.\")\n",
    "    return M\n",
    "\n",
    "# ============================================================\n",
    "# -------------------------- NJ TREE --------------------------\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class NJTree:\n",
    "    newick: str\n",
    "    patristic: np.ndarray\n",
    "    splits: Set[frozenset]\n",
    "    adj: Dict[int, Dict[int, float]]\n",
    "    root: int\n",
    "\n",
    "def neighbor_joining_nonneg(D_full: np.ndarray, labels: List[str]) -> NJTree:\n",
    "    D = sanitize_distance_matrix(D_full, \"NJ_input\", force_nonneg=True)\n",
    "    n = len(labels)\n",
    "    if D.shape != (n, n):\n",
    "        raise ValueError(f\"D shape {D.shape} != (n,n) with n={n}\")\n",
    "\n",
    "    adj: Dict[int, Dict[int, float]] = {}\n",
    "\n",
    "    def add_edge(u: int, v: int, w: float):\n",
    "        w = float(max(w, 1e-9))\n",
    "        adj.setdefault(u, {})\n",
    "        adj.setdefault(v, {})\n",
    "        adj[u][v] = w\n",
    "        adj[v][u] = w\n",
    "\n",
    "    next_id = n\n",
    "    idx2node = {i: i for i in range(n)}\n",
    "    act = list(range(n))\n",
    "    Dv = D.copy()\n",
    "\n",
    "    while len(act) > 2:\n",
    "        m = len(act)\n",
    "        r = np.sum(Dv, axis=1)\n",
    "        r = np.nan_to_num(r, nan=_finite_fill(r, 1.0), posinf=_finite_fill(r, 1.0), neginf=_finite_fill(r, 1.0))\n",
    "\n",
    "        Q = (m - 2) * Dv - r[:, None] - r[None, :]\n",
    "        Q = np.nan_to_num(Q, nan=np.inf, posinf=np.inf, neginf=np.inf)\n",
    "        np.fill_diagonal(Q, np.inf)\n",
    "\n",
    "        if not np.isfinite(Q).any():\n",
    "            Q = Dv.copy()\n",
    "            np.fill_diagonal(Q, np.inf)\n",
    "\n",
    "        a_idx, b_idx = np.unravel_index(np.argmin(Q), Q.shape)\n",
    "        if a_idx > b_idx:\n",
    "            a_idx, b_idx = b_idx, a_idx\n",
    "\n",
    "        i, j = act[a_idx], act[b_idx]\n",
    "        dij = float(Dv[a_idx, b_idx])\n",
    "\n",
    "        li = 0.5 * dij + (r[a_idx] - r[b_idx]) / (2 * (m - 2))\n",
    "        lj = dij - li\n",
    "        if not np.isfinite(li): li = 0.5 * dij\n",
    "        if not np.isfinite(lj): lj = 0.5 * dij\n",
    "\n",
    "        u = next_id\n",
    "        next_id += 1\n",
    "\n",
    "        add_edge(u, idx2node[i], li)\n",
    "        add_edge(u, idx2node[j], lj)\n",
    "\n",
    "        duk = {}\n",
    "        for k in range(m):\n",
    "            if k in (a_idx, b_idx):\n",
    "                continue\n",
    "            val = 0.5 * (Dv[a_idx, k] + Dv[b_idx, k] - dij)\n",
    "            if not np.isfinite(val):\n",
    "                val = _finite_fill([Dv[a_idx, k], Dv[b_idx, k], dij], fallback=0.0)\n",
    "            duk[k] = float(val)\n",
    "\n",
    "        mask = np.ones(m, dtype=bool)\n",
    "        mask[b_idx] = False\n",
    "        Dv = Dv[np.ix_(mask, mask)]\n",
    "\n",
    "        new_a = a_idx\n",
    "        for t in range(m - 1):\n",
    "            if t == new_a:\n",
    "                Dv[new_a, t] = 0.0\n",
    "                continue\n",
    "            old_t = t if t < b_idx else t + 1\n",
    "            Dv[new_a, t] = Dv[t, new_a] = duk.get(old_t, 0.0)\n",
    "\n",
    "        Dv = np.maximum(0.5 * (Dv + Dv.T), 0.0)\n",
    "        np.fill_diagonal(Dv, 0.0)\n",
    "\n",
    "        idx2node[i] = u\n",
    "        act.pop(b_idx)\n",
    "\n",
    "    i, j = act[0], act[1]\n",
    "    add_edge(idx2node[i], idx2node[j], float(Dv[0, 1]))\n",
    "    root = idx2node[i]\n",
    "\n",
    "    def to_newick(x: int, parent: int = -1) -> str:\n",
    "        if x < n:\n",
    "            return labels[x]\n",
    "        parts = []\n",
    "        for v, w in adj.get(x, {}).items():\n",
    "            if v == parent:\n",
    "                continue\n",
    "            parts.append(f\"{to_newick(v, x)}:{w:.6f}\")\n",
    "        return \"(\" + \",\".join(parts) + \")\"\n",
    "\n",
    "    newick = to_newick(root) + \";\"\n",
    "\n",
    "    def path_len(a: int, b: int) -> float:\n",
    "        stack = [(a, -1, 0.0)]\n",
    "        seen = set()\n",
    "        while stack:\n",
    "            x, p, acc = stack.pop()\n",
    "            if x == b:\n",
    "                return acc\n",
    "            seen.add(x)\n",
    "            for y, w in adj.get(x, {}).items():\n",
    "                if y == p or y in seen:\n",
    "                    continue\n",
    "                stack.append((y, x, acc + w))\n",
    "        return np.nan\n",
    "\n",
    "    P = np.zeros((n, n), dtype=float)\n",
    "    for a in range(n):\n",
    "        for b in range(a + 1, n):\n",
    "            d = path_len(a, b)\n",
    "            P[a, b] = P[b, a] = d\n",
    "\n",
    "    def compute_splits() -> Set[frozenset]:\n",
    "        splits = set()\n",
    "        seen_edges = set()\n",
    "        for u in adj:\n",
    "            for v in adj[u]:\n",
    "                if (v, u) in seen_edges:\n",
    "                    continue\n",
    "                seen_edges.add((u, v))\n",
    "\n",
    "                stack = [u]\n",
    "                blocked = v\n",
    "                visited = set([blocked])\n",
    "                leafset = set()\n",
    "\n",
    "                while stack:\n",
    "                    x = stack.pop()\n",
    "                    if x in visited:\n",
    "                        continue\n",
    "                    visited.add(x)\n",
    "                    if x < n:\n",
    "                        leafset.add(labels[x])\n",
    "                    for y in adj.get(x, {}):\n",
    "                        if y not in visited:\n",
    "                            stack.append(y)\n",
    "\n",
    "                if 1 < len(leafset) < n - 1:\n",
    "                    splits.add(frozenset(sorted(leafset)))\n",
    "        return splits\n",
    "\n",
    "    return NJTree(newick=newick, patristic=P, splits=compute_splits(), adj=adj, root=root)\n",
    "\n",
    "# ============================================================\n",
    "# ---------------------- TREE DRAWING -------------------------\n",
    "# ============================================================\n",
    "\n",
    "def draw_nj_tree(nj: NJTree, labels: List[str], title: str, out_path: str, dpi: int = 160):\n",
    "    n = len(labels)\n",
    "    x_pos = {i: i for i in range(n)}\n",
    "    y_pos: Dict[int, float] = {}\n",
    "\n",
    "    def dfs(u: int, p: int = -1, y: float = 0.0):\n",
    "        y_pos[u] = -y\n",
    "        for v, w in nj.adj.get(u, {}).items():\n",
    "            if v == p:\n",
    "                continue\n",
    "            dfs(v, u, y + w)\n",
    "\n",
    "    dfs(nj.root, -1, 0.0)\n",
    "\n",
    "    def leaf_span(node: int) -> float:\n",
    "        if node < n:\n",
    "            return float(x_pos[node])\n",
    "        seen = set()\n",
    "        stack = [node]\n",
    "        leaves = []\n",
    "        while stack:\n",
    "            x = stack.pop()\n",
    "            if x in seen:\n",
    "                continue\n",
    "            seen.add(x)\n",
    "            if x < n:\n",
    "                leaves.append(x_pos[x])\n",
    "            else:\n",
    "                for y in nj.adj.get(x, {}):\n",
    "                    if y not in seen:\n",
    "                        stack.append(y)\n",
    "        return float(np.mean(leaves)) if leaves else 0.0\n",
    "\n",
    "    plt.figure(figsize=(9, 4.2))\n",
    "    drawn = set()\n",
    "    for u in nj.adj:\n",
    "        for v, w in nj.adj[u].items():\n",
    "            if (v, u) in drawn:\n",
    "                continue\n",
    "            drawn.add((u, v))\n",
    "            plt.plot([leaf_span(u), leaf_span(v)], [y_pos.get(u, 0.0), y_pos.get(v, 0.0)], linewidth=1.4)\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.text(leaf_span(i), y_pos.get(i, 0.0), labels[i], ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"leaves (order = label order)\")\n",
    "    plt.ylabel(\"− branch length\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if SHOW_PLOTS_INLINE:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------ METRICS ----------------------------\n",
    "# ============================================================\n",
    "\n",
    "def rf_distance(t1: NJTree, t2: NJTree) -> int:\n",
    "    return len(t1.splits - t2.splits) + len(t2.splits - t1.splits)\n",
    "\n",
    "def rf_normalized(t1: NJTree, t2: NJTree, n_leaves: int) -> float:\n",
    "    if n_leaves < 4:\n",
    "        return 0.0\n",
    "    rf = rf_distance(t1, t2)\n",
    "    rf_max = 2 * (n_leaves - 3)\n",
    "    return float(rf) / float(rf_max) if rf_max > 0 else 0.0\n",
    "\n",
    "def _upper_vec(M: np.ndarray) -> np.ndarray:\n",
    "    M = np.asarray(M, dtype=float)\n",
    "    iu = np.triu_indices(M.shape[0], k=1)\n",
    "    v = M[iu]\n",
    "    v = v[np.isfinite(v)]\n",
    "    return v\n",
    "\n",
    "def _pearson(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return float(\"nan\")\n",
    "    if np.std(a) == 0 or np.std(b) == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "def _spearman(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return float(\"nan\")\n",
    "    ra = pd.Series(a).rank(method=\"average\").to_numpy()\n",
    "    rb = pd.Series(b).rank(method=\"average\").to_numpy()\n",
    "    return _pearson(ra, rb)\n",
    "\n",
    "def patristic_metrics(t: NJTree, tref: NJTree) -> Dict[str, float]:\n",
    "    v = _upper_vec(t.patristic)\n",
    "    vr = _upper_vec(tref.patristic)\n",
    "    m = min(v.size, vr.size)\n",
    "    if m == 0:\n",
    "        return {\"pat_MAE\": np.nan, \"pat_RMSE\": np.nan, \"pat_Pearson\": np.nan, \"pat_Spearman\": np.nan}\n",
    "    v = v[:m]; vr = vr[:m]\n",
    "    diff = v - vr\n",
    "    return {\n",
    "        \"pat_MAE\": float(np.mean(np.abs(diff))),\n",
    "        \"pat_RMSE\": float(np.sqrt(np.mean(diff * diff))),\n",
    "        \"pat_Pearson\": _pearson(v, vr),\n",
    "        \"pat_Spearman\": _spearman(v, vr),\n",
    "    }\n",
    "\n",
    "def matrix_metrics(D: np.ndarray, Dref: np.ndarray) -> Dict[str, float]:\n",
    "    v = _upper_vec(D)\n",
    "    vr = _upper_vec(Dref)\n",
    "    m = min(v.size, vr.size)\n",
    "    if m == 0:\n",
    "        return {\"mat_MAE\": np.nan, \"mat_RMSE\": np.nan, \"mat_Pearson\": np.nan, \"mat_Spearman\": np.nan}\n",
    "    v = v[:m]; vr = vr[:m]\n",
    "    diff = v - vr\n",
    "    return {\n",
    "        \"mat_MAE\": float(np.mean(np.abs(diff))),\n",
    "        \"mat_RMSE\": float(np.sqrt(np.mean(diff * diff))),\n",
    "        \"mat_Pearson\": _pearson(v, vr),\n",
    "        \"mat_Spearman\": _spearman(v, vr),\n",
    "    }\n",
    "\n",
    "def fmt_pm(mean_val: float, std_val: float, decimals: int = 6) -> str:\n",
    "    return f\"{mean_val:.{decimals}f} ± {std_val:.{decimals}f}\"\n",
    "\n",
    "def mean_std_by_group(df: pd.DataFrame, group_col: str, metrics: List[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for g, sub in df.groupby(group_col):\n",
    "        row = {group_col: g}\n",
    "        for m in metrics:\n",
    "            vals = sub[m].astype(float).to_numpy()\n",
    "            mu = float(np.mean(vals))\n",
    "            sd = float(np.std(vals, ddof=1)) if len(vals) > 1 else 0.0\n",
    "            row[m] = fmt_pm(mu, sd, decimals=6)\n",
    "            row[m + \"_mean\"] = mu\n",
    "            row[m + \"_std\"]  = sd\n",
    "        rows.append(row)\n",
    "    out = pd.DataFrame(rows).sort_values(group_col)\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------- HEATMAPS --------------------------\n",
    "# ============================================================\n",
    "\n",
    "def plot_heatmap(M: np.ndarray, labels: List[str], title: str, out_png: str):\n",
    "    plt.figure(figsize=(8.2, 6.6))\n",
    "    im = plt.imshow(M, interpolation=\"nearest\", cmap=HEATMAP_CMAP)\n",
    "    plt.title(title, fontsize=12, pad=12)\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90, fontsize=7)\n",
    "    plt.yticks(range(len(labels)), labels, fontsize=7)\n",
    "    plt.colorbar(im, shrink=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=HEATMAP_DPI, bbox_inches=\"tight\")\n",
    "    if SHOW_PLOTS_INLINE:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_heatmap_grid(mats: List[np.ndarray], titles: List[str], labels: List[str], out_png: str):\n",
    "    assert len(mats) == len(titles)\n",
    "    k = len(mats)\n",
    "    ncol = int(math.ceil(math.sqrt(k)))\n",
    "    nrow = int(math.ceil(k / ncol))\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(5.3*ncol, 4.6*nrow))\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    im = None\n",
    "    for idx in range(nrow * ncol):\n",
    "        ax = axes[idx]\n",
    "        if idx < k:\n",
    "            im = ax.imshow(mats[idx], interpolation=\"nearest\", cmap=HEATMAP_CMAP)\n",
    "            ax.set_title(titles[idx], fontsize=9)\n",
    "            ax.set_xticks(range(len(labels)))\n",
    "            ax.set_xticklabels(labels, rotation=90, fontsize=5)\n",
    "            ax.set_yticks(range(len(labels)))\n",
    "            ax.set_yticklabels(labels, fontsize=5)\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # colorbar on the right\n",
    "    cbar_ax = fig.add_axes([0.92, 0.12, 0.015, 0.76])\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"Distance\")\n",
    "    plt.savefig(out_png, dpi=HEATMAP_DPI, bbox_inches=\"tight\")\n",
    "    if SHOW_PLOTS_INLINE:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# -------------------------- MAIN -----------------------------\n",
    "# ============================================================\n",
    "\n",
    "# 1) Discover ALL completed matrices for Hyb-Adam-UM (no TreePrior)\n",
    "if not os.path.exists(COMPLETED_DIR):\n",
    "    raise FileNotFoundError(f\"Completed directory not found: {COMPLETED_DIR}\")\n",
    "\n",
    "# Matches filenames created by the Hyb-Adam-UM-only code above:\n",
    "#   HybAdamUM_completed_p{pct}_rep{rep}.csv\n",
    "pat = re.compile(r\"^HybAdamUM_completed_p(\\d+)_rep(\\d+)\\.csv$\")\n",
    "found = []\n",
    "for fn in sorted(os.listdir(COMPLETED_DIR)):\n",
    "    m = pat.match(fn)\n",
    "    if m:\n",
    "        pct = int(m.group(1))\n",
    "        rep = int(m.group(2))\n",
    "        found.append((pct, rep, fn))\n",
    "\n",
    "if len(found) == 0:\n",
    "    raise RuntimeError(\n",
    "        f\"No files matched pattern in {COMPLETED_DIR}: HybAdamUM_completed_p##_rep#.csv\"\n",
    "    )\n",
    "\n",
    "found = sorted(found, key=lambda x: (x[0], x[1]))\n",
    "if MAX_COMPLETED_TO_PROCESS is not None:\n",
    "    found = found[:int(MAX_COMPLETED_TO_PROCESS)]\n",
    "\n",
    "print(f\"Found {len(found)} completed matrices in: {os.path.abspath(COMPLETED_DIR)}\")\n",
    "for pct, rep, fn in found[:10]:\n",
    "    print(f\"  p{pct} rep{rep}: {fn}\")\n",
    "if len(found) > 10:\n",
    "    print(\"  ...\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "print(f\"\\nOutput directory: {os.path.abspath(OUT_DIR)}\")\n",
    "\n",
    "# 2) Load ORIGINAL matrix\n",
    "print(\"\\nLoading original matrix...\")\n",
    "D0, D0_path = load_matrix_with_candidates(ORIG_CANDIDATES)\n",
    "D0 = sanitize_distance_matrix(D0, \"D_orig\", force_nonneg=True)\n",
    "print(f\"  Original matrix loaded: {D0_path}\")\n",
    "print(f\"  Original matrix shape:  {D0.shape}\")\n",
    "\n",
    "# 3) Load first completed matrix to get labels (authoritative)\n",
    "first_path = os.path.join(COMPLETED_DIR, found[0][2])\n",
    "D_first, labels = load_completed_csv(first_path)\n",
    "if D_first.shape != D0.shape:\n",
    "    raise ValueError(\n",
    "        f\"Original shape {D0.shape} != completed shape {D_first.shape}. \"\n",
    "        f\"Fix ORIG_CANDIDATES or use matching original.\"\n",
    "    )\n",
    "\n",
    "# 4) Build Original NJ tree once\n",
    "print(\"\\nBuilding NJ tree for original matrix...\")\n",
    "tree_orig = neighbor_joining_nonneg(D0, labels)\n",
    "draw_nj_tree(tree_orig, labels, \"NJ (Original full matrix)\", os.path.join(OUT_DIR, \"tree_Original.png\"), dpi=TREE_DPI)\n",
    "with open(os.path.join(OUT_DIR, \"tree_Original.newick\"), \"w\") as f:\n",
    "    f.write(tree_orig.newick + \"\\n\")\n",
    "print(\"  Saved: tree_Original.png, tree_Original.newick\")\n",
    "\n",
    "# 5) Process all completed matrices\n",
    "tree_rows = []\n",
    "mat_rows  = []\n",
    "\n",
    "heat_mats   = [D0]\n",
    "heat_titles = [\"Original\"]\n",
    "\n",
    "if SAVE_PATRISTIC_HEATMAPS:\n",
    "    pat_mats   = [tree_orig.patristic]\n",
    "    pat_titles = [\"Patristic (Original)\"]\n",
    "\n",
    "for pct, rep, fn in found:\n",
    "    path = os.path.join(COMPLETED_DIR, fn)\n",
    "    print(f\"\\nProcessing: {fn} (p{pct}, rep{rep})\")\n",
    "\n",
    "    D_comp, labels2 = load_completed_csv(path)\n",
    "    labels_use = labels2 if labels2 != labels else labels\n",
    "\n",
    "    if D_comp.shape != D0.shape:\n",
    "        print(f\"  Skip: shape mismatch {D_comp.shape} vs original {D0.shape}\")\n",
    "        continue\n",
    "\n",
    "    D_comp = sanitize_distance_matrix(D_comp, f\"D_comp_p{pct}_rep{rep}\", force_nonneg=True)\n",
    "\n",
    "    # build NJ tree\n",
    "    tree_comp = neighbor_joining_nonneg(D_comp, labels_use)\n",
    "\n",
    "    # draw + save tree\n",
    "    tree_png = os.path.join(OUT_DIR, f\"tree_p{pct}_rep{rep}.png\")\n",
    "    draw_nj_tree(tree_comp, labels_use, f\"NJ (Hyb-Adam-UM — {pct}% missing, rep{rep})\", tree_png, dpi=TREE_DPI)\n",
    "\n",
    "    # save newick\n",
    "    newick_path = os.path.join(OUT_DIR, f\"tree_p{pct}_rep{rep}.newick\")\n",
    "    with open(newick_path, \"w\") as f:\n",
    "        f.write(tree_comp.newick + \"\\n\")\n",
    "\n",
    "    # benchmarks (tree-level)\n",
    "    tr = {\n",
    "        \"pct_missing\": pct,\n",
    "        \"replicate\": rep,\n",
    "        \"file\": fn,\n",
    "        \"RF\": int(rf_distance(tree_comp, tree_orig)),\n",
    "        \"RF_norm\": float(rf_normalized(tree_comp, tree_orig, len(labels_use))),\n",
    "        \"n_splits\": int(len(tree_comp.splits)),\n",
    "    }\n",
    "    tr.update(patristic_metrics(tree_comp, tree_orig))\n",
    "    tree_rows.append(tr)\n",
    "\n",
    "    # benchmarks (matrix-level)\n",
    "    mr = {\"pct_missing\": pct, \"replicate\": rep, \"file\": fn}\n",
    "    mr.update(matrix_metrics(D_comp, D0))\n",
    "    mat_rows.append(mr)\n",
    "\n",
    "    print(f\"  Done: RF_norm = {tr['RF_norm']:.6f} | saved -> {os.path.basename(tree_png)}\")\n",
    "\n",
    "    # collect for heatmap grid\n",
    "    heat_mats.append(D_comp)\n",
    "    heat_titles.append(f\"p{pct} r{rep} (RF={tr['RF_norm']:.3f})\")\n",
    "\n",
    "    if SAVE_PATRISTIC_HEATMAPS:\n",
    "        pat_mats.append(tree_comp.patristic)\n",
    "        pat_titles.append(f\"Patristic p{pct} r{rep}\")\n",
    "\n",
    "    # optional individual heatmaps\n",
    "    if SAVE_INDIVIDUAL_HEATMAPS:\n",
    "        plot_heatmap(\n",
    "            D_comp, labels_use,\n",
    "            f\"Hyb-Adam-UM completed (p{pct}, rep{rep})\",\n",
    "            os.path.join(OUT_DIR, f\"heatmap_completed_p{pct}_rep{rep}.png\")\n",
    "        )\n",
    "\n",
    "# 6) Save detailed tables\n",
    "df_tree = pd.DataFrame(tree_rows).sort_values([\"pct_missing\", \"replicate\"])\n",
    "df_mat  = pd.DataFrame(mat_rows).sort_values([\"pct_missing\", \"replicate\"])\n",
    "\n",
    "tree_csv = os.path.join(OUT_DIR, \"benchmark_tree_all.csv\")\n",
    "mat_csv  = os.path.join(OUT_DIR, \"benchmark_matrix_all.csv\")\n",
    "df_tree.to_csv(tree_csv, index=False)\n",
    "df_mat.to_csv(mat_csv, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Detailed Tree Benchmark Results (ALL)\")\n",
    "print(\"=\"*70)\n",
    "with pd.option_context(\"display.max_rows\", 300, \"display.max_columns\", 300, \"display.width\", 240):\n",
    "    print(df_tree.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Detailed Matrix Benchmark Results (ALL)\")\n",
    "print(\"=\"*70)\n",
    "with pd.option_context(\"display.max_rows\", 300, \"display.max_columns\", 300, \"display.width\", 240):\n",
    "    print(df_mat.to_string(index=False))\n",
    "\n",
    "# 7) Mean ± SD by missingness\n",
    "tree_metrics_list = [\"RF\", \"RF_norm\", \"pat_MAE\", \"pat_RMSE\", \"pat_Pearson\", \"pat_Spearman\"]\n",
    "mat_metrics_list  = [\"mat_MAE\", \"mat_RMSE\", \"mat_Pearson\", \"mat_Spearman\"]\n",
    "\n",
    "df_tree_ms = mean_std_by_group(df_tree, \"pct_missing\", tree_metrics_list)\n",
    "df_mat_ms  = mean_std_by_group(df_mat,  \"pct_missing\", mat_metrics_list)\n",
    "\n",
    "tree_ms_csv = os.path.join(OUT_DIR, \"benchmark_tree_by_missingness_meanstd.csv\")\n",
    "mat_ms_csv  = os.path.join(OUT_DIR, \"benchmark_matrix_by_missingness_meanstd.csv\")\n",
    "df_tree_ms.to_csv(tree_ms_csv, index=False)\n",
    "df_mat_ms.to_csv(mat_ms_csv, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Tree metrics: mean ± SD by missingness\")\n",
    "print(\"=\"*70)\n",
    "print(df_tree_ms[[\"pct_missing\"] + tree_metrics_list].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Matrix metrics: mean ± SD by missingness\")\n",
    "print(\"=\"*70)\n",
    "print(df_mat_ms[[\"pct_missing\"] + mat_metrics_list].to_string(index=False))\n",
    "\n",
    "# 8) Heatmaps\n",
    "if SAVE_HEATMAP_GRID:\n",
    "    out_grid = os.path.join(OUT_DIR, \"heatmap_grid_original_plus_all.png\")\n",
    "    plot_heatmap_grid(heat_mats, heat_titles, labels, out_grid)\n",
    "    print(f\"\\nSaved heatmap grid: {os.path.abspath(out_grid)}\")\n",
    "\n",
    "if SAVE_PATRISTIC_HEATMAPS:\n",
    "    out_grid_pat = os.path.join(OUT_DIR, \"heatmap_grid_patristic_original_plus_all.png\")\n",
    "    plot_heatmap_grid(pat_mats, pat_titles, labels, out_grid_pat)\n",
    "    print(f\"Saved patristic heatmap grid: {os.path.abspath(out_grid_pat)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL PROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Output directory: {os.path.abspath(OUT_DIR)}\")\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"  - Trees: 1 Original + {len(df_tree)} completed PNGs + Newicks\")\n",
    "print(f\"  - Detailed CSVs: {os.path.basename(tree_csv)}, {os.path.basename(mat_csv)}\")\n",
    "print(f\"  - Mean±SD CSVs:  {os.path.basename(tree_ms_csv)}, {os.path.basename(mat_ms_csv)}\")\n",
    "if SAVE_HEATMAP_GRID:\n",
    "    print(f\"  - Heatmap grid: heatmap_grid_original_plus_all.png\")\n",
    "if SAVE_INDIVIDUAL_HEATMAPS:\n",
    "    print(f\"  - Individual heatmaps: {len(df_mat)} PNGs (plus original if you add it)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f50c4c-2979-4a94-b0fb-ae7e61596bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
