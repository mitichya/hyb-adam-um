{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "688068cb-3134-4e4f-9399-a96112fff9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calculating Δ for original matrix ===\n",
      "Original matrix file: Result_NW_15x15.txt\n",
      "Number of triplets (n choose 3) = 455\n",
      "Original matrix Δ_total = 105.474106\n",
      "Original Δ_normalized = 0.037533\n",
      "Original Δ_per_triangle (Δ/ntri) = 0.231811\n",
      "\n",
      "=== Running Hyb-Adam-UM on all masks ===\n",
      "\n",
      "  Processing 30% missing, replicate 1...\n",
      "Initial robust Δ: 183.917145\n",
      "Epoch     1 | full Δ = 327.061732 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 79.330071 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 78.471793 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 74.334304 | lr=0.01000\n",
      "    End-to-end runtime: 12.34 sec (0.21 min)\n",
      "\n",
      "  Processing 30% missing, replicate 2...\n",
      "Initial robust Δ: 295.173674\n",
      "Epoch     1 | full Δ = 415.442741 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 86.874481 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 83.946653 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 80.459499 | lr=0.01000\n",
      "    End-to-end runtime: 12.39 sec (0.21 min)\n",
      "\n",
      "  Processing 30% missing, replicate 3...\n",
      "Initial robust Δ: 226.809928\n",
      "Epoch     1 | full Δ = 310.567043 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 70.765930 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 75.883986 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 67.739358 | lr=0.01000\n",
      "    End-to-end runtime: 12.22 sec (0.20 min)\n",
      "\n",
      "  Processing 30% missing, replicate 4...\n",
      "Initial robust Δ: 236.493826\n",
      "Epoch     1 | full Δ = 327.310084 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 104.856439 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 94.832765 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 89.471414 | lr=0.01000\n",
      "    End-to-end runtime: 12.23 sec (0.20 min)\n",
      "\n",
      "  Processing 30% missing, replicate 5...\n",
      "Initial robust Δ: 302.921617\n",
      "Epoch     1 | full Δ = 323.544901 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 100.063592 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 100.744160 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 94.678147 | lr=0.01000\n",
      "    End-to-end runtime: 12.27 sec (0.20 min)\n",
      "\n",
      "  Processing 50% missing, replicate 1...\n",
      "Initial robust Δ: 243.066975\n",
      "Epoch     1 | full Δ = 381.057073 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 75.090632 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 76.185390 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 64.648692 | lr=0.01000\n",
      "    Runtime for 50% missing, replicate 1: 19.75 sec (0.33 min)\n",
      "    End-to-end runtime: 19.75 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 2...\n",
      "Initial robust Δ: 188.218800\n",
      "Epoch     1 | full Δ = 335.480424 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 65.789140 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 66.390567 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 56.183236 | lr=0.01000\n",
      "    Runtime for 50% missing, replicate 2: 19.84 sec (0.33 min)\n",
      "    End-to-end runtime: 19.84 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 3...\n",
      "Initial robust Δ: 152.632863\n",
      "Epoch     1 | full Δ = 351.536512 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 60.988139 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 57.244281 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 50.491394 | lr=0.01000\n",
      "    Runtime for 50% missing, replicate 3: 19.79 sec (0.33 min)\n",
      "    End-to-end runtime: 19.79 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 4...\n",
      "Initial robust Δ: 223.673541\n",
      "Epoch     1 | full Δ = 248.564304 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 57.617558 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 58.983674 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 49.991213 | lr=0.01000\n",
      "    Runtime for 50% missing, replicate 4: 19.62 sec (0.33 min)\n",
      "    End-to-end runtime: 19.62 sec (0.33 min)\n",
      "\n",
      "  Processing 50% missing, replicate 5...\n",
      "Initial robust Δ: 268.340100\n",
      "Epoch     1 | full Δ = 237.950093 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 68.774392 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 68.854012 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 64.658593 | lr=0.01000\n",
      "    Runtime for 50% missing, replicate 5: 19.69 sec (0.33 min)\n",
      "    End-to-end runtime: 19.69 sec (0.33 min)\n",
      "\n",
      "  Processing 65% missing, replicate 1...\n",
      "Initial robust Δ: 164.923388\n",
      "Epoch     1 | full Δ = 293.114437 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 52.977404 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 46.321830 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 42.282242 | lr=0.01000\n",
      "    End-to-end runtime: 25.82 sec (0.43 min)\n",
      "\n",
      "  Processing 65% missing, replicate 2...\n",
      "Initial robust Δ: 112.219396\n",
      "Epoch     1 | full Δ = 360.654517 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 42.253035 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 39.002871 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 28.234126 | lr=0.01000\n",
      "    End-to-end runtime: 26.00 sec (0.43 min)\n",
      "\n",
      "  Processing 65% missing, replicate 3...\n",
      "Initial robust Δ: 151.537648\n",
      "Epoch     1 | full Δ = 643.577209 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 52.070876 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 50.581024 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 43.899588 | lr=0.01000\n",
      "    End-to-end runtime: 25.72 sec (0.43 min)\n",
      "\n",
      "  Processing 65% missing, replicate 4...\n",
      "Initial robust Δ: 135.393234\n",
      "Epoch     1 | full Δ = 228.789516 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 50.440742 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 46.002058 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 36.729376 | lr=0.01000\n",
      "    End-to-end runtime: 25.77 sec (0.43 min)\n",
      "\n",
      "  Processing 65% missing, replicate 5...\n",
      "Initial robust Δ: 246.990225\n",
      "Epoch     1 | full Δ = 379.598502 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 104.766895 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 107.068063 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 96.725031 | lr=0.01000\n",
      "    End-to-end runtime: 25.71 sec (0.43 min)\n",
      "\n",
      "  Processing 85% missing, replicate 1...\n",
      "Initial robust Δ: 51.591621\n",
      "Epoch     1 | full Δ = 821.435286 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 17.740426 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 19.600265 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 11.616889 | lr=0.01000\n",
      "    End-to-end runtime: 33.63 sec (0.56 min)\n",
      "\n",
      "  Processing 85% missing, replicate 2...\n",
      "Initial robust Δ: 27.691751\n",
      "Epoch     1 | full Δ = 319.776879 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 15.199247 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 18.318140 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 8.719462 | lr=0.01000\n",
      "    End-to-end runtime: 33.73 sec (0.56 min)\n",
      "\n",
      "  Processing 85% missing, replicate 3...\n",
      "Initial robust Δ: 58.507383\n",
      "Epoch     1 | full Δ = 527.584709 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 21.072318 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 20.762369 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 14.836900 | lr=0.01000\n",
      "    End-to-end runtime: 33.87 sec (0.56 min)\n",
      "\n",
      "  Processing 85% missing, replicate 4...\n",
      "Initial robust Δ: 70.133411\n",
      "Epoch     1 | full Δ = 453.746840 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 27.976170 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 26.994071 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 13.058038 | lr=0.01000\n",
      "    End-to-end runtime: 33.71 sec (0.56 min)\n",
      "\n",
      "  Processing 85% missing, replicate 5...\n",
      "Initial robust Δ: 97.495613\n",
      "Epoch     1 | full Δ = 2035.263262 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 27.522479 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 30.324134 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 20.237026 | lr=0.01000\n",
      "    End-to-end runtime: 33.94 sec (0.57 min)\n",
      "\n",
      "  Processing 90% missing, replicate 1...\n",
      "Initial robust Δ: 32.891125\n",
      "Epoch     1 | full Δ = 390.857910 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 1602.487161 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 1564.149258 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 1545.248053 | lr=0.01000\n",
      "    End-to-end runtime: 35.56 sec (0.59 min)\n",
      "\n",
      "  Processing 90% missing, replicate 2...\n",
      "Initial robust Δ: 20.143064\n",
      "Epoch     1 | full Δ = 213.375197 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 79.084087 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 74.440737 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 69.582915 | lr=0.01000\n",
      "    End-to-end runtime: 35.75 sec (0.60 min)\n",
      "\n",
      "  Processing 90% missing, replicate 3...\n",
      "Initial robust Δ: 28.522100\n",
      "Epoch     1 | full Δ = 383.029538 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 1609.283122 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 1506.443400 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 1463.416201 | lr=0.01000\n",
      "    End-to-end runtime: 35.21 sec (0.59 min)\n",
      "\n",
      "  Processing 90% missing, replicate 4...\n",
      "Initial robust Δ: 58.390102\n",
      "Epoch     1 | full Δ = 432.680667 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 1733.612401 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 1663.359525 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 1624.777745 | lr=0.01000\n",
      "    End-to-end runtime: 35.35 sec (0.59 min)\n",
      "\n",
      "  Processing 90% missing, replicate 5...\n",
      "Initial robust Δ: 51.179022\n",
      "Epoch     1 | full Δ = 1444.322238 | lr=0.04000\n",
      "Epoch 00700: lr milestone 0.040000->0.020000\n",
      "Epoch  1000 | full Δ = 1586.562396 | lr=0.02000\n",
      "Epoch 02000: lr milestone 0.020000->0.010000\n",
      "Epoch  2000 | full Δ = 1545.278717 | lr=0.01000\n",
      "Epoch  3000 | full Δ = 1529.563721 | lr=0.01000\n",
      "    End-to-end runtime: 35.27 sec (0.59 min)\n",
      "\n",
      "=== Runtime summary for 50% missing matrices ===\n",
      "Count: 5\n",
      "Average: 19.74 sec (0.33 min)\n",
      "Range:   19.62 - 19.84 sec (0.33 - 0.33 min)\n",
      "\n",
      "=== Hyb-Adam-UM results for all masks ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_missing</th>\n",
       "      <th>replicate</th>\n",
       "      <th>RMSE_vs_ORIG</th>\n",
       "      <th>Δ_total</th>\n",
       "      <th>Δ_normalized</th>\n",
       "      <th>Δ_per_triangle</th>\n",
       "      <th>Δ_relative</th>\n",
       "      <th>runtime_seconds</th>\n",
       "      <th>completed_file</th>\n",
       "      <th>train_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>73.220974</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>0.160925</td>\n",
       "      <td>0.694208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p30_rep1.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>78.935976</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.173486</td>\n",
       "      <td>0.748392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p30_rep2.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004644</td>\n",
       "      <td>65.305514</td>\n",
       "      <td>0.026050</td>\n",
       "      <td>0.143529</td>\n",
       "      <td>0.619162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p30_rep3.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>86.801353</td>\n",
       "      <td>0.031384</td>\n",
       "      <td>0.190772</td>\n",
       "      <td>0.822964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p30_rep4.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>94.290873</td>\n",
       "      <td>0.033872</td>\n",
       "      <td>0.207233</td>\n",
       "      <td>0.893972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p30_rep5.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013534</td>\n",
       "      <td>62.219500</td>\n",
       "      <td>0.024175</td>\n",
       "      <td>0.136746</td>\n",
       "      <td>0.589903</td>\n",
       "      <td>19.745462</td>\n",
       "      <td>HybAdamUM_completed_p50_rep1.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.014419</td>\n",
       "      <td>53.947371</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.118566</td>\n",
       "      <td>0.511475</td>\n",
       "      <td>19.835471</td>\n",
       "      <td>HybAdamUM_completed_p50_rep2.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008292</td>\n",
       "      <td>49.147614</td>\n",
       "      <td>0.020060</td>\n",
       "      <td>0.108017</td>\n",
       "      <td>0.465969</td>\n",
       "      <td>19.788318</td>\n",
       "      <td>HybAdamUM_completed_p50_rep3.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.014044</td>\n",
       "      <td>46.243620</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.101634</td>\n",
       "      <td>0.438436</td>\n",
       "      <td>19.624310</td>\n",
       "      <td>HybAdamUM_completed_p50_rep4.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>61.339516</td>\n",
       "      <td>0.024655</td>\n",
       "      <td>0.134812</td>\n",
       "      <td>0.581560</td>\n",
       "      <td>19.686655</td>\n",
       "      <td>HybAdamUM_completed_p50_rep5.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>37.363680</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0.082118</td>\n",
       "      <td>0.354245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p65_rep1.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>27.272717</td>\n",
       "      <td>0.011518</td>\n",
       "      <td>0.059940</td>\n",
       "      <td>0.258573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p65_rep2.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>41.473239</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.091150</td>\n",
       "      <td>0.393208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p65_rep3.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>0.013864</td>\n",
       "      <td>33.690180</td>\n",
       "      <td>0.013964</td>\n",
       "      <td>0.074044</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p65_rep4.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>0.036795</td>\n",
       "      <td>92.994527</td>\n",
       "      <td>0.030714</td>\n",
       "      <td>0.204384</td>\n",
       "      <td>0.881681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p65_rep5.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040384</td>\n",
       "      <td>7.364356</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.016185</td>\n",
       "      <td>0.069821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p85_rep1.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042554</td>\n",
       "      <td>7.496389</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.016476</td>\n",
       "      <td>0.071073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p85_rep2.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>9.715963</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.021354</td>\n",
       "      <td>0.092117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p85_rep3.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>85</td>\n",
       "      <td>4</td>\n",
       "      <td>0.034706</td>\n",
       "      <td>13.053719</td>\n",
       "      <td>0.005187</td>\n",
       "      <td>0.028689</td>\n",
       "      <td>0.123762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p85_rep4.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>14.333336</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.031502</td>\n",
       "      <td>0.135894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p85_rep5.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048874</td>\n",
       "      <td>390.857910</td>\n",
       "      <td>0.077006</td>\n",
       "      <td>0.859028</td>\n",
       "      <td>3.705724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p90_rep1.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>60.673863</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.133349</td>\n",
       "      <td>0.575249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p90_rep2.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>0.045360</td>\n",
       "      <td>383.029538</td>\n",
       "      <td>0.072349</td>\n",
       "      <td>0.841823</td>\n",
       "      <td>3.631503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p90_rep3.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>90</td>\n",
       "      <td>4</td>\n",
       "      <td>0.066633</td>\n",
       "      <td>432.674392</td>\n",
       "      <td>0.069927</td>\n",
       "      <td>0.950933</td>\n",
       "      <td>4.102186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p90_rep4.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90</td>\n",
       "      <td>5</td>\n",
       "      <td>0.055266</td>\n",
       "      <td>441.588776</td>\n",
       "      <td>0.112257</td>\n",
       "      <td>0.970525</td>\n",
       "      <td>4.186703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HybAdamUM_completed_p90_rep5.csv</td>\n",
       "      <td>{'skipped': False, 'epochs': 3000, 'final_lr':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pct_missing  replicate  RMSE_vs_ORIG     Δ_total  Δ_normalized  \\\n",
       "0            30          1      0.011035   73.220974      0.028634   \n",
       "1            30          2      0.013289   78.935976      0.029021   \n",
       "2            30          3      0.004644   65.305514      0.026050   \n",
       "3            30          4      0.006316   86.801353      0.031384   \n",
       "4            30          5      0.002205   94.290873      0.033872   \n",
       "5            50          1      0.013534   62.219500      0.024175   \n",
       "6            50          2      0.014419   53.947371      0.020481   \n",
       "7            50          3      0.008292   49.147614      0.020060   \n",
       "8            50          4      0.014044   46.243620      0.018767   \n",
       "9            50          5      0.004616   61.339516      0.024655   \n",
       "10           65          1      0.014495   37.363680      0.015113   \n",
       "11           65          2      0.022682   27.272717      0.011518   \n",
       "12           65          3      0.008072   41.473239      0.017036   \n",
       "13           65          4      0.013864   33.690180      0.013964   \n",
       "14           65          5      0.036795   92.994527      0.030714   \n",
       "15           85          1      0.040384    7.364356      0.003384   \n",
       "16           85          2      0.042554    7.496389      0.003468   \n",
       "17           85          3      0.041562    9.715963      0.004082   \n",
       "18           85          4      0.034706   13.053719      0.005187   \n",
       "19           85          5      0.033046   14.333336      0.006100   \n",
       "20           90          1      0.048874  390.857910      0.077006   \n",
       "21           90          2      0.046747   60.673863      0.017531   \n",
       "22           90          3      0.045360  383.029538      0.072349   \n",
       "23           90          4      0.066633  432.674392      0.069927   \n",
       "24           90          5      0.055266  441.588776      0.112257   \n",
       "\n",
       "    Δ_per_triangle  Δ_relative  runtime_seconds  \\\n",
       "0         0.160925    0.694208              NaN   \n",
       "1         0.173486    0.748392              NaN   \n",
       "2         0.143529    0.619162              NaN   \n",
       "3         0.190772    0.822964              NaN   \n",
       "4         0.207233    0.893972              NaN   \n",
       "5         0.136746    0.589903        19.745462   \n",
       "6         0.118566    0.511475        19.835471   \n",
       "7         0.108017    0.465969        19.788318   \n",
       "8         0.101634    0.438436        19.624310   \n",
       "9         0.134812    0.581560        19.686655   \n",
       "10        0.082118    0.354245              NaN   \n",
       "11        0.059940    0.258573              NaN   \n",
       "12        0.091150    0.393208              NaN   \n",
       "13        0.074044    0.319417              NaN   \n",
       "14        0.204384    0.881681              NaN   \n",
       "15        0.016185    0.069821              NaN   \n",
       "16        0.016476    0.071073              NaN   \n",
       "17        0.021354    0.092117              NaN   \n",
       "18        0.028689    0.123762              NaN   \n",
       "19        0.031502    0.135894              NaN   \n",
       "20        0.859028    3.705724              NaN   \n",
       "21        0.133349    0.575249              NaN   \n",
       "22        0.841823    3.631503              NaN   \n",
       "23        0.950933    4.102186              NaN   \n",
       "24        0.970525    4.186703              NaN   \n",
       "\n",
       "                      completed_file  \\\n",
       "0   HybAdamUM_completed_p30_rep1.csv   \n",
       "1   HybAdamUM_completed_p30_rep2.csv   \n",
       "2   HybAdamUM_completed_p30_rep3.csv   \n",
       "3   HybAdamUM_completed_p30_rep4.csv   \n",
       "4   HybAdamUM_completed_p30_rep5.csv   \n",
       "5   HybAdamUM_completed_p50_rep1.csv   \n",
       "6   HybAdamUM_completed_p50_rep2.csv   \n",
       "7   HybAdamUM_completed_p50_rep3.csv   \n",
       "8   HybAdamUM_completed_p50_rep4.csv   \n",
       "9   HybAdamUM_completed_p50_rep5.csv   \n",
       "10  HybAdamUM_completed_p65_rep1.csv   \n",
       "11  HybAdamUM_completed_p65_rep2.csv   \n",
       "12  HybAdamUM_completed_p65_rep3.csv   \n",
       "13  HybAdamUM_completed_p65_rep4.csv   \n",
       "14  HybAdamUM_completed_p65_rep5.csv   \n",
       "15  HybAdamUM_completed_p85_rep1.csv   \n",
       "16  HybAdamUM_completed_p85_rep2.csv   \n",
       "17  HybAdamUM_completed_p85_rep3.csv   \n",
       "18  HybAdamUM_completed_p85_rep4.csv   \n",
       "19  HybAdamUM_completed_p85_rep5.csv   \n",
       "20  HybAdamUM_completed_p90_rep1.csv   \n",
       "21  HybAdamUM_completed_p90_rep2.csv   \n",
       "22  HybAdamUM_completed_p90_rep3.csv   \n",
       "23  HybAdamUM_completed_p90_rep4.csv   \n",
       "24  HybAdamUM_completed_p90_rep5.csv   \n",
       "\n",
       "                                           train_info  \n",
       "0   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "1   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "2   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "3   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "4   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "5   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "6   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "7   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "8   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "9   {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "10  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "11  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "12  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "13  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "14  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "15  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "16  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "17  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "18  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "19  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "20  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "21  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "22  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "23  {'skipped': False, 'epochs': 3000, 'final_lr':...  \n",
       "24  {'skipped': False, 'epochs': 3000, 'final_lr':...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyb-Adam-UM summary (mean ± std over replicates) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Missing</th>\n",
       "      <th>RMSE_mean</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>Δ_total_mean</th>\n",
       "      <th>Δ_total_std</th>\n",
       "      <th>Δ_normalized_mean</th>\n",
       "      <th>Δ_normalized_std</th>\n",
       "      <th>Δ_per_triangle_mean</th>\n",
       "      <th>Δ_per_triangle_std</th>\n",
       "      <th>Δ_relative_mean</th>\n",
       "      <th>Δ_relative_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30%</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.004572</td>\n",
       "      <td>79.710938</td>\n",
       "      <td>11.325689</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.175189</td>\n",
       "      <td>0.024892</td>\n",
       "      <td>0.755739</td>\n",
       "      <td>0.107379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.004344</td>\n",
       "      <td>54.579524</td>\n",
       "      <td>7.131958</td>\n",
       "      <td>0.021628</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.119955</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.517468</td>\n",
       "      <td>0.067618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65%</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.011137</td>\n",
       "      <td>46.558869</td>\n",
       "      <td>26.477558</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.102327</td>\n",
       "      <td>0.058192</td>\n",
       "      <td>0.441425</td>\n",
       "      <td>0.251034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85%</td>\n",
       "      <td>0.038451</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>10.392753</td>\n",
       "      <td>3.186969</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.022841</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>0.098534</td>\n",
       "      <td>0.030216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90%</td>\n",
       "      <td>0.052576</td>\n",
       "      <td>0.008726</td>\n",
       "      <td>341.764896</td>\n",
       "      <td>159.181034</td>\n",
       "      <td>0.069814</td>\n",
       "      <td>0.033886</td>\n",
       "      <td>0.751132</td>\n",
       "      <td>0.349848</td>\n",
       "      <td>3.240273</td>\n",
       "      <td>1.509195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  % Missing  RMSE_mean  RMSE_std  Δ_total_mean  Δ_total_std  \\\n",
       "0       30%   0.007498  0.004572     79.710938    11.325689   \n",
       "1       50%   0.010981  0.004344     54.579524     7.131958   \n",
       "2       65%   0.019182  0.011137     46.558869    26.477558   \n",
       "3       85%   0.038451  0.004286     10.392753     3.186969   \n",
       "4       90%   0.052576  0.008726    341.764896   159.181034   \n",
       "\n",
       "   Δ_normalized_mean  Δ_normalized_std  Δ_per_triangle_mean  \\\n",
       "0           0.029792          0.002963             0.175189   \n",
       "1           0.021628          0.002627             0.119955   \n",
       "2           0.017669          0.007561             0.102327   \n",
       "3           0.004444          0.001173             0.022841   \n",
       "4           0.069814          0.033886             0.751132   \n",
       "\n",
       "   Δ_per_triangle_std  Δ_relative_mean  Δ_relative_std  \n",
       "0            0.024892         0.755739        0.107379  \n",
       "1            0.015675         0.517468        0.067618  \n",
       "2            0.058192         0.441425        0.251034  \n",
       "3            0.007004         0.098534        0.030216  \n",
       "4            0.349848         3.240273        1.509195  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyb-Adam-UM formatted summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Missing</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Δ_total</th>\n",
       "      <th>Δ_normalized</th>\n",
       "      <th>Δ̄ (per triangle)</th>\n",
       "      <th>Δ_relative (to original)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30%</td>\n",
       "      <td>0.007498 ± 0.004572</td>\n",
       "      <td>79.7109 ± 11.3257</td>\n",
       "      <td>0.029792 ± 0.002963</td>\n",
       "      <td>0.175189 ± 0.024892</td>\n",
       "      <td>0.755739 ± 0.107379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50%</td>\n",
       "      <td>0.010981 ± 0.004344</td>\n",
       "      <td>54.5795 ± 7.1320</td>\n",
       "      <td>0.021628 ± 0.002627</td>\n",
       "      <td>0.119955 ± 0.015675</td>\n",
       "      <td>0.517468 ± 0.067618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65%</td>\n",
       "      <td>0.019182 ± 0.011137</td>\n",
       "      <td>46.5589 ± 26.4776</td>\n",
       "      <td>0.017669 ± 0.007561</td>\n",
       "      <td>0.102327 ± 0.058192</td>\n",
       "      <td>0.441425 ± 0.251034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85%</td>\n",
       "      <td>0.038451 ± 0.004286</td>\n",
       "      <td>10.3928 ± 3.1870</td>\n",
       "      <td>0.004444 ± 0.001173</td>\n",
       "      <td>0.022841 ± 0.007004</td>\n",
       "      <td>0.098534 ± 0.030216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90%</td>\n",
       "      <td>0.052576 ± 0.008726</td>\n",
       "      <td>341.7649 ± 159.1810</td>\n",
       "      <td>0.069814 ± 0.033886</td>\n",
       "      <td>0.751132 ± 0.349848</td>\n",
       "      <td>3.240273 ± 1.509195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  % Missing                 RMSE              Δ_total         Δ_normalized  \\\n",
       "0       30%  0.007498 ± 0.004572    79.7109 ± 11.3257  0.029792 ± 0.002963   \n",
       "1       50%  0.010981 ± 0.004344     54.5795 ± 7.1320  0.021628 ± 0.002627   \n",
       "2       65%  0.019182 ± 0.011137    46.5589 ± 26.4776  0.017669 ± 0.007561   \n",
       "3       85%  0.038451 ± 0.004286     10.3928 ± 3.1870  0.004444 ± 0.001173   \n",
       "4       90%  0.052576 ± 0.008726  341.7649 ± 159.1810  0.069814 ± 0.033886   \n",
       "\n",
       "     Δ̄ (per triangle) Δ_relative (to original)  \n",
       "0  0.175189 ± 0.024892      0.755739 ± 0.107379  \n",
       "1  0.119955 ± 0.015675      0.517468 ± 0.067618  \n",
       "2  0.102327 ± 0.058192      0.441425 ± 0.251034  \n",
       "3  0.022841 ± 0.007004      0.098534 ± 0.030216  \n",
       "4  0.751132 ± 0.349848      3.240273 ± 1.509195  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Delta Sum Table (training-style; COMPLETED matrices) for Hyb-Adam-UM ===\n",
      "Original Δ_total = 105.474106\n",
      "Original Δ_normalized = 0.037533\n",
      "Number of triangles = 455\n",
      "Original Δ_per_triangle = 0.231811\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% Missing</th>\n",
       "      <th>Hyb-Adam-UM Δ_total</th>\n",
       "      <th>Δ_normalized</th>\n",
       "      <th>Δ̄ (per triangle)</th>\n",
       "      <th>Δ_relative (to original)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original</td>\n",
       "      <td>105.4741</td>\n",
       "      <td>0.037533</td>\n",
       "      <td>0.231811</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30%</td>\n",
       "      <td>79.7109 ± 11.3257</td>\n",
       "      <td>0.029792 ± 0.002963</td>\n",
       "      <td>0.175189 ± 0.024892</td>\n",
       "      <td>0.7557 ± 0.1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50%</td>\n",
       "      <td>54.5795 ± 7.1320</td>\n",
       "      <td>0.021628 ± 0.002627</td>\n",
       "      <td>0.119955 ± 0.015675</td>\n",
       "      <td>0.5175 ± 0.0676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65%</td>\n",
       "      <td>46.5589 ± 26.4776</td>\n",
       "      <td>0.017669 ± 0.007561</td>\n",
       "      <td>0.102327 ± 0.058192</td>\n",
       "      <td>0.4414 ± 0.2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85%</td>\n",
       "      <td>10.3928 ± 3.1870</td>\n",
       "      <td>0.004444 ± 0.001173</td>\n",
       "      <td>0.022841 ± 0.007004</td>\n",
       "      <td>0.0985 ± 0.0302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90%</td>\n",
       "      <td>341.7649 ± 159.1810</td>\n",
       "      <td>0.069814 ± 0.033886</td>\n",
       "      <td>0.751132 ± 0.349848</td>\n",
       "      <td>3.2403 ± 1.5092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  % Missing  Hyb-Adam-UM Δ_total         Δ_normalized    Δ̄ (per triangle)  \\\n",
       "0  Original             105.4741             0.037533             0.231811   \n",
       "1       30%    79.7109 ± 11.3257  0.029792 ± 0.002963  0.175189 ± 0.024892   \n",
       "2       50%     54.5795 ± 7.1320  0.021628 ± 0.002627  0.119955 ± 0.015675   \n",
       "3       65%    46.5589 ± 26.4776  0.017669 ± 0.007561  0.102327 ± 0.058192   \n",
       "4       85%     10.3928 ± 3.1870  0.004444 ± 0.001173  0.022841 ± 0.007004   \n",
       "5       90%  341.7649 ± 159.1810  0.069814 ± 0.033886  0.751132 ± 0.349848   \n",
       "\n",
       "  Δ_relative (to original)  \n",
       "0                   1.0000  \n",
       "1          0.7557 ± 0.1074  \n",
       "2          0.5175 ± 0.0676  \n",
       "3          0.4414 ± 0.2510  \n",
       "4          0.0985 ± 0.0302  \n",
       "5          3.2403 ± 1.5092  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ALL PROCESSING COMPLETE! ===\n",
      "Output files:\n",
      "  - Masked matrices saved to: hyb_adam_um_missing_matrices/\n",
      "  - Completed matrices saved to: hyb_adam_um_completed_matrices/\n",
      "  - Detailed results: hyb_adam_um_all_masks_detailed.csv\n",
      "  - Formatted summary: hyb_adam_um_summary_formatted.csv\n",
      "  - Numeric summary: hyb_adam_um_summary_numeric.csv\n",
      "  - Training-style delta table: hyb_adam_um_delta_sum_training_style.csv\n",
      "\n",
      "Note: Δ_normalized uses log scaling: δ_norm = log(1+δ)/log(101), then clipped to [0,1].\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "STANDALONE Hyb-Adam-UM ALGORITHM ONLY — ALL MISSINGNESS × REPS, NJ*-STYLE OUTPUT TABLES\n",
    "\n",
    "Minimal-change rewrite of your \"Hyb-Adam-UM only (30% rep1)\" script so it matches the\n",
    "output style of the TreePrior code you posted:\n",
    "\n",
    "What this script does\n",
    "---------------------\n",
    "1) Load ORIGINAL full matrix, symmetrize & sanitize.\n",
    "2) Build & freeze ALL masked matrices for each missingness level × replicate:\n",
    "     - default: 30/50/65/85% × 5 reps  (match your TreePrior script)\n",
    "     - same seeding pattern: rng = RandomState(BASE_SEED + (rep-1))\n",
    "3) For each mask:\n",
    "     - Run Hyb-Adam-UM (your manual Adam, NumPy-only, central-diff grads on missing LT)\n",
    "     - Produce a COMPLETED matrix\n",
    "4) Save:\n",
    "     - All masked matrices to MASKED_DIR\n",
    "     - All completed matrices to COMPLETED_DIR\n",
    "     - Detailed results CSV (all masks)\n",
    "     - Summary mean±std CSV (by missingness)\n",
    "     - Numeric summary CSV\n",
    "     - Training-style delta table CSV (Original + each missingness mean±std)\n",
    "\n",
    "Notes\n",
    "-----\n",
    "- I did NOT change the optimizer math (central diff + Adam). I only wrapped it in an\n",
    "  \"all masks\" driver and added the same table outputs as in the TreePrior script.\n",
    "- This NumPy central-diff implementation is extremely expensive for n=100; it is intended\n",
    "  for small matrices (e.g., 15×15). If you run n=100 with EPOCHS=30000 you will likely\n",
    "  wait a very long time.\n",
    "\"\"\"\n",
    "\n",
    "import os, sys, json, math, warnings, zipfile, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Set, Tuple, Union\n",
    "from dataclasses import dataclass\n",
    "from itertools import combinations\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- CONFIG -----------------------------\n",
    "# ============================================================\n",
    "\n",
    "# Data (align with your TreePrior script)\n",
    "ORIG_CANDIDATES = [\n",
    "    \"Result_NW_15x15.txt\",\n",
    "    \"/mnt/data/Result_NW_100x100.txt\",\n",
    "    \"Result_NW_15x15.txt\",\n",
    "    \"/mnt/data/Result_NW_15x15.txt\",\n",
    "]\n",
    "\n",
    "# Missingness × reps (align with your TreePrior script)\n",
    "MISSING_FRACS = (0.30, 0.50, 0.65, 0.85, 0.90)\n",
    "REPS          = 5\n",
    "BASE_SEED     = 55\n",
    "\n",
    "# Output folders (NJ*-style)\n",
    "MASKED_DIR    = \"hyb_adam_um_missing_matrices\"\n",
    "COMPLETED_DIR = \"hyb_adam_um_completed_matrices\"\n",
    "\n",
    "# Preserve observed entries EXACTLY in the final output?\n",
    "# IMPORTANT: Your original hyb_adam_um_impute() reconstructs the whole matrix from\n",
    "# observed LT + optimized missing LT, so observed entries are preserved by construction.\n",
    "PRESERVE_OBSERVED = True\n",
    "\n",
    "# -----------------------\n",
    "# Training hyperparameters (keep your original defaults)\n",
    "# -----------------------\n",
    "EPOCHS              = 3000\n",
    "PRINT_EVERY         = 1000\n",
    "LR_INIT             = 0.04\n",
    "WEIGHT_DECAY        = 0.0\n",
    "CLIP_GRAD_NORM      = 5.0\n",
    "H_CENTRAL_DIFF      = 5e-5\n",
    "BETA1               = 0.9\n",
    "BETA2               = 0.999\n",
    "ADAM_EPS            = 1e-8\n",
    "TRI_FRAC            = 1.0   # use ALL triplets\n",
    "SEED_HYB            = 42\n",
    "\n",
    "# LR schedule: earlier & also fixed milestones\n",
    "SCHED_PATIENCE_BLOCKS = 7    # with PRINT_EVERY=100 -> ~700 epochs\n",
    "LR_FACTOR             = 0.5\n",
    "LR_MIN                = 1e-4\n",
    "LR_MILESTONES         = [700, 2000]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- Loading & helpers -------------------\n",
    "# ============================================================\n",
    "\n",
    "MISSING_VAL = -1.0\n",
    "\n",
    "def load_matrix_with_candidates(cands):\n",
    "    for p in cands:\n",
    "        if os.path.exists(p):\n",
    "            M = np.loadtxt(p)\n",
    "            if np.nanmax(M) > 500:\n",
    "                M = M / 1000.0\n",
    "            return M, p\n",
    "    raise FileNotFoundError(f\"File not found. Tried: {cands}\")\n",
    "\n",
    "def symmetrize_full(D: np.ndarray) -> np.ndarray:\n",
    "    D = 0.5*(D + D.T)\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "def symmetrize_with_missing(D: np.ndarray) -> np.ndarray:\n",
    "    D = D.copy().astype(float)\n",
    "    n = D.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            a, b = D[i, j], D[j, i]\n",
    "            if a >= 0 and b >= 0: v = 0.5*(a+b)\n",
    "            elif a >= 0:         v = a\n",
    "            elif b >= 0:         v = b\n",
    "            else:                v = MISSING_VAL\n",
    "            D[i, j] = D[j, i] = v\n",
    "    np.fill_diagonal(D, 0.0)\n",
    "    return D\n",
    "\n",
    "def _finite_fill(v, fallback=1.0):\n",
    "    v = np.asarray(v)\n",
    "    if np.isfinite(v).any():\n",
    "        return float(np.nanmedian(v[np.isfinite(v)]))\n",
    "    return float(fallback)\n",
    "\n",
    "def sanitize_distance_matrix(D: np.ndarray, name: str=\"D\", force_nonneg: bool=True) -> np.ndarray:\n",
    "    \"\"\"Ensure finite, symmetric, optionally nonnegative, 0-diagonal matrix.\"\"\"\n",
    "    M = np.array(D, dtype=float)\n",
    "    n = M.shape[0]\n",
    "    neg = (M < 0); np.fill_diagonal(neg, False)\n",
    "    M[neg] = np.nan\n",
    "    off = ~np.eye(n, dtype=bool)\n",
    "    med = _finite_fill(M[off], fallback=1.0)\n",
    "    M = np.nan_to_num(M, nan=med, posinf=med, neginf=med)\n",
    "    q = np.quantile(M[off], 0.995)\n",
    "    if np.isfinite(q) and q > 0: M[off] = np.minimum(M[off], q)\n",
    "    M = 0.5*(M + M.T)\n",
    "    if force_nonneg: M = np.maximum(M, 0.0)\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "    if not np.isfinite(M).all():\n",
    "        raise ValueError(f\"{name} has non-finite entries after sanitize.\")\n",
    "    return M\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- Robust δ / Δ ------------------------\n",
    "# ============================================================\n",
    "\n",
    "OMEGA   = 2.0\n",
    "EPS_NUM = 1.0e-12\n",
    "\n",
    "def robust_delta_per_triplet_numpy(M: np.ndarray, triplets: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return δ(i,j,k) for each triplet; M must be symmetric, nonnegative, 0-diagonal.\"\"\"\n",
    "    i, j, k = triplets[:, 0], triplets[:, 1], triplets[:, 2]\n",
    "    a = M[i, j]; b = M[i, k]; c = M[j, k]\n",
    "    S = np.stack([a, b, c], axis=1)\n",
    "    S_sorted = -np.sort(-S, axis=1)\n",
    "    a, b, c = S_sorted[:, 0], S_sorted[:, 1], S_sorted[:, 2]\n",
    "    viol = a >= (b + c)\n",
    "    denom_v = np.maximum(b + c, EPS_NUM)\n",
    "    delta1 = np.maximum(a / denom_v, OMEGA)\n",
    "    denomA = np.maximum(2.0 * b * c, EPS_NUM)\n",
    "    denomB = np.maximum(2.0 * a * c, EPS_NUM)\n",
    "    denomG = np.maximum(2.0 * a * b, EPS_NUM)\n",
    "    cosA = np.clip((b*b + c*c - a*a) / denomA, -1.0, 1.0)\n",
    "    cosB = np.clip((a*a + c*c - b*b) / denomB, -1.0, 1.0)\n",
    "    cosG = np.clip((a*a + b*b - c*c) / denomG, -1.0, 1.0)\n",
    "    A = np.arccos(cosA); B = np.arccos(cosB); G = np.arccos(cosG)\n",
    "    Ang = np.stack([A, B, G], axis=1)\n",
    "    Ang_sorted = -np.sort(-Ang, axis=1)\n",
    "    A, B, G = Ang_sorted[:, 0], Ang_sorted[:, 1], Ang_sorted[:, 2]\n",
    "    delta2 = (A - B) / np.maximum(G, EPS_NUM)\n",
    "    return np.where(viol, delta1, delta2)\n",
    "\n",
    "def robust_delta_sum_numpy(M: np.ndarray, triplets: np.ndarray) -> float:\n",
    "    return float(robust_delta_per_triplet_numpy(M, triplets).sum())\n",
    "\n",
    "def compute_normalized_delta(M: np.ndarray, triplets: np.ndarray) -> float:\n",
    "    \"\"\"Log-compressed mean δ in [0,1] (clipped), using max_reasonable_delta=100.\"\"\"\n",
    "    delta_vals = robust_delta_per_triplet_numpy(M, triplets)\n",
    "    max_reasonable_delta = 100.0\n",
    "    delta_norm_vals = np.log1p(delta_vals) / np.log1p(max_reasonable_delta)\n",
    "    delta_norm_vals = np.clip(delta_norm_vals, 0.0, 1.0)\n",
    "    return float(np.mean(delta_norm_vals))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- RMSE helper -------------------------\n",
    "# ============================================================\n",
    "\n",
    "def rmse_on_lt(A: np.ndarray, B: np.ndarray) -> float:\n",
    "    n = A.shape[0]\n",
    "    i_lt, j_lt = np.tril_indices(n, k=-1)\n",
    "    diff = (A - B)[i_lt, j_lt]\n",
    "    return float(np.sqrt(np.mean(diff*diff)))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- Mask generation ---------------------\n",
    "# ============================================================\n",
    "\n",
    "def simulate_missing(D_full: np.ndarray, frac_missing: float, rng: np.random.RandomState):\n",
    "    \"\"\"Mask lower-triangle pairs to -1 (symmetrically) at given fraction.\"\"\"\n",
    "    n = D_full.shape[0]\n",
    "    lower = np.tril(np.ones((n,n), dtype=bool), k=-1)\n",
    "    I, J = np.where(lower); m = len(I)\n",
    "    drop = int(round(frac_missing*m))\n",
    "    keep = np.ones(m, dtype=bool)\n",
    "    if drop > 0:\n",
    "        keep[rng.choice(m, size=drop, replace=False)] = False\n",
    "    D_inc = D_full.copy().astype(float)\n",
    "    for idx in range(m):\n",
    "        i, j = I[idx], J[idx]\n",
    "        if not keep[idx]:\n",
    "            D_inc[i, j] = D_inc[j, i] = MISSING_VAL\n",
    "    np.fill_diagonal(D_inc, 0.0)\n",
    "    D_inc = symmetrize_with_missing(D_inc)\n",
    "    obs_mask = (D_inc >= 0)\n",
    "    np.fill_diagonal(obs_mask, True)\n",
    "    return D_inc, obs_mask\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ---------------- Hyb-Adam-UM (manual Adam) ------------------\n",
    "# ============================================================\n",
    "\n",
    "def setup_problem_for_hyb_adam(M_in: np.ndarray):\n",
    "    \"\"\"Prepare parameterization over missing lower-triangle entries.\"\"\"\n",
    "    n = M_in.shape[0]\n",
    "    lower_mask = np.tril(np.ones((n, n), dtype=bool), k=-1)\n",
    "    given_mask_lower   = lower_mask & (M_in >= 0.0)\n",
    "    missing_mask_lower = lower_mask & (M_in <  0.0)\n",
    "    given_pairs   = np.array(np.where(given_mask_lower)).T\n",
    "    missing_pairs = np.array(np.where(missing_mask_lower)).T\n",
    "    Ng = len(given_pairs)\n",
    "    given_vals = M_in[given_mask_lower].astype(np.float64)\n",
    "    init_val = float(np.mean(given_vals)) if Ng > 0 else 1.0\n",
    "    x = np.full((len(missing_pairs),), init_val, dtype=np.float64)\n",
    "    triplets = np.array(list(combinations(range(n), 3)), dtype=np.int32)\n",
    "\n",
    "    def assemble_full(xvec: np.ndarray) -> np.ndarray:\n",
    "        # Observed LT preserved EXACTLY because we copy given_vals to those LT positions.\n",
    "        M = np.zeros((n, n), dtype=np.float64)\n",
    "        if Ng > 0:\n",
    "            gi, gj = given_pairs[:, 0], given_pairs[:, 1]\n",
    "            M[gi, gj] = given_vals\n",
    "        if len(missing_pairs) > 0:\n",
    "            mi, mj = missing_pairs[:, 0], missing_pairs[:, 1]\n",
    "            M[mi, mj] = xvec\n",
    "        M = M + M.T\n",
    "        np.fill_diagonal(M, 0.0)\n",
    "        np.maximum(M, 0.0, out=M)\n",
    "        return M\n",
    "\n",
    "    return x, given_pairs, missing_pairs, given_vals, triplets, assemble_full\n",
    "\n",
    "def central_diff_grad(x: np.ndarray, f, h: float = H_CENTRAL_DIFF) -> np.ndarray:\n",
    "    g = np.zeros_like(x)\n",
    "    for k in range(x.size):\n",
    "        x[k] += h; f1 = f(x)\n",
    "        x[k] -= 2*h; f2 = f(x)\n",
    "        x[k] += h\n",
    "        g[k] = (f1 - f2) / (2*h)\n",
    "    return g\n",
    "\n",
    "def hyb_adam_um_impute(D_in: np.ndarray, trip_all: np.ndarray, ntri: int, verbose: bool=True) -> Tuple[np.ndarray, Dict]:\n",
    "    \"\"\"\n",
    "    Optimize missing LT with robust-Δ objective; FULL-BATCH so batch Δ == full Δ.\n",
    "    Returns (completed_matrix, train_info_dict).\n",
    "    \"\"\"\n",
    "    np.random.seed(SEED_HYB)\n",
    "\n",
    "    x, _, _, _, all_triplets, assemble_full = setup_problem_for_hyb_adam(D_in)\n",
    "    T = all_triplets.shape[0]\n",
    "\n",
    "    if x.size == 0:\n",
    "        M0 = assemble_full(x)\n",
    "        info = {\"skipped\": True, \"reason\": \"no missing pairs\", \"epochs\": 0}\n",
    "        return M0, info\n",
    "\n",
    "    def objective_full(xvec: np.ndarray) -> float:\n",
    "        M = assemble_full(xvec)\n",
    "        return robust_delta_sum_numpy(M, all_triplets)\n",
    "\n",
    "    # Initial\n",
    "    delta0_full = objective_full(x)\n",
    "    if verbose:\n",
    "        print(f\"Initial robust Δ: {delta0_full:.6f}\")\n",
    "\n",
    "    # Adam state\n",
    "    m = np.zeros_like(x); v = np.zeros_like(x); t = 0\n",
    "    lr = LR_INIT\n",
    "\n",
    "    # Scheduler state\n",
    "    best_full = float(\"inf\")\n",
    "    last_block_best = float(\"inf\")\n",
    "    no_improve_blocks = 0\n",
    "\n",
    "    best_x = x.copy()\n",
    "    best_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        t += 1\n",
    "\n",
    "        # FULL batch\n",
    "        f_batch = lambda xvec: objective_full(xvec)\n",
    "\n",
    "        # Central-diff gradient\n",
    "        g = central_diff_grad(x, f_batch, h=H_CENTRAL_DIFF)\n",
    "\n",
    "        # Weight decay\n",
    "        if WEIGHT_DECAY > 0.0:\n",
    "            g = g + WEIGHT_DECAY * x\n",
    "\n",
    "        # Gradient clipping\n",
    "        if CLIP_GRAD_NORM is not None:\n",
    "            g_norm = float(np.linalg.norm(g))\n",
    "            if g_norm > CLIP_GRAD_NORM and g_norm > 0:\n",
    "                g = g * (CLIP_GRAD_NORM / g_norm)\n",
    "\n",
    "        # Adam update\n",
    "        m = BETA1 * m + (1 - BETA1) * g\n",
    "        v = BETA2 * v + (1 - BETA2) * (g * g)\n",
    "        m_hat = m / (1 - (BETA1 ** t))\n",
    "        v_hat = v / (1 - (BETA2 ** t))\n",
    "        x -= lr * (m_hat / (np.sqrt(v_hat) + ADAM_EPS))\n",
    "        x = np.maximum(x, 0.0)\n",
    "\n",
    "        # Fixed epoch milestones\n",
    "        if epoch in LR_MILESTONES and lr > LR_MIN + 1e-12:\n",
    "            new_lr = max(LR_MIN, lr * LR_FACTOR)\n",
    "            if new_lr < lr - 1e-12 and verbose:\n",
    "                print(f\"Epoch {epoch:05d}: lr milestone {lr:.6f}->{new_lr:.6f}\")\n",
    "            lr = new_lr\n",
    "\n",
    "        # Logging + plateau schedule\n",
    "        if epoch % PRINT_EVERY == 0 or epoch == 1 or epoch == EPOCHS:\n",
    "            full_loss  = objective_full(x)\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch:5d} | full Δ = {full_loss:.6f} | lr={lr:.5f}\")\n",
    "\n",
    "            # plateau-based reduction\n",
    "            if full_loss < last_block_best - 1e-12:\n",
    "                no_improve_blocks = 0\n",
    "                last_block_best = full_loss\n",
    "            else:\n",
    "                no_improve_blocks += 1\n",
    "                if no_improve_blocks >= SCHED_PATIENCE_BLOCKS and lr > LR_MIN + 1e-12:\n",
    "                    new_lr = max(LR_MIN, lr * LR_FACTOR)\n",
    "                    if new_lr < lr - 1e-12 and verbose:\n",
    "                        print(f\"Epoch {epoch:05d}: lr plateau {lr:.6f}->{new_lr:.6f}\")\n",
    "                    lr = new_lr\n",
    "                    no_improve_blocks = 0\n",
    "\n",
    "        # Track best\n",
    "        full_loss_now = objective_full(x)\n",
    "        if full_loss_now < best_loss - 1e-12:\n",
    "            best_loss = full_loss_now\n",
    "            best_x = x.copy()\n",
    "\n",
    "        if full_loss_now < best_full - 1e-12:\n",
    "            best_full = full_loss_now\n",
    "\n",
    "    M_best = assemble_full(best_x)\n",
    "    M_best = 0.5*(M_best + M_best.T)\n",
    "    np.fill_diagonal(M_best, 0.0)\n",
    "    M_best = np.maximum(M_best, 0.0)\n",
    "\n",
    "    info = {\n",
    "        \"skipped\": False,\n",
    "        \"epochs\": int(EPOCHS),\n",
    "        \"final_lr\": float(lr),\n",
    "        \"best_obj\": float(best_loss),\n",
    "        \"missing_params\": int(best_x.size),\n",
    "    }\n",
    "    return M_best, info\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------- Tables helpers --------------------\n",
    "# ============================================================\n",
    "\n",
    "def fmt_pm(mean_val, std_val, decimals=6) -> str:\n",
    "    return f\"{mean_val:.{decimals}f} ± {std_val:.{decimals}f}\"\n",
    "\n",
    "def mean_std(x: np.ndarray) -> Tuple[float, float]:\n",
    "    m = float(np.mean(x))\n",
    "    s = float(np.std(x, ddof=1)) if len(x) > 1 else 0.0\n",
    "    return m, s\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------- MAIN ------------------------------\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # Load ORIGINAL\n",
    "    D_orig, used_orig_path = load_matrix_with_candidates(ORIG_CANDIDATES)\n",
    "    D0 = sanitize_distance_matrix(symmetrize_full(D_orig), \"D_orig\")\n",
    "\n",
    "    n = D0.shape[0]\n",
    "    labels = [f\"T{i+1}\" for i in range(n)]\n",
    "    trip_all = np.array(list(combinations(range(n), 3)), dtype=np.int32)\n",
    "    ntri = n*(n-1)*(n-2)//6\n",
    "\n",
    "    # ORIGINAL Δ\n",
    "    print(\"=== Calculating Δ for original matrix ===\")\n",
    "    Δ_original = robust_delta_sum_numpy(D0, trip_all)\n",
    "    Δ_normalized_original = compute_normalized_delta(D0, trip_all)\n",
    "    print(f\"Original matrix file: {used_orig_path}\")\n",
    "    print(f\"Number of triplets (n choose 3) = {ntri}\")\n",
    "    print(f\"Original matrix Δ_total = {Δ_original:.6f}\")\n",
    "    print(f\"Original Δ_normalized = {Δ_normalized_original:.6f}\")\n",
    "    print(f\"Original Δ_per_triangle (Δ/ntri) = {Δ_original/ntri:.6f}\")\n",
    "    print()\n",
    "\n",
    "    # Build & freeze ALL masked matrices (same seed pattern as TreePrior)\n",
    "    masked_registry = []\n",
    "    for frac in MISSING_FRACS:\n",
    "        for r in range(1, REPS + 1):\n",
    "            rng = np.random.RandomState(BASE_SEED + (r - 1))\n",
    "            D_inc, obs_mask = simulate_missing(D0, frac, rng)\n",
    "            masked_registry.append({\"frac\": frac, \"rep\": r, \"D_inc\": D_inc, \"obs_mask\": obs_mask})\n",
    "\n",
    "    # Save all masked matrices\n",
    "    os.makedirs(MASKED_DIR, exist_ok=True)\n",
    "    for rec in masked_registry:\n",
    "        pct = int(round(100 * rec[\"frac\"]))\n",
    "        fn = f\"missing_p{pct}_rep{rec['rep']}.csv\"\n",
    "        pd.DataFrame(rec[\"D_inc\"], index=labels, columns=labels).to_csv(os.path.join(MASKED_DIR, fn))\n",
    "\n",
    "    # Run Hyb-Adam-UM on ALL masks\n",
    "    print(\"=== Running Hyb-Adam-UM on all masks ===\")\n",
    "    os.makedirs(COMPLETED_DIR, exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    runtimes_50 = []\n",
    "\n",
    "    for rec in masked_registry:\n",
    "        frac = rec[\"frac\"]; rep = rec[\"rep\"]\n",
    "        D_inc = rec[\"D_inc\"]\n",
    "        pct = int(round(100 * frac))\n",
    "        print(f\"\\n  Processing {pct}% missing, replicate {rep}...\")\n",
    "\n",
    "        t0_50 = time.perf_counter() if abs(frac - 0.50) < 1e-12 else None\n",
    "        t_all = time.perf_counter()\n",
    "\n",
    "        # Train\n",
    "        D_hyb, info = hyb_adam_um_impute(D_inc, trip_all=trip_all, ntri=ntri, verbose=True)\n",
    "\n",
    "        runtime_total = time.perf_counter() - t_all\n",
    "        runtime_50 = None\n",
    "        if t0_50 is not None:\n",
    "            runtime_50 = time.perf_counter() - t0_50\n",
    "            runtimes_50.append(runtime_50)\n",
    "            print(f\"    Runtime for 50% missing, replicate {rep}: {runtime_50:.2f} sec ({runtime_50/60:.2f} min)\")\n",
    "        print(f\"    End-to-end runtime: {runtime_total:.2f} sec ({runtime_total/60:.2f} min)\")\n",
    "\n",
    "        # Sanitize (consistent with your earlier script)\n",
    "        D_hyb_san = sanitize_distance_matrix(D_hyb, f\"Hyb-Adam-UM_p{pct}_rep{rep}\")\n",
    "\n",
    "        # Metrics vs original\n",
    "        rmse_val = rmse_on_lt(D_hyb_san, D0)\n",
    "        Δ_total  = robust_delta_sum_numpy(D_hyb_san, trip_all)\n",
    "        Δ_norm   = compute_normalized_delta(D_hyb_san, trip_all)\n",
    "        Δ_per_triangle = Δ_total / ntri\n",
    "        Δ_relative = (Δ_total / Δ_original) if (Δ_original != 0) else float(\"nan\")\n",
    "\n",
    "        # Save completed matrix\n",
    "        out_fn = f\"HybAdamUM_completed_p{pct}_rep{rep}.csv\"\n",
    "        pd.DataFrame(D_hyb_san, index=labels, columns=labels).to_csv(os.path.join(COMPLETED_DIR, out_fn))\n",
    "\n",
    "        results.append({\n",
    "            \"pct_missing\": pct,\n",
    "            \"replicate\": rep,\n",
    "            \"RMSE_vs_ORIG\": rmse_val,\n",
    "            \"Δ_total\": Δ_total,\n",
    "            \"Δ_normalized\": Δ_norm,\n",
    "            \"Δ_per_triangle\": Δ_per_triangle,\n",
    "            \"Δ_relative\": Δ_relative,\n",
    "            \"runtime_seconds\": runtime_50,   # keep TreePrior convention: only filled for 50%\n",
    "            \"completed_file\": out_fn,\n",
    "            \"train_info\": str(info),\n",
    "        })\n",
    "\n",
    "    # runtime summary for 50%\n",
    "    if runtimes_50:\n",
    "        avg_runtime_50 = float(np.mean(runtimes_50))\n",
    "        min_runtime_50 = float(np.min(runtimes_50))\n",
    "        max_runtime_50 = float(np.max(runtimes_50))\n",
    "        print(\"\\n=== Runtime summary for 50% missing matrices ===\")\n",
    "        print(f\"Count: {len(runtimes_50)}\")\n",
    "        print(f\"Average: {avg_runtime_50:.2f} sec ({avg_runtime_50/60:.2f} min)\")\n",
    "        print(f\"Range:   {min_runtime_50:.2f} - {max_runtime_50:.2f} sec ({min_runtime_50/60:.2f} - {max_runtime_50/60:.2f} min)\")\n",
    "\n",
    "    # detailed results table\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n=== Hyb-Adam-UM results for all masks ===\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(results_df)\n",
    "    except Exception:\n",
    "        print(results_df.to_string(index=False))\n",
    "    results_df.to_csv(\"hyb_adam_um_all_masks_detailed.csv\", index=False)\n",
    "\n",
    "    # summary (mean ± std over reps per missingness)\n",
    "    summary_rows = []\n",
    "    for frac in MISSING_FRACS:\n",
    "        pct = int(round(100 * frac))\n",
    "        mask_results = results_df[results_df[\"pct_missing\"] == pct]\n",
    "\n",
    "        rmse_vals = mask_results[\"RMSE_vs_ORIG\"].astype(float).to_numpy()\n",
    "        dt_vals   = mask_results[\"Δ_total\"].astype(float).to_numpy()\n",
    "        dn_vals   = mask_results[\"Δ_normalized\"].astype(float).to_numpy()\n",
    "        dpt_vals  = mask_results[\"Δ_per_triangle\"].astype(float).to_numpy()\n",
    "        dr_vals   = mask_results[\"Δ_relative\"].astype(float).to_numpy()\n",
    "\n",
    "        rmse_m, rmse_s = mean_std(rmse_vals)\n",
    "        dt_m, dt_s     = mean_std(dt_vals)\n",
    "        dn_m, dn_s     = mean_std(dn_vals)\n",
    "        dpt_m, dpt_s   = mean_std(dpt_vals)\n",
    "        dr_m, dr_s     = mean_std(dr_vals)\n",
    "\n",
    "        summary_rows.append({\n",
    "            \"% Missing\": f\"{pct}%\",\n",
    "            \"RMSE_mean\": rmse_m, \"RMSE_std\": rmse_s,\n",
    "            \"Δ_total_mean\": dt_m, \"Δ_total_std\": dt_s,\n",
    "            \"Δ_normalized_mean\": dn_m, \"Δ_normalized_std\": dn_s,\n",
    "            \"Δ_per_triangle_mean\": dpt_m, \"Δ_per_triangle_std\": dpt_s,\n",
    "            \"Δ_relative_mean\": dr_m, \"Δ_relative_std\": dr_s\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows)\n",
    "    print(\"\\n=== Hyb-Adam-UM summary (mean ± std over replicates) ===\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(summary_df)\n",
    "    except Exception:\n",
    "        print(summary_df.to_string(index=False))\n",
    "\n",
    "    # formatted summary (NJ*-style)\n",
    "    formatted_summary_df = summary_df.copy()\n",
    "    formatted_summary_df[\"RMSE\"] = [\n",
    "        fmt_pm(row[\"RMSE_mean\"], row[\"RMSE_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ_total\"] = [\n",
    "        fmt_pm(row[\"Δ_total_mean\"], row[\"Δ_total_std\"], 4) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ_normalized\"] = [\n",
    "        fmt_pm(row[\"Δ_normalized_mean\"], row[\"Δ_normalized_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ̄ (per triangle)\"] = [\n",
    "        fmt_pm(row[\"Δ_per_triangle_mean\"], row[\"Δ_per_triangle_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df[\"Δ_relative (to original)\"] = [\n",
    "        fmt_pm(row[\"Δ_relative_mean\"], row[\"Δ_relative_std\"], 6) for _, row in summary_df.iterrows()\n",
    "    ]\n",
    "    formatted_summary_df = formatted_summary_df[\n",
    "        [\"% Missing\", \"RMSE\", \"Δ_total\", \"Δ_normalized\", \"Δ̄ (per triangle)\", \"Δ_relative (to original)\"]\n",
    "    ]\n",
    "\n",
    "    print(\"\\n=== Hyb-Adam-UM formatted summary ===\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(formatted_summary_df)\n",
    "    except Exception:\n",
    "        print(formatted_summary_df.to_string(index=False))\n",
    "\n",
    "    formatted_summary_df.to_csv(\"hyb_adam_um_summary_formatted.csv\", index=False)\n",
    "    pd.concat({\n",
    "        \"mean\": summary_df[[\"RMSE_mean\", \"Δ_total_mean\", \"Δ_normalized_mean\", \"Δ_per_triangle_mean\", \"Δ_relative_mean\"]],\n",
    "        \"std\":  summary_df[[\"RMSE_std\",  \"Δ_total_std\",  \"Δ_normalized_std\",  \"Δ_per_triangle_std\",  \"Δ_relative_std\"]]\n",
    "    }, axis=1).to_csv(\"hyb_adam_um_summary_numeric.csv\")\n",
    "\n",
    "    # training-style delta table (final matrices)\n",
    "    print(f\"\\n=== Delta Sum Table (training-style; COMPLETED matrices) for Hyb-Adam-UM ===\")\n",
    "    print(f\"Original Δ_total = {Δ_original:.6f}\")\n",
    "    print(f\"Original Δ_normalized = {Δ_normalized_original:.6f}\")\n",
    "    print(f\"Number of triangles = {ntri}\")\n",
    "    print(f\"Original Δ_per_triangle = {Δ_original/ntri:.6f}\")\n",
    "\n",
    "    delta_table_rows = [\n",
    "        {\"% Missing\": \"Original\",\n",
    "         \"Hyb-Adam-UM Δ_total\": f\"{Δ_original:.4f}\",\n",
    "         \"Δ_normalized\": f\"{Δ_normalized_original:.6f}\",\n",
    "         \"Δ̄ (per triangle)\": f\"{Δ_original/ntri:.6f}\",\n",
    "         \"Δ_relative (to original)\": \"1.0000\"}\n",
    "    ]\n",
    "\n",
    "    for frac in MISSING_FRACS:\n",
    "        pct = int(round(100 * frac))\n",
    "        mask_results = results_df[results_df[\"pct_missing\"] == pct]\n",
    "\n",
    "        dt_vals  = mask_results[\"Δ_total\"].astype(float).to_numpy()\n",
    "        dn_vals  = mask_results[\"Δ_normalized\"].astype(float).to_numpy()\n",
    "        dpt_vals = mask_results[\"Δ_per_triangle\"].astype(float).to_numpy()\n",
    "        dr_vals  = mask_results[\"Δ_relative\"].astype(float).to_numpy()\n",
    "\n",
    "        dt_m, dt_s   = mean_std(dt_vals)\n",
    "        dn_m, dn_s   = mean_std(dn_vals)\n",
    "        dpt_m, dpt_s = mean_std(dpt_vals)\n",
    "        dr_m, dr_s   = mean_std(dr_vals)\n",
    "\n",
    "        delta_table_rows.append({\n",
    "            \"% Missing\": f\"{pct}%\",\n",
    "            \"Hyb-Adam-UM Δ_total\": f\"{dt_m:.4f} ± {dt_s:.4f}\",\n",
    "            \"Δ_normalized\": f\"{dn_m:.6f} ± {dn_s:.6f}\",\n",
    "            \"Δ̄ (per triangle)\": f\"{dpt_m:.6f} ± {dpt_s:.6f}\",\n",
    "            \"Δ_relative (to original)\": f\"{dr_m:.4f} ± {dr_s:.4f}\"\n",
    "        })\n",
    "\n",
    "    delta_table_df = pd.DataFrame(delta_table_rows)\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(delta_table_df)\n",
    "    except Exception:\n",
    "        print(delta_table_df.to_string(index=False))\n",
    "\n",
    "    delta_table_df.to_csv(\"hyb_adam_um_delta_sum_training_style.csv\", index=False)\n",
    "\n",
    "    print(\"\\n=== ALL PROCESSING COMPLETE! ===\")\n",
    "    print(\"Output files:\")\n",
    "    print(f\"  - Masked matrices saved to: {MASKED_DIR}/\")\n",
    "    print(f\"  - Completed matrices saved to: {COMPLETED_DIR}/\")\n",
    "    print(\"  - Detailed results: hyb_adam_um_all_masks_detailed.csv\")\n",
    "    print(\"  - Formatted summary: hyb_adam_um_summary_formatted.csv\")\n",
    "    print(\"  - Numeric summary: hyb_adam_um_summary_numeric.csv\")\n",
    "    print(\"  - Training-style delta table: hyb_adam_um_delta_sum_training_style.csv\")\n",
    "    print(\"\\nNote: Δ_normalized uses log scaling: δ_norm = log(1+δ)/log(101), then clipped to [0,1].\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb86fb4-01c9-4d0c-a711-870869dc4f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25 completed matrices in: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/hyb_adam_um_completed_matrices\n",
      "  p30 rep1: HybAdamUM_completed_p30_rep1.csv\n",
      "  p30 rep2: HybAdamUM_completed_p30_rep2.csv\n",
      "  p30 rep3: HybAdamUM_completed_p30_rep3.csv\n",
      "  p30 rep4: HybAdamUM_completed_p30_rep4.csv\n",
      "  p30 rep5: HybAdamUM_completed_p30_rep5.csv\n",
      "  p50 rep1: HybAdamUM_completed_p50_rep1.csv\n",
      "  p50 rep2: HybAdamUM_completed_p50_rep2.csv\n",
      "  p50 rep3: HybAdamUM_completed_p50_rep3.csv\n",
      "  p50 rep4: HybAdamUM_completed_p50_rep4.csv\n",
      "  p50 rep5: HybAdamUM_completed_p50_rep5.csv\n",
      "  ...\n",
      "\n",
      "Output directory: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/trees_hyb_adam_um_all\n",
      "\n",
      "Loading original matrix...\n",
      "  Original matrix loaded: Result_NW_15x15.txt\n",
      "  Original matrix shape:  (15, 15)\n",
      "\n",
      "Building NJ tree for original matrix...\n",
      "  Saved: tree_Original.png, tree_Original.newick\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep1.csv (p30, rep1)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p30_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep2.csv (p30, rep2)\n",
      "  Done: RF_norm = 0.333333 | saved -> tree_p30_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep3.csv (p30, rep3)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p30_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep4.csv (p30, rep4)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p30_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p30_rep5.csv (p30, rep5)\n",
      "  Done: RF_norm = 0.000000 | saved -> tree_p30_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep1.csv (p50, rep1)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p50_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep2.csv (p50, rep2)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p50_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep3.csv (p50, rep3)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p50_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep4.csv (p50, rep4)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p50_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p50_rep5.csv (p50, rep5)\n",
      "  Done: RF_norm = 0.416667 | saved -> tree_p50_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep1.csv (p65, rep1)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p65_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep2.csv (p65, rep2)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p65_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep3.csv (p65, rep3)\n",
      "  Done: RF_norm = 0.583333 | saved -> tree_p65_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep4.csv (p65, rep4)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p65_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p65_rep5.csv (p65, rep5)\n",
      "  Done: RF_norm = 0.500000 | saved -> tree_p65_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep1.csv (p85, rep1)\n",
      "  Done: RF_norm = 0.833333 | saved -> tree_p85_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep2.csv (p85, rep2)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p85_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep3.csv (p85, rep3)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p85_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep4.csv (p85, rep4)\n",
      "  Done: RF_norm = 0.750000 | saved -> tree_p85_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p85_rep5.csv (p85, rep5)\n",
      "  Done: RF_norm = 1.000000 | saved -> tree_p85_rep5.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep1.csv (p90, rep1)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p90_rep1.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep2.csv (p90, rep2)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p90_rep2.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep3.csv (p90, rep3)\n",
      "  Done: RF_norm = 0.833333 | saved -> tree_p90_rep3.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep4.csv (p90, rep4)\n",
      "  Done: RF_norm = 0.916667 | saved -> tree_p90_rep4.png\n",
      "\n",
      "Processing: HybAdamUM_completed_p90_rep5.csv (p90, rep5)\n",
      "  Done: RF_norm = 1.000000 | saved -> tree_p90_rep5.png\n",
      "\n",
      "======================================================================\n",
      "Detailed Tree Benchmark Results (ALL)\n",
      "======================================================================\n",
      " pct_missing  replicate                             file  RF  RF_norm  n_splits  pat_MAE  pat_RMSE  pat_Pearson  pat_Spearman\n",
      "          30          1 HybAdamUM_completed_p30_rep1.csv  14 0.583333        12 0.003757  0.010976     0.952821      0.930717\n",
      "          30          2 HybAdamUM_completed_p30_rep2.csv   8 0.333333        12 0.003722  0.013130     0.933712      0.897533\n",
      "          30          3 HybAdamUM_completed_p30_rep3.csv  12 0.500000        12 0.003255  0.005278     0.990696      0.965758\n",
      "          30          4 HybAdamUM_completed_p30_rep4.csv  10 0.416667        12 0.003217  0.006648     0.982462      0.980790\n",
      "          30          5 HybAdamUM_completed_p30_rep5.csv   0 0.000000        12 0.000934  0.001220     0.999498      0.995791\n",
      "          50          1 HybAdamUM_completed_p50_rep1.csv  10 0.416667        12 0.004151  0.013484     0.927933      0.895604\n",
      "          50          2 HybAdamUM_completed_p50_rep2.csv  10 0.416667        12 0.005839  0.014267     0.923170      0.881122\n",
      "          50          3 HybAdamUM_completed_p50_rep3.csv  12 0.500000        12 0.004223  0.007756     0.984120      0.965011\n",
      "          50          4 HybAdamUM_completed_p50_rep4.csv  14 0.583333        12 0.005164  0.013934     0.924263      0.899160\n",
      "          50          5 HybAdamUM_completed_p50_rep5.csv  10 0.416667        12 0.002695  0.004079     0.994232      0.969718\n",
      "          65          1 HybAdamUM_completed_p65_rep1.csv  14 0.583333        12 0.006030  0.014315     0.924316      0.907858\n",
      "          65          2 HybAdamUM_completed_p65_rep2.csv  12 0.500000        12 0.010036  0.022512     0.804828      0.842515\n",
      "          65          3 HybAdamUM_completed_p65_rep3.csv  14 0.583333        12 0.004457  0.007528     0.984022      0.960937\n",
      "          65          4 HybAdamUM_completed_p65_rep4.csv  12 0.500000        12 0.006023  0.013614     0.931080      0.898787\n",
      "          65          5 HybAdamUM_completed_p65_rep5.csv  12 0.500000        12 0.008872  0.012481     0.959542      0.881039\n",
      "          85          1 HybAdamUM_completed_p85_rep1.csv  20 0.833333        12 0.023484  0.040490     0.319375      0.291675\n",
      "          85          2 HybAdamUM_completed_p85_rep2.csv  22 0.916667        12 0.026145  0.042519     0.246836      0.214400\n",
      "          85          3 HybAdamUM_completed_p85_rep3.csv  22 0.916667        12 0.024687  0.041485     0.337793      0.244360\n",
      "          85          4 HybAdamUM_completed_p85_rep4.csv  18 0.750000        12 0.020120  0.034220     0.518634      0.497844\n",
      "          85          5 HybAdamUM_completed_p85_rep5.csv  24 1.000000        12 0.018676  0.033334     0.564808      0.586440\n",
      "          90          1 HybAdamUM_completed_p90_rep1.csv  22 0.916667        12 0.043357  0.047536     0.329062      0.140711\n",
      "          90          2 HybAdamUM_completed_p90_rep2.csv  22 0.916667        12 0.030061  0.046854     0.128818      0.411341\n",
      "          90          3 HybAdamUM_completed_p90_rep3.csv  20 0.833333        12 0.041863  0.044637     0.342753      0.288451\n",
      "          90          4 HybAdamUM_completed_p90_rep4.csv  22 0.916667        12 0.057522  0.066526     0.017742      0.020143\n",
      "          90          5 HybAdamUM_completed_p90_rep5.csv  24 1.000000        12 0.042865  0.054285     0.214867      0.333392\n",
      "\n",
      "======================================================================\n",
      "Detailed Matrix Benchmark Results (ALL)\n",
      "======================================================================\n",
      " pct_missing  replicate                             file  mat_MAE  mat_RMSE  mat_Pearson  mat_Spearman\n",
      "          30          1 HybAdamUM_completed_p30_rep1.csv 0.002543  0.011035     0.951756      0.952404\n",
      "          30          2 HybAdamUM_completed_p30_rep2.csv 0.003397  0.013289     0.931174      0.896230\n",
      "          30          3 HybAdamUM_completed_p30_rep3.csv 0.001625  0.004645     0.992249      0.979296\n",
      "          30          4 HybAdamUM_completed_p30_rep4.csv 0.002054  0.006316     0.984019      0.983834\n",
      "          30          5 HybAdamUM_completed_p30_rep5.csv 0.000822  0.002205     0.998132      0.986406\n",
      "          50          1 HybAdamUM_completed_p50_rep1.csv 0.003823  0.013535     0.926405      0.878571\n",
      "          50          2 HybAdamUM_completed_p50_rep2.csv 0.005118  0.014419     0.919915      0.888097\n",
      "          50          3 HybAdamUM_completed_p50_rep3.csv 0.003360  0.008292     0.978682      0.970336\n",
      "          50          4 HybAdamUM_completed_p50_rep4.csv 0.004596  0.014044     0.921897      0.886588\n",
      "          50          5 HybAdamUM_completed_p50_rep5.csv 0.002148  0.004616     0.991820      0.956578\n",
      "          65          1 HybAdamUM_completed_p65_rep1.csv 0.005598  0.014495     0.919831      0.885980\n",
      "          65          2 HybAdamUM_completed_p65_rep2.csv 0.009389  0.022682     0.798165      0.823929\n",
      "          65          3 HybAdamUM_completed_p65_rep3.csv 0.003694  0.008072     0.979562      0.957861\n",
      "          65          4 HybAdamUM_completed_p65_rep4.csv 0.005514  0.013864     0.926005      0.882216\n",
      "          65          5 HybAdamUM_completed_p65_rep5.csv 0.007713  0.036386     0.718468      0.934200\n",
      "          85          1 HybAdamUM_completed_p85_rep1.csv 0.022957  0.040384     0.316774      0.310895\n",
      "          85          2 HybAdamUM_completed_p85_rep2.csv 0.025665  0.042554     0.235280      0.175983\n",
      "          85          3 HybAdamUM_completed_p85_rep3.csv 0.024105  0.041562     0.330834      0.282587\n",
      "          85          4 HybAdamUM_completed_p85_rep4.csv 0.019788  0.034707     0.490339      0.466859\n",
      "          85          5 HybAdamUM_completed_p85_rep5.csv 0.017873  0.033046     0.569134      0.623642\n",
      "          90          1 HybAdamUM_completed_p90_rep1.csv 0.043303  0.048874     0.244462      0.332857\n",
      "          90          2 HybAdamUM_completed_p90_rep2.csv 0.029338  0.046747     0.127467      0.393132\n",
      "          90          3 HybAdamUM_completed_p90_rep3.csv 0.040226  0.045360     0.300709      0.285424\n",
      "          90          4 HybAdamUM_completed_p90_rep4.csv 0.056821  0.066633     0.105568      0.026062\n",
      "          90          5 HybAdamUM_completed_p90_rep5.csv 0.043839  0.055265     0.215781      0.332273\n",
      "\n",
      "======================================================================\n",
      "Tree metrics: mean ± SD by missingness\n",
      "======================================================================\n",
      " pct_missing                   RF             RF_norm             pat_MAE            pat_RMSE         pat_Pearson        pat_Spearman\n",
      "          30  8.800000 ± 5.403702 0.366667 ± 0.225154 0.002977 ± 0.001169 0.007451 ± 0.004714 0.971838 ± 0.027608 0.954118 ± 0.039790\n",
      "          50 11.200000 ± 1.788854 0.466667 ± 0.074536 0.004414 ± 0.001189 0.010704 ± 0.004567 0.950744 ± 0.035310 0.922123 ± 0.041882\n",
      "          65 12.800000 ± 1.095445 0.533333 ± 0.045644 0.007083 ± 0.002294 0.014090 ± 0.005405 0.920758 ± 0.069039 0.898227 ± 0.043084\n",
      "          85 21.200000 ± 2.280351 0.883333 ± 0.095015 0.022622 ± 0.003132 0.038409 ± 0.004301 0.397489 ± 0.136961 0.366944 ± 0.165284\n",
      "          90 22.000000 ± 1.414214 0.916667 ± 0.058926 0.043134 ± 0.009742 0.051968 ± 0.008900 0.206648 ± 0.137223 0.238808 ± 0.157016\n",
      "\n",
      "======================================================================\n",
      "Matrix metrics: mean ± SD by missingness\n",
      "======================================================================\n",
      " pct_missing             mat_MAE            mat_RMSE         mat_Pearson        mat_Spearman\n",
      "          30 0.002088 ± 0.000967 0.007498 ± 0.004572 0.971466 ± 0.028777 0.959634 ± 0.037952\n",
      "          50 0.003809 ± 0.001151 0.010981 ± 0.004344 0.947744 ± 0.034633 0.916034 ± 0.043713\n",
      "          65 0.006382 ± 0.002203 0.019100 ± 0.010976 0.868406 ± 0.106926 0.896837 ± 0.051882\n",
      "          85 0.022078 ± 0.003189 0.038451 ± 0.004286 0.388472 ± 0.136882 0.371993 ± 0.174981\n",
      "          90 0.042705 ± 0.009820 0.052576 ± 0.008726 0.198797 ± 0.081455 0.273950 ± 0.143750\n",
      "\n",
      "Saved heatmap grid: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/trees_hyb_adam_um_all/heatmap_grid_original_plus_all.png\n",
      "\n",
      "======================================================================\n",
      "ALL PROCESSING COMPLETE!\n",
      "======================================================================\n",
      "Output directory: /home/user/bioinformatics/try match 2/Hyb-Adam-UM/trees_hyb_adam_um_all\n",
      "\n",
      "Saved:\n",
      "  - Trees: 1 Original + 25 completed PNGs + Newicks\n",
      "  - Detailed CSVs: benchmark_tree_all.csv, benchmark_matrix_all.csv\n",
      "  - Mean±SD CSVs:  benchmark_tree_by_missingness_meanstd.csv, benchmark_matrix_by_missingness_meanstd.csv\n",
      "  - Heatmap grid: heatmap_grid_original_plus_all.png\n"
     ]
    }
   ],
   "source": [
    "# Cell — PICTURES OF TREES + HEATMAPS (ALL masks) for Hyb-Adam-UM (NO TreePrior)\n",
    "#\n",
    "# Compatible with the \"Hyb-Adam-UM only — all missingness × reps\" script above.\n",
    "#\n",
    "# What this does:\n",
    "#   • Auto-finds ALL completed matrices produced by that script:\n",
    "#       HybAdamUM_completed_p{30,50,65,85}_rep{1..5}.csv   (default 20 files)\n",
    "#   • Loads ORIGINAL matrix\n",
    "#   • Builds NJ tree for Original (once)\n",
    "#   • Builds NJ trees for ALL completed matrices\n",
    "#   • Saves:\n",
    "#       - tree PNGs + Newicks (Original + all completed)\n",
    "#       - benchmark CSVs (tree + matrix), detailed + mean±std by missingness\n",
    "#       - heatmap grid PNG (Original + all completed; auto grid size)\n",
    "#\n",
    "# Output folder (single directory, minimal files by default):\n",
    "#   trees_hyb_adam_um_all/\n",
    "#     tree_Original.png\n",
    "#     tree_Original.newick\n",
    "#     tree_p30_rep1.png, tree_p30_rep1.newick, ... (all found)\n",
    "#     benchmark_tree_all.csv\n",
    "#     benchmark_matrix_all.csv\n",
    "#     benchmark_tree_by_missingness_meanstd.csv\n",
    "#     benchmark_matrix_by_missingness_meanstd.csv\n",
    "#     heatmap_grid_original_plus_all.png\n",
    "#\n",
    "# Notes:\n",
    "#   • Heatmap = plt.imshow(matrix), saved as PNG.\n",
    "#   • Grid size is automatic (works for 16, 20, etc).\n",
    "#   • This NJ implementation is a simple nonnegative NJ for visualization/benchmarking.\n",
    "#     It is NOT NJ* for incomplete matrices (we are reading COMPLETED matrices).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Set, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ============================================================\n",
    "# -------------------------- CONFIG ---------------------------\n",
    "# ============================================================\n",
    "\n",
    "COMPLETED_DIR = \"hyb_adam_um_completed_matrices\"   # from the code above\n",
    "OUT_DIR       = \"trees_hyb_adam_um_all\"\n",
    "\n",
    "# Original matrix candidates (edit if needed)\n",
    "ORIG_CANDIDATES = [\n",
    "    \"Result_NW_15x15.txt\",\n",
    "    \"./Result_NW_15x15.txt\",\n",
    "    \"/mnt/data/Result_NW_15x15.txt\",\n",
    "    \"Result_NW_100x100.txt\",\n",
    "    \"./Result_NW_100x100.txt\",\n",
    "    \"/mnt/data/Result_NW_100x100.txt\",\n",
    "    \"ta41_orig.txt\",\n",
    "    \"./ta41_orig.txt\",\n",
    "    \"/mnt/data/ta41_orig.txt\",\n",
    "]\n",
    "\n",
    "# Heatmap options (keep minimal by default)\n",
    "SAVE_HEATMAP_GRID          = True\n",
    "SAVE_INDIVIDUAL_HEATMAPS   = False   # if True: saves (1 + N) PNGs\n",
    "SAVE_PATRISTIC_HEATMAPS    = False   # if True: saves patristic grid too\n",
    "SHOW_PLOTS_INLINE          = False\n",
    "\n",
    "HEATMAP_CMAP = \"viridis\"\n",
    "HEATMAP_DPI  = 220\n",
    "TREE_DPI     = 180\n",
    "\n",
    "# If your completed folder contains extra files, you can limit to first K\n",
    "MAX_COMPLETED_TO_PROCESS = None   # e.g. 15, 20, or None for all found\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- IO HELPERS --------------------------\n",
    "# ============================================================\n",
    "\n",
    "def load_matrix_with_candidates(cands: List[str]) -> Tuple[np.ndarray, str]:\n",
    "    for p in cands:\n",
    "        if os.path.exists(p):\n",
    "            M = np.loadtxt(p)\n",
    "            # heuristic: if distances are in ~1000s, rescale to ~units\n",
    "            if np.nanmax(M) > 500:\n",
    "                M = M / 1000.0\n",
    "            return M, p\n",
    "    raise FileNotFoundError(f\"File not found. Tried: {cands}\")\n",
    "\n",
    "def load_completed_csv(path_csv: str) -> Tuple[np.ndarray, List[str]]:\n",
    "    if not os.path.exists(path_csv):\n",
    "        raise FileNotFoundError(path_csv)\n",
    "    df = pd.read_csv(path_csv, index_col=0)\n",
    "    labels = list(df.columns)\n",
    "    return df.values.astype(float), labels\n",
    "\n",
    "# ============================================================\n",
    "# ----------------------- SANITIZATION ------------------------\n",
    "# ============================================================\n",
    "\n",
    "def _finite_fill(v, fallback: float = 1.0) -> float:\n",
    "    v = np.asarray(v, dtype=float)\n",
    "    vv = v[np.isfinite(v)]\n",
    "    if vv.size > 0:\n",
    "        return float(np.nanmedian(vv))\n",
    "    return float(fallback)\n",
    "\n",
    "def sanitize_distance_matrix(D: np.ndarray, name: str = \"D\", force_nonneg: bool = True) -> np.ndarray:\n",
    "    M = np.array(D, dtype=float)\n",
    "    if M.ndim != 2 or M.shape[0] != M.shape[1]:\n",
    "        raise ValueError(f\"{name} must be square. Got {M.shape}.\")\n",
    "    n = M.shape[0]\n",
    "\n",
    "    neg = (M < 0)\n",
    "    np.fill_diagonal(neg, False)\n",
    "    M[neg] = np.nan\n",
    "\n",
    "    off = ~np.eye(n, dtype=bool)\n",
    "    med = _finite_fill(M[off], fallback=1.0)\n",
    "    M = np.nan_to_num(M, nan=med, posinf=med, neginf=med)\n",
    "\n",
    "    try:\n",
    "        q = np.quantile(M[off], 0.995)\n",
    "    except Exception:\n",
    "        q = np.nan\n",
    "    if np.isfinite(q) and q > 0:\n",
    "        M[off] = np.minimum(M[off], q)\n",
    "\n",
    "    M = 0.5 * (M + M.T)\n",
    "    if force_nonneg:\n",
    "        M = np.maximum(M, 0.0)\n",
    "    np.fill_diagonal(M, 0.0)\n",
    "\n",
    "    if not np.isfinite(M).all():\n",
    "        raise ValueError(f\"{name} has non-finite entries after sanitize.\")\n",
    "    return M\n",
    "\n",
    "# ============================================================\n",
    "# -------------------------- NJ TREE --------------------------\n",
    "# ============================================================\n",
    "\n",
    "@dataclass\n",
    "class NJTree:\n",
    "    newick: str\n",
    "    patristic: np.ndarray\n",
    "    splits: Set[frozenset]\n",
    "    adj: Dict[int, Dict[int, float]]\n",
    "    root: int\n",
    "\n",
    "def neighbor_joining_nonneg(D_full: np.ndarray, labels: List[str]) -> NJTree:\n",
    "    D = sanitize_distance_matrix(D_full, \"NJ_input\", force_nonneg=True)\n",
    "    n = len(labels)\n",
    "    if D.shape != (n, n):\n",
    "        raise ValueError(f\"D shape {D.shape} != (n,n) with n={n}\")\n",
    "\n",
    "    adj: Dict[int, Dict[int, float]] = {}\n",
    "\n",
    "    def add_edge(u: int, v: int, w: float):\n",
    "        w = float(max(w, 1e-9))\n",
    "        adj.setdefault(u, {})\n",
    "        adj.setdefault(v, {})\n",
    "        adj[u][v] = w\n",
    "        adj[v][u] = w\n",
    "\n",
    "    next_id = n\n",
    "    idx2node = {i: i for i in range(n)}\n",
    "    act = list(range(n))\n",
    "    Dv = D.copy()\n",
    "\n",
    "    while len(act) > 2:\n",
    "        m = len(act)\n",
    "        r = np.sum(Dv, axis=1)\n",
    "        r = np.nan_to_num(r, nan=_finite_fill(r, 1.0), posinf=_finite_fill(r, 1.0), neginf=_finite_fill(r, 1.0))\n",
    "\n",
    "        Q = (m - 2) * Dv - r[:, None] - r[None, :]\n",
    "        Q = np.nan_to_num(Q, nan=np.inf, posinf=np.inf, neginf=np.inf)\n",
    "        np.fill_diagonal(Q, np.inf)\n",
    "\n",
    "        if not np.isfinite(Q).any():\n",
    "            Q = Dv.copy()\n",
    "            np.fill_diagonal(Q, np.inf)\n",
    "\n",
    "        a_idx, b_idx = np.unravel_index(np.argmin(Q), Q.shape)\n",
    "        if a_idx > b_idx:\n",
    "            a_idx, b_idx = b_idx, a_idx\n",
    "\n",
    "        i, j = act[a_idx], act[b_idx]\n",
    "        dij = float(Dv[a_idx, b_idx])\n",
    "\n",
    "        li = 0.5 * dij + (r[a_idx] - r[b_idx]) / (2 * (m - 2))\n",
    "        lj = dij - li\n",
    "        if not np.isfinite(li): li = 0.5 * dij\n",
    "        if not np.isfinite(lj): lj = 0.5 * dij\n",
    "\n",
    "        u = next_id\n",
    "        next_id += 1\n",
    "\n",
    "        add_edge(u, idx2node[i], li)\n",
    "        add_edge(u, idx2node[j], lj)\n",
    "\n",
    "        duk = {}\n",
    "        for k in range(m):\n",
    "            if k in (a_idx, b_idx):\n",
    "                continue\n",
    "            val = 0.5 * (Dv[a_idx, k] + Dv[b_idx, k] - dij)\n",
    "            if not np.isfinite(val):\n",
    "                val = _finite_fill([Dv[a_idx, k], Dv[b_idx, k], dij], fallback=0.0)\n",
    "            duk[k] = float(val)\n",
    "\n",
    "        mask = np.ones(m, dtype=bool)\n",
    "        mask[b_idx] = False\n",
    "        Dv = Dv[np.ix_(mask, mask)]\n",
    "\n",
    "        new_a = a_idx\n",
    "        for t in range(m - 1):\n",
    "            if t == new_a:\n",
    "                Dv[new_a, t] = 0.0\n",
    "                continue\n",
    "            old_t = t if t < b_idx else t + 1\n",
    "            Dv[new_a, t] = Dv[t, new_a] = duk.get(old_t, 0.0)\n",
    "\n",
    "        Dv = np.maximum(0.5 * (Dv + Dv.T), 0.0)\n",
    "        np.fill_diagonal(Dv, 0.0)\n",
    "\n",
    "        idx2node[i] = u\n",
    "        act.pop(b_idx)\n",
    "\n",
    "    i, j = act[0], act[1]\n",
    "    add_edge(idx2node[i], idx2node[j], float(Dv[0, 1]))\n",
    "    root = idx2node[i]\n",
    "\n",
    "    def to_newick(x: int, parent: int = -1) -> str:\n",
    "        if x < n:\n",
    "            return labels[x]\n",
    "        parts = []\n",
    "        for v, w in adj.get(x, {}).items():\n",
    "            if v == parent:\n",
    "                continue\n",
    "            parts.append(f\"{to_newick(v, x)}:{w:.6f}\")\n",
    "        return \"(\" + \",\".join(parts) + \")\"\n",
    "\n",
    "    newick = to_newick(root) + \";\"\n",
    "\n",
    "    def path_len(a: int, b: int) -> float:\n",
    "        stack = [(a, -1, 0.0)]\n",
    "        seen = set()\n",
    "        while stack:\n",
    "            x, p, acc = stack.pop()\n",
    "            if x == b:\n",
    "                return acc\n",
    "            seen.add(x)\n",
    "            for y, w in adj.get(x, {}).items():\n",
    "                if y == p or y in seen:\n",
    "                    continue\n",
    "                stack.append((y, x, acc + w))\n",
    "        return np.nan\n",
    "\n",
    "    P = np.zeros((n, n), dtype=float)\n",
    "    for a in range(n):\n",
    "        for b in range(a + 1, n):\n",
    "            d = path_len(a, b)\n",
    "            P[a, b] = P[b, a] = d\n",
    "\n",
    "    def compute_splits() -> Set[frozenset]:\n",
    "        splits = set()\n",
    "        seen_edges = set()\n",
    "        for u in adj:\n",
    "            for v in adj[u]:\n",
    "                if (v, u) in seen_edges:\n",
    "                    continue\n",
    "                seen_edges.add((u, v))\n",
    "\n",
    "                stack = [u]\n",
    "                blocked = v\n",
    "                visited = set([blocked])\n",
    "                leafset = set()\n",
    "\n",
    "                while stack:\n",
    "                    x = stack.pop()\n",
    "                    if x in visited:\n",
    "                        continue\n",
    "                    visited.add(x)\n",
    "                    if x < n:\n",
    "                        leafset.add(labels[x])\n",
    "                    for y in adj.get(x, {}):\n",
    "                        if y not in visited:\n",
    "                            stack.append(y)\n",
    "\n",
    "                if 1 < len(leafset) < n - 1:\n",
    "                    splits.add(frozenset(sorted(leafset)))\n",
    "        return splits\n",
    "\n",
    "    return NJTree(newick=newick, patristic=P, splits=compute_splits(), adj=adj, root=root)\n",
    "\n",
    "# ============================================================\n",
    "# ---------------------- TREE DRAWING -------------------------\n",
    "# ============================================================\n",
    "\n",
    "def draw_nj_tree(nj: NJTree, labels: List[str], title: str, out_path: str, dpi: int = 160):\n",
    "    n = len(labels)\n",
    "    x_pos = {i: i for i in range(n)}\n",
    "    y_pos: Dict[int, float] = {}\n",
    "\n",
    "    def dfs(u: int, p: int = -1, y: float = 0.0):\n",
    "        y_pos[u] = -y\n",
    "        for v, w in nj.adj.get(u, {}).items():\n",
    "            if v == p:\n",
    "                continue\n",
    "            dfs(v, u, y + w)\n",
    "\n",
    "    dfs(nj.root, -1, 0.0)\n",
    "\n",
    "    def leaf_span(node: int) -> float:\n",
    "        if node < n:\n",
    "            return float(x_pos[node])\n",
    "        seen = set()\n",
    "        stack = [node]\n",
    "        leaves = []\n",
    "        while stack:\n",
    "            x = stack.pop()\n",
    "            if x in seen:\n",
    "                continue\n",
    "            seen.add(x)\n",
    "            if x < n:\n",
    "                leaves.append(x_pos[x])\n",
    "            else:\n",
    "                for y in nj.adj.get(x, {}):\n",
    "                    if y not in seen:\n",
    "                        stack.append(y)\n",
    "        return float(np.mean(leaves)) if leaves else 0.0\n",
    "\n",
    "    plt.figure(figsize=(9, 4.2))\n",
    "    drawn = set()\n",
    "    for u in nj.adj:\n",
    "        for v, w in nj.adj[u].items():\n",
    "            if (v, u) in drawn:\n",
    "                continue\n",
    "            drawn.add((u, v))\n",
    "            plt.plot([leaf_span(u), leaf_span(v)], [y_pos.get(u, 0.0), y_pos.get(v, 0.0)], linewidth=1.4)\n",
    "\n",
    "    for i in range(n):\n",
    "        plt.text(leaf_span(i), y_pos.get(i, 0.0), labels[i], ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"leaves (order = label order)\")\n",
    "    plt.ylabel(\"− branch length\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches=\"tight\")\n",
    "    if SHOW_PLOTS_INLINE:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------ METRICS ----------------------------\n",
    "# ============================================================\n",
    "\n",
    "def rf_distance(t1: NJTree, t2: NJTree) -> int:\n",
    "    return len(t1.splits - t2.splits) + len(t2.splits - t1.splits)\n",
    "\n",
    "def rf_normalized(t1: NJTree, t2: NJTree, n_leaves: int) -> float:\n",
    "    if n_leaves < 4:\n",
    "        return 0.0\n",
    "    rf = rf_distance(t1, t2)\n",
    "    rf_max = 2 * (n_leaves - 3)\n",
    "    return float(rf) / float(rf_max) if rf_max > 0 else 0.0\n",
    "\n",
    "def _upper_vec(M: np.ndarray) -> np.ndarray:\n",
    "    M = np.asarray(M, dtype=float)\n",
    "    iu = np.triu_indices(M.shape[0], k=1)\n",
    "    v = M[iu]\n",
    "    v = v[np.isfinite(v)]\n",
    "    return v\n",
    "\n",
    "def _pearson(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return float(\"nan\")\n",
    "    if np.std(a) == 0 or np.std(b) == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.corrcoef(a, b)[0, 1])\n",
    "\n",
    "def _spearman(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return float(\"nan\")\n",
    "    ra = pd.Series(a).rank(method=\"average\").to_numpy()\n",
    "    rb = pd.Series(b).rank(method=\"average\").to_numpy()\n",
    "    return _pearson(ra, rb)\n",
    "\n",
    "def patristic_metrics(t: NJTree, tref: NJTree) -> Dict[str, float]:\n",
    "    v = _upper_vec(t.patristic)\n",
    "    vr = _upper_vec(tref.patristic)\n",
    "    m = min(v.size, vr.size)\n",
    "    if m == 0:\n",
    "        return {\"pat_MAE\": np.nan, \"pat_RMSE\": np.nan, \"pat_Pearson\": np.nan, \"pat_Spearman\": np.nan}\n",
    "    v = v[:m]; vr = vr[:m]\n",
    "    diff = v - vr\n",
    "    return {\n",
    "        \"pat_MAE\": float(np.mean(np.abs(diff))),\n",
    "        \"pat_RMSE\": float(np.sqrt(np.mean(diff * diff))),\n",
    "        \"pat_Pearson\": _pearson(v, vr),\n",
    "        \"pat_Spearman\": _spearman(v, vr),\n",
    "    }\n",
    "\n",
    "def matrix_metrics(D: np.ndarray, Dref: np.ndarray) -> Dict[str, float]:\n",
    "    v = _upper_vec(D)\n",
    "    vr = _upper_vec(Dref)\n",
    "    m = min(v.size, vr.size)\n",
    "    if m == 0:\n",
    "        return {\"mat_MAE\": np.nan, \"mat_RMSE\": np.nan, \"mat_Pearson\": np.nan, \"mat_Spearman\": np.nan}\n",
    "    v = v[:m]; vr = vr[:m]\n",
    "    diff = v - vr\n",
    "    return {\n",
    "        \"mat_MAE\": float(np.mean(np.abs(diff))),\n",
    "        \"mat_RMSE\": float(np.sqrt(np.mean(diff * diff))),\n",
    "        \"mat_Pearson\": _pearson(v, vr),\n",
    "        \"mat_Spearman\": _spearman(v, vr),\n",
    "    }\n",
    "\n",
    "def fmt_pm(mean_val: float, std_val: float, decimals: int = 6) -> str:\n",
    "    return f\"{mean_val:.{decimals}f} ± {std_val:.{decimals}f}\"\n",
    "\n",
    "def mean_std_by_group(df: pd.DataFrame, group_col: str, metrics: List[str]) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for g, sub in df.groupby(group_col):\n",
    "        row = {group_col: g}\n",
    "        for m in metrics:\n",
    "            vals = sub[m].astype(float).to_numpy()\n",
    "            mu = float(np.mean(vals))\n",
    "            sd = float(np.std(vals, ddof=1)) if len(vals) > 1 else 0.0\n",
    "            row[m] = fmt_pm(mu, sd, decimals=6)\n",
    "            row[m + \"_mean\"] = mu\n",
    "            row[m + \"_std\"]  = sd\n",
    "        rows.append(row)\n",
    "    out = pd.DataFrame(rows).sort_values(group_col)\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# ------------------------- HEATMAPS --------------------------\n",
    "# ============================================================\n",
    "\n",
    "def plot_heatmap(M: np.ndarray, labels: List[str], title: str, out_png: str):\n",
    "    plt.figure(figsize=(8.2, 6.6))\n",
    "    im = plt.imshow(M, interpolation=\"nearest\", cmap=HEATMAP_CMAP)\n",
    "    plt.title(title, fontsize=12, pad=12)\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90, fontsize=7)\n",
    "    plt.yticks(range(len(labels)), labels, fontsize=7)\n",
    "    plt.colorbar(im, shrink=0.8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=HEATMAP_DPI, bbox_inches=\"tight\")\n",
    "    if SHOW_PLOTS_INLINE:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def plot_heatmap_grid(mats: List[np.ndarray], titles: List[str], labels: List[str], out_png: str):\n",
    "    assert len(mats) == len(titles)\n",
    "    k = len(mats)\n",
    "    ncol = int(math.ceil(math.sqrt(k)))\n",
    "    nrow = int(math.ceil(k / ncol))\n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(5.3*ncol, 4.6*nrow))\n",
    "    axes = np.atleast_1d(axes).ravel()\n",
    "\n",
    "    im = None\n",
    "    for idx in range(nrow * ncol):\n",
    "        ax = axes[idx]\n",
    "        if idx < k:\n",
    "            im = ax.imshow(mats[idx], interpolation=\"nearest\", cmap=HEATMAP_CMAP)\n",
    "            ax.set_title(titles[idx], fontsize=9)\n",
    "            ax.set_xticks(range(len(labels)))\n",
    "            ax.set_xticklabels(labels, rotation=90, fontsize=5)\n",
    "            ax.set_yticks(range(len(labels)))\n",
    "            ax.set_yticklabels(labels, fontsize=5)\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # colorbar on the right\n",
    "    cbar_ax = fig.add_axes([0.92, 0.12, 0.015, 0.76])\n",
    "    fig.colorbar(im, cax=cbar_ax, label=\"Distance\")\n",
    "    plt.savefig(out_png, dpi=HEATMAP_DPI, bbox_inches=\"tight\")\n",
    "    if SHOW_PLOTS_INLINE:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# ============================================================\n",
    "# -------------------------- MAIN -----------------------------\n",
    "# ============================================================\n",
    "\n",
    "# 1) Discover ALL completed matrices for Hyb-Adam-UM (no TreePrior)\n",
    "if not os.path.exists(COMPLETED_DIR):\n",
    "    raise FileNotFoundError(f\"Completed directory not found: {COMPLETED_DIR}\")\n",
    "\n",
    "# Matches filenames created by the Hyb-Adam-UM-only code above:\n",
    "#   HybAdamUM_completed_p{pct}_rep{rep}.csv\n",
    "pat = re.compile(r\"^HybAdamUM_completed_p(\\d+)_rep(\\d+)\\.csv$\")\n",
    "found = []\n",
    "for fn in sorted(os.listdir(COMPLETED_DIR)):\n",
    "    m = pat.match(fn)\n",
    "    if m:\n",
    "        pct = int(m.group(1))\n",
    "        rep = int(m.group(2))\n",
    "        found.append((pct, rep, fn))\n",
    "\n",
    "if len(found) == 0:\n",
    "    raise RuntimeError(\n",
    "        f\"No files matched pattern in {COMPLETED_DIR}: HybAdamUM_completed_p##_rep#.csv\"\n",
    "    )\n",
    "\n",
    "found = sorted(found, key=lambda x: (x[0], x[1]))\n",
    "if MAX_COMPLETED_TO_PROCESS is not None:\n",
    "    found = found[:int(MAX_COMPLETED_TO_PROCESS)]\n",
    "\n",
    "print(f\"Found {len(found)} completed matrices in: {os.path.abspath(COMPLETED_DIR)}\")\n",
    "for pct, rep, fn in found[:10]:\n",
    "    print(f\"  p{pct} rep{rep}: {fn}\")\n",
    "if len(found) > 10:\n",
    "    print(\"  ...\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "print(f\"\\nOutput directory: {os.path.abspath(OUT_DIR)}\")\n",
    "\n",
    "# 2) Load ORIGINAL matrix\n",
    "print(\"\\nLoading original matrix...\")\n",
    "D0, D0_path = load_matrix_with_candidates(ORIG_CANDIDATES)\n",
    "D0 = sanitize_distance_matrix(D0, \"D_orig\", force_nonneg=True)\n",
    "print(f\"  Original matrix loaded: {D0_path}\")\n",
    "print(f\"  Original matrix shape:  {D0.shape}\")\n",
    "\n",
    "# 3) Load first completed matrix to get labels (authoritative)\n",
    "first_path = os.path.join(COMPLETED_DIR, found[0][2])\n",
    "D_first, labels = load_completed_csv(first_path)\n",
    "if D_first.shape != D0.shape:\n",
    "    raise ValueError(\n",
    "        f\"Original shape {D0.shape} != completed shape {D_first.shape}. \"\n",
    "        f\"Fix ORIG_CANDIDATES or use matching original.\"\n",
    "    )\n",
    "\n",
    "# 4) Build Original NJ tree once\n",
    "print(\"\\nBuilding NJ tree for original matrix...\")\n",
    "tree_orig = neighbor_joining_nonneg(D0, labels)\n",
    "draw_nj_tree(tree_orig, labels, \"NJ (Original full matrix)\", os.path.join(OUT_DIR, \"tree_Original.png\"), dpi=TREE_DPI)\n",
    "with open(os.path.join(OUT_DIR, \"tree_Original.newick\"), \"w\") as f:\n",
    "    f.write(tree_orig.newick + \"\\n\")\n",
    "print(\"  Saved: tree_Original.png, tree_Original.newick\")\n",
    "\n",
    "# 5) Process all completed matrices\n",
    "tree_rows = []\n",
    "mat_rows  = []\n",
    "\n",
    "heat_mats   = [D0]\n",
    "heat_titles = [\"Original\"]\n",
    "\n",
    "if SAVE_PATRISTIC_HEATMAPS:\n",
    "    pat_mats   = [tree_orig.patristic]\n",
    "    pat_titles = [\"Patristic (Original)\"]\n",
    "\n",
    "for pct, rep, fn in found:\n",
    "    path = os.path.join(COMPLETED_DIR, fn)\n",
    "    print(f\"\\nProcessing: {fn} (p{pct}, rep{rep})\")\n",
    "\n",
    "    D_comp, labels2 = load_completed_csv(path)\n",
    "    labels_use = labels2 if labels2 != labels else labels\n",
    "\n",
    "    if D_comp.shape != D0.shape:\n",
    "        print(f\"  Skip: shape mismatch {D_comp.shape} vs original {D0.shape}\")\n",
    "        continue\n",
    "\n",
    "    D_comp = sanitize_distance_matrix(D_comp, f\"D_comp_p{pct}_rep{rep}\", force_nonneg=True)\n",
    "\n",
    "    # build NJ tree\n",
    "    tree_comp = neighbor_joining_nonneg(D_comp, labels_use)\n",
    "\n",
    "    # draw + save tree\n",
    "    tree_png = os.path.join(OUT_DIR, f\"tree_p{pct}_rep{rep}.png\")\n",
    "    draw_nj_tree(tree_comp, labels_use, f\"NJ (Hyb-Adam-UM — {pct}% missing, rep{rep})\", tree_png, dpi=TREE_DPI)\n",
    "\n",
    "    # save newick\n",
    "    newick_path = os.path.join(OUT_DIR, f\"tree_p{pct}_rep{rep}.newick\")\n",
    "    with open(newick_path, \"w\") as f:\n",
    "        f.write(tree_comp.newick + \"\\n\")\n",
    "\n",
    "    # benchmarks (tree-level)\n",
    "    tr = {\n",
    "        \"pct_missing\": pct,\n",
    "        \"replicate\": rep,\n",
    "        \"file\": fn,\n",
    "        \"RF\": int(rf_distance(tree_comp, tree_orig)),\n",
    "        \"RF_norm\": float(rf_normalized(tree_comp, tree_orig, len(labels_use))),\n",
    "        \"n_splits\": int(len(tree_comp.splits)),\n",
    "    }\n",
    "    tr.update(patristic_metrics(tree_comp, tree_orig))\n",
    "    tree_rows.append(tr)\n",
    "\n",
    "    # benchmarks (matrix-level)\n",
    "    mr = {\"pct_missing\": pct, \"replicate\": rep, \"file\": fn}\n",
    "    mr.update(matrix_metrics(D_comp, D0))\n",
    "    mat_rows.append(mr)\n",
    "\n",
    "    print(f\"  Done: RF_norm = {tr['RF_norm']:.6f} | saved -> {os.path.basename(tree_png)}\")\n",
    "\n",
    "    # collect for heatmap grid\n",
    "    heat_mats.append(D_comp)\n",
    "    heat_titles.append(f\"p{pct} r{rep} (RF={tr['RF_norm']:.3f})\")\n",
    "\n",
    "    if SAVE_PATRISTIC_HEATMAPS:\n",
    "        pat_mats.append(tree_comp.patristic)\n",
    "        pat_titles.append(f\"Patristic p{pct} r{rep}\")\n",
    "\n",
    "    # optional individual heatmaps\n",
    "    if SAVE_INDIVIDUAL_HEATMAPS:\n",
    "        plot_heatmap(\n",
    "            D_comp, labels_use,\n",
    "            f\"Hyb-Adam-UM completed (p{pct}, rep{rep})\",\n",
    "            os.path.join(OUT_DIR, f\"heatmap_completed_p{pct}_rep{rep}.png\")\n",
    "        )\n",
    "\n",
    "# 6) Save detailed tables\n",
    "df_tree = pd.DataFrame(tree_rows).sort_values([\"pct_missing\", \"replicate\"])\n",
    "df_mat  = pd.DataFrame(mat_rows).sort_values([\"pct_missing\", \"replicate\"])\n",
    "\n",
    "tree_csv = os.path.join(OUT_DIR, \"benchmark_tree_all.csv\")\n",
    "mat_csv  = os.path.join(OUT_DIR, \"benchmark_matrix_all.csv\")\n",
    "df_tree.to_csv(tree_csv, index=False)\n",
    "df_mat.to_csv(mat_csv, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Detailed Tree Benchmark Results (ALL)\")\n",
    "print(\"=\"*70)\n",
    "with pd.option_context(\"display.max_rows\", 300, \"display.max_columns\", 300, \"display.width\", 240):\n",
    "    print(df_tree.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Detailed Matrix Benchmark Results (ALL)\")\n",
    "print(\"=\"*70)\n",
    "with pd.option_context(\"display.max_rows\", 300, \"display.max_columns\", 300, \"display.width\", 240):\n",
    "    print(df_mat.to_string(index=False))\n",
    "\n",
    "# 7) Mean ± SD by missingness\n",
    "tree_metrics_list = [\"RF\", \"RF_norm\", \"pat_MAE\", \"pat_RMSE\", \"pat_Pearson\", \"pat_Spearman\"]\n",
    "mat_metrics_list  = [\"mat_MAE\", \"mat_RMSE\", \"mat_Pearson\", \"mat_Spearman\"]\n",
    "\n",
    "df_tree_ms = mean_std_by_group(df_tree, \"pct_missing\", tree_metrics_list)\n",
    "df_mat_ms  = mean_std_by_group(df_mat,  \"pct_missing\", mat_metrics_list)\n",
    "\n",
    "tree_ms_csv = os.path.join(OUT_DIR, \"benchmark_tree_by_missingness_meanstd.csv\")\n",
    "mat_ms_csv  = os.path.join(OUT_DIR, \"benchmark_matrix_by_missingness_meanstd.csv\")\n",
    "df_tree_ms.to_csv(tree_ms_csv, index=False)\n",
    "df_mat_ms.to_csv(mat_ms_csv, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Tree metrics: mean ± SD by missingness\")\n",
    "print(\"=\"*70)\n",
    "print(df_tree_ms[[\"pct_missing\"] + tree_metrics_list].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Matrix metrics: mean ± SD by missingness\")\n",
    "print(\"=\"*70)\n",
    "print(df_mat_ms[[\"pct_missing\"] + mat_metrics_list].to_string(index=False))\n",
    "\n",
    "# 8) Heatmaps\n",
    "if SAVE_HEATMAP_GRID:\n",
    "    out_grid = os.path.join(OUT_DIR, \"heatmap_grid_original_plus_all.png\")\n",
    "    plot_heatmap_grid(heat_mats, heat_titles, labels, out_grid)\n",
    "    print(f\"\\nSaved heatmap grid: {os.path.abspath(out_grid)}\")\n",
    "\n",
    "if SAVE_PATRISTIC_HEATMAPS:\n",
    "    out_grid_pat = os.path.join(OUT_DIR, \"heatmap_grid_patristic_original_plus_all.png\")\n",
    "    plot_heatmap_grid(pat_mats, pat_titles, labels, out_grid_pat)\n",
    "    print(f\"Saved patristic heatmap grid: {os.path.abspath(out_grid_pat)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL PROCESSING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Output directory: {os.path.abspath(OUT_DIR)}\")\n",
    "print(\"\\nSaved:\")\n",
    "print(f\"  - Trees: 1 Original + {len(df_tree)} completed PNGs + Newicks\")\n",
    "print(f\"  - Detailed CSVs: {os.path.basename(tree_csv)}, {os.path.basename(mat_csv)}\")\n",
    "print(f\"  - Mean±SD CSVs:  {os.path.basename(tree_ms_csv)}, {os.path.basename(mat_ms_csv)}\")\n",
    "if SAVE_HEATMAP_GRID:\n",
    "    print(f\"  - Heatmap grid: heatmap_grid_original_plus_all.png\")\n",
    "if SAVE_INDIVIDUAL_HEATMAPS:\n",
    "    print(f\"  - Individual heatmaps: {len(df_mat)} PNGs (plus original if you add it)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f50c4c-2979-4a94-b0fb-ae7e61596bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
